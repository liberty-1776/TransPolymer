{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python310\\lib\\site-packages\\transformers\\trainer_pt_utils.py:211: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: Optional[torch.device] = torch.device(\"cuda\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downstream_Dataset class is called\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, RobertaModel, RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from PolymerSmilesTokenization import PolymerSmilesTokenizer\n",
    "from dataset import Downstream_Dataset, DataAugmentation, LoadPretrainData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import R2Score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = pd.read_csv('data/practice.csv')\n",
    "len(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*C*</td>\n",
       "      <td>0.671870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*CC(*)C</td>\n",
       "      <td>0.440891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*CC(*)CC</td>\n",
       "      <td>0.439301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*CC(*)CCC</td>\n",
       "      <td>0.571796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CC(*)CC(C)C</td>\n",
       "      <td>0.575343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>*CC1CCC(*)C1</td>\n",
       "      <td>0.711080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>*CC(*)CCCC1CCCCC1</td>\n",
       "      <td>0.349564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>*C=CCCC*</td>\n",
       "      <td>-0.710518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>*C=CCC*</td>\n",
       "      <td>-0.358177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>*C=C*</td>\n",
       "      <td>-2.691151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              smiles     value\n",
       "0                *C*  0.671870\n",
       "1            *CC(*)C  0.440891\n",
       "2           *CC(*)CC  0.439301\n",
       "3          *CC(*)CCC  0.571796\n",
       "4       *CC(*)CC(C)C  0.575343\n",
       "5       *CC1CCC(*)C1  0.711080\n",
       "6  *CC(*)CCCC1CCCCC1  0.349564\n",
       "7           *C=CCCC* -0.710518\n",
       "8            *C=CCC* -0.358177\n",
       "9              *C=C* -2.691151"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data.iloc[:, 1] = scaler.fit_transform(train_data.iloc[:, 1].values.reshape(-1, 1))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'PolymerSmilesTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*CC(*)CCCC1CCCCC1\n",
      "['*', 'C', 'C', '(', '*', ')', 'C', 'C', 'C', 'C', '1', 'C', 'C', 'C', 'C', 'C', '1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,  347,  134,\n",
       "         347,  347,  347,  347,  347,  134,    2,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PolymerSmilesTokenizer.from_pretrained(\"roberta-base\", max_len=411)\n",
    "text = train_data['smiles'][6]\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "train_dataset = Downstream_Dataset(train_data, tokenizer, 411)\n",
    "train_dataset[6]['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0014,  0.0059,  0.0089,  ..., -0.0203, -0.0186,  0.0288],\n",
      "        [ 0.0365, -0.0035,  0.0030,  ...,  0.0026, -0.0073, -0.0154],\n",
      "        [ 0.0061, -0.0477,  0.0195,  ...,  0.0075, -0.0146, -0.0528],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([411, 768])\n",
      "tensor([-0.0014,  0.0059,  0.0089, -0.0007, -0.0136, -0.0154, -0.0051, -0.0126,\n",
      "         0.0142, -0.0357, -0.0092, -0.0254, -0.0044, -0.0343, -0.0358, -0.0219,\n",
      "         0.0267, -0.0130, -0.0353, -0.0004,  0.0254, -0.0411, -0.0052,  0.0124,\n",
      "         0.0079, -0.0140,  0.0470,  0.0152,  0.0154,  0.0119,  0.0164,  0.0035,\n",
      "        -0.0114, -0.0068,  0.0060,  0.0094,  0.0240,  0.0187, -0.0291,  0.0057,\n",
      "         0.0004,  0.0156,  0.0009,  0.0167, -0.0058,  0.0005,  0.0271,  0.0202,\n",
      "        -0.0118, -0.0069, -0.0152, -0.0082,  0.0401, -0.0112, -0.0130, -0.0035,\n",
      "        -0.0024, -0.0259,  0.0040, -0.0246,  0.0139, -0.0161, -0.0005, -0.0047,\n",
      "         0.0009, -0.0338,  0.0061,  0.0004,  0.0043, -0.0155, -0.0116,  0.0329,\n",
      "         0.0233, -0.0086,  0.0227, -0.0044,  0.0146, -0.0007,  0.0429,  0.0017,\n",
      "        -0.0115,  0.0231,  0.0075,  0.0214,  0.0075,  0.0344, -0.0173, -0.0353,\n",
      "         0.0055,  0.0107, -0.0027,  0.0048, -0.0226,  0.0068, -0.0403, -0.0053,\n",
      "        -0.0098,  0.0371,  0.0055,  0.0277,  0.0088, -0.0181, -0.0156,  0.0264,\n",
      "        -0.0076, -0.0095, -0.0370, -0.0143, -0.0215, -0.0285, -0.0081, -0.0191,\n",
      "        -0.0087,  0.0091,  0.0262,  0.0042, -0.0041, -0.0159, -0.0016, -0.0131,\n",
      "        -0.0253,  0.0025,  0.0275,  0.0232,  0.0161, -0.0212,  0.0080,  0.0107,\n",
      "         0.0089, -0.0440, -0.0055, -0.0125,  0.0016,  0.0396, -0.0087,  0.0075,\n",
      "        -0.0282,  0.0177, -0.0138,  0.0166,  0.0337,  0.0118,  0.0001,  0.0054,\n",
      "         0.0058, -0.0029, -0.0064, -0.0209, -0.0195, -0.0032, -0.0261, -0.0031,\n",
      "         0.0146, -0.0028,  0.0106,  0.0209,  0.0114, -0.0045,  0.0049,  0.0033,\n",
      "        -0.0275,  0.0017, -0.0270,  0.0176,  0.0043,  0.0042, -0.0196, -0.0081,\n",
      "         0.0029,  0.0315,  0.0069, -0.0204,  0.0136,  0.0253,  0.0092,  0.0243,\n",
      "         0.0253, -0.0062,  0.0208,  0.0096, -0.0373, -0.0196, -0.0081, -0.0105,\n",
      "        -0.0260, -0.0079, -0.0138,  0.0112,  0.0216, -0.0253,  0.0514,  0.0085,\n",
      "        -0.0193, -0.0444,  0.0150,  0.0139, -0.0429,  0.0244,  0.0333,  0.0066,\n",
      "         0.0184, -0.0128, -0.0095,  0.0237,  0.0201,  0.0408,  0.0120, -0.0157,\n",
      "        -0.0105, -0.0028,  0.0091, -0.0095,  0.0058, -0.0284,  0.0275,  0.0269,\n",
      "        -0.0231,  0.0098, -0.0008, -0.0219,  0.0234, -0.0030,  0.0142, -0.0078,\n",
      "        -0.0026,  0.0197,  0.0162, -0.0002, -0.0101,  0.0219,  0.0125,  0.0032,\n",
      "        -0.0196, -0.0078, -0.0280,  0.0009, -0.0181, -0.0146,  0.0363,  0.0115,\n",
      "         0.0116, -0.0273, -0.0157,  0.0035, -0.0058,  0.0399,  0.0156,  0.0073,\n",
      "        -0.0278,  0.0368,  0.0263,  0.0227, -0.0004, -0.0455, -0.0222,  0.0077,\n",
      "        -0.0055,  0.0182, -0.0401, -0.0104,  0.0285,  0.0361, -0.0257,  0.0310,\n",
      "        -0.0008, -0.0193, -0.0197,  0.0028, -0.0297, -0.0307,  0.0145, -0.0139,\n",
      "         0.0370, -0.0152, -0.0443, -0.0193, -0.0175,  0.0042,  0.0333,  0.0133,\n",
      "         0.0031, -0.0128, -0.0213, -0.0132,  0.0292,  0.0069, -0.0102, -0.0098,\n",
      "        -0.0379,  0.0125,  0.0025,  0.0408,  0.0237, -0.0058,  0.0061,  0.0129,\n",
      "         0.0176, -0.0136, -0.0094, -0.0487, -0.0114, -0.0048, -0.0124, -0.0004,\n",
      "         0.0331, -0.0386,  0.0191,  0.0078, -0.0322, -0.0319, -0.0330,  0.0287,\n",
      "         0.0006, -0.0094,  0.0153, -0.0136, -0.0103,  0.0185,  0.0086,  0.0212,\n",
      "         0.0221, -0.0051,  0.0226,  0.0196, -0.0153, -0.0192, -0.0322,  0.0098,\n",
      "        -0.0019, -0.0039, -0.0053, -0.0282,  0.0136, -0.0333,  0.0292, -0.0260,\n",
      "        -0.0262,  0.0202, -0.0469,  0.0080,  0.0012,  0.0293,  0.0196,  0.0241,\n",
      "        -0.0212, -0.0246, -0.0246,  0.0076,  0.0234, -0.0415, -0.0136, -0.0309,\n",
      "        -0.0054,  0.0047,  0.0313, -0.0345, -0.0147,  0.0187,  0.0167,  0.0007,\n",
      "        -0.0187,  0.0075,  0.0208, -0.0256, -0.0111,  0.0074,  0.0125,  0.0232,\n",
      "        -0.0004, -0.0050, -0.0194,  0.0256,  0.0140, -0.0179, -0.0028,  0.0564,\n",
      "         0.0047,  0.0390,  0.0032, -0.0095, -0.0115, -0.0352,  0.0265, -0.0208,\n",
      "        -0.0283, -0.0021, -0.0134, -0.0223,  0.0299, -0.0104,  0.0441, -0.0131,\n",
      "        -0.0140, -0.0069, -0.0181,  0.0122,  0.0284, -0.0278,  0.0312, -0.0065,\n",
      "         0.0073,  0.0006, -0.0115,  0.0235, -0.0054,  0.0283, -0.0074,  0.0067,\n",
      "        -0.0196, -0.0068,  0.0123,  0.0087, -0.0100,  0.0409, -0.0398,  0.0268,\n",
      "        -0.0143, -0.0089,  0.0147, -0.0259,  0.0106,  0.0327,  0.0071,  0.0063,\n",
      "         0.0136, -0.0050, -0.0213,  0.0420,  0.0078, -0.0258,  0.0374, -0.0046,\n",
      "        -0.0065,  0.0267,  0.0329, -0.0342,  0.0053,  0.0226, -0.0082,  0.0193,\n",
      "        -0.0271,  0.0255,  0.0179, -0.0152,  0.0031, -0.0056,  0.0259,  0.0383,\n",
      "        -0.0120, -0.0270, -0.0165,  0.0004, -0.0312,  0.0113,  0.0072,  0.0254,\n",
      "         0.0364, -0.0452,  0.0351, -0.0082,  0.0356,  0.0380,  0.0102,  0.0232,\n",
      "        -0.0047,  0.0048,  0.0171,  0.0071,  0.0080,  0.0067,  0.0105,  0.0430,\n",
      "         0.0224, -0.0281,  0.0124,  0.0113,  0.0132, -0.0093,  0.0309,  0.0030,\n",
      "        -0.0010,  0.0418, -0.0228,  0.0031,  0.0016,  0.0073,  0.0267, -0.0100,\n",
      "         0.0038,  0.0303, -0.0129, -0.0101,  0.0221, -0.0066, -0.0202, -0.0130,\n",
      "        -0.0180,  0.0074,  0.0006,  0.0224,  0.0133,  0.0393, -0.0296, -0.0046,\n",
      "         0.0188, -0.0112, -0.0215, -0.0135,  0.0010,  0.0131,  0.0028,  0.0361,\n",
      "         0.0124,  0.0015,  0.0087,  0.0073, -0.0106, -0.0023,  0.0593,  0.0130,\n",
      "         0.0073,  0.0177,  0.0034, -0.0249, -0.0035, -0.0036, -0.0404, -0.0090,\n",
      "         0.0068, -0.0176,  0.0061,  0.0044, -0.0161, -0.0272,  0.0171,  0.0097,\n",
      "         0.0161,  0.0011, -0.0308,  0.0233, -0.0110,  0.0036,  0.0227, -0.0041,\n",
      "         0.0112,  0.0050, -0.0044,  0.0133,  0.0401, -0.0249,  0.0191, -0.0194,\n",
      "         0.0003,  0.0136, -0.0110, -0.0191,  0.0084, -0.0220,  0.0405, -0.0169,\n",
      "        -0.0144, -0.0044,  0.0223,  0.0582, -0.0337, -0.0239,  0.0172, -0.0048,\n",
      "        -0.0154,  0.0072,  0.0129,  0.0274,  0.0091, -0.0056, -0.0068,  0.0431,\n",
      "        -0.0352,  0.0001,  0.0035, -0.0155,  0.0140,  0.0491,  0.0261, -0.0591,\n",
      "        -0.0247,  0.0062, -0.0207,  0.0076, -0.0162, -0.0084, -0.0077, -0.0076,\n",
      "         0.0018, -0.0076,  0.0162,  0.0042,  0.0165, -0.0172, -0.0177, -0.0064,\n",
      "         0.0111, -0.0040,  0.0067, -0.0064, -0.0138, -0.0112, -0.0081, -0.0031,\n",
      "        -0.0106,  0.0198,  0.0301, -0.0026, -0.0225, -0.0205, -0.0053,  0.0149,\n",
      "        -0.0493, -0.0288, -0.0596, -0.0170, -0.0244,  0.0051, -0.0085,  0.0063,\n",
      "         0.0177, -0.0111,  0.0376,  0.0191, -0.0086,  0.0220, -0.0258, -0.0306,\n",
      "        -0.0055,  0.0265, -0.0031, -0.0021,  0.0070,  0.0153, -0.0007, -0.0025,\n",
      "        -0.0216,  0.0657, -0.0242,  0.0256, -0.0223,  0.0054, -0.0227, -0.0229,\n",
      "        -0.0063,  0.0010, -0.0159,  0.0329, -0.0318,  0.0077,  0.0466, -0.0117,\n",
      "         0.0152,  0.0103, -0.0071, -0.0023, -0.0106,  0.0093,  0.0012, -0.0089,\n",
      "        -0.0183,  0.0335, -0.0338,  0.0066, -0.0026, -0.0142,  0.0320,  0.0129,\n",
      "        -0.0038, -0.0205,  0.0157, -0.0501, -0.0077, -0.0318,  0.0100, -0.0331,\n",
      "        -0.0038,  0.0272,  0.0058,  0.0180,  0.0035, -0.0076,  0.0215, -0.0166,\n",
      "        -0.0241,  0.0022,  0.0111,  0.0098, -0.0003, -0.0199,  0.0144, -0.0295,\n",
      "        -0.0066, -0.0644,  0.0100, -0.0087,  0.0263, -0.0301,  0.0214, -0.0140,\n",
      "         0.0172, -0.0251,  0.0191, -0.0358,  0.0293, -0.0104, -0.0087, -0.0559,\n",
      "         0.0465, -0.0060,  0.0053, -0.0228, -0.0299,  0.0263, -0.0119, -0.0110,\n",
      "        -0.0198,  0.0035,  0.0020, -0.0112, -0.0027,  0.0177, -0.0391,  0.0231,\n",
      "        -0.0052, -0.0259, -0.0202,  0.0148,  0.0055, -0.0061,  0.0169,  0.0097,\n",
      "         0.0141, -0.0174,  0.0094,  0.0191, -0.0159, -0.0203,  0.0154,  0.0164,\n",
      "        -0.0023, -0.0166, -0.0092, -0.0333,  0.0308, -0.0073,  0.0076, -0.0092,\n",
      "        -0.0204,  0.0066,  0.0388, -0.0117,  0.0090,  0.0279, -0.0343, -0.0051,\n",
      "        -0.0289,  0.0263,  0.0215,  0.0305,  0.0005, -0.0203, -0.0186,  0.0288],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = RobertaConfig(\n",
    "            vocab_size=50265,\n",
    "            max_position_embeddings=514,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "PretrainedModel = RobertaModel(config=config)\n",
    "embeddings = PretrainedModel.embeddings.word_embeddings(train_dataset[6]['input_ids'])\n",
    "print(embeddings)\n",
    "print(embeddings.size())\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class DownstreamRegression is called\n"
     ]
    }
   ],
   "source": [
    "class DownstreamRegression(nn.Module):\n",
    "    print('Class DownstreamRegression is called')\n",
    "    def __init__(self, drop_rate=0.1):\n",
    "        super(DownstreamRegression, self).__init__()\n",
    "        self.PretrainedModel = deepcopy(PretrainedModel)\n",
    "        self.PretrainedModel.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.PretrainedModel.config.hidden_size, self.PretrainedModel.config.hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.PretrainedModel.config.hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.PretrainedModel(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        print(outputs.last_hidden_state.size())\n",
    "        logits = outputs.last_hidden_state[:, 0, :] #fingerprint\n",
    "        print(f'Finger print is:')\n",
    "        print(logits)\n",
    "        print(logits.size())\n",
    "        output = self.Regressor(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, loss_fn, train_dataloader, device):\n",
    "    print('Train func is called')\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print(f'Batch and Step: {step}')\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        print('Batch')\n",
    "        print(input_ids)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        prop = batch[\"prop\"].to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).float()\n",
    "        print('Output for step',step)\n",
    "        print(outputs)\n",
    "        loss = loss_fn(outputs.squeeze(), prop.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print('End of one step')\n",
    "        print('--------------------------------------------------------------------------------')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DownstreamRegression(drop_rate=0.1).to(device)\n",
    "model = model.double()\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, 1, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for scheduler\"\"\"\n",
    "steps_per_epoch = train_data.shape[0] // 1\n",
    "training_steps = steps_per_epoch * 1\n",
    "warmup_steps = int(training_steps * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "                    [\n",
    "                        {\"params\": model.PretrainedModel.parameters(), \"lr\":  0.00005,\n",
    "                         \"weight_decay\": 0.0},\n",
    "                        {\"params\": model.Regressor.parameters(), \"lr\": 0.0001,\n",
    "                         \"weight_decay\": 0.01},\n",
    "                    ],\n",
    "    \t\t\t\tno_deprecation_warning=True\n",
    "                )\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                        num_training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/1\n",
      "Train func is called\n",
      "Batch and Step: 0\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 1.6266e+00, -1.5628e+00, -8.0075e-01, -4.7280e-01,  6.5397e-01,\n",
      "         -1.4828e+00, -1.3986e+00, -1.1669e+00,  5.9937e-01, -9.0250e-01,\n",
      "          1.1724e+00, -7.4268e-01,  2.5214e-01, -9.3020e-01, -1.6215e+00,\n",
      "          9.0063e-01,  1.3538e-01,  2.4855e-01, -7.0899e-02, -6.7829e-02,\n",
      "          4.9462e-01,  1.9735e+00, -2.0417e-02,  1.0404e-01,  1.5647e-01,\n",
      "          2.7965e-01,  1.2653e+00, -7.2166e-01,  1.6199e-01,  7.5041e-01,\n",
      "         -4.8130e-01, -8.0420e-01,  5.6812e-01,  5.9994e-02, -1.7911e+00,\n",
      "          1.1018e-01,  5.3416e-02, -1.5309e-01, -2.2220e+00, -1.5202e+00,\n",
      "          1.0298e+00,  8.2396e-01,  2.3634e-01,  4.0032e-01,  8.3266e-01,\n",
      "          1.0725e+00, -9.3680e-01,  7.4017e-01, -1.9606e-01,  4.5736e-01,\n",
      "         -6.2050e-01, -3.2014e-01,  2.6151e-02,  9.5278e-01, -6.7710e-01,\n",
      "          7.5752e-01,  2.0143e+00,  8.9207e-01,  2.1471e-01, -8.2646e-02,\n",
      "         -2.6492e-01, -5.6239e-01,  1.2941e-01, -1.3437e+00, -9.0485e-01,\n",
      "          2.9089e-01,  1.2565e+00, -2.6057e-01,  1.0245e-01,  1.5826e+00,\n",
      "          6.5248e-01,  1.1393e+00,  7.8090e-01, -1.2426e+00,  1.6002e-01,\n",
      "         -1.6905e-01,  4.5656e-01, -4.2009e-01, -4.3024e-01,  3.2020e-01,\n",
      "         -1.4621e+00,  9.8436e-01,  4.6298e-01, -1.2426e+00, -9.9091e-01,\n",
      "          3.3634e-01,  1.0522e+00, -1.9606e+00,  8.0498e-01, -1.7649e-01,\n",
      "          1.3163e+00, -7.4774e-02, -2.4333e-01,  1.6905e-01, -1.1381e+00,\n",
      "          8.8909e-01, -7.8616e-01, -5.7004e-01, -5.0481e-03,  7.5165e-01,\n",
      "         -1.1069e+00,  9.7666e-01, -2.4210e-01, -9.9361e-02,  2.1017e+00,\n",
      "         -6.9018e-01,  1.5715e-02,  1.8609e-01, -1.2118e-01, -1.3359e-01,\n",
      "         -7.4945e-01, -4.6201e-01,  8.8483e-01, -9.0029e-02,  7.4948e-01,\n",
      "          2.0147e+00, -3.9026e-01,  3.5386e-01,  1.0673e+00, -9.8100e-01,\n",
      "         -8.1573e-01,  5.0172e-01, -1.0720e+00,  1.1333e+00, -1.5628e-01,\n",
      "          8.3683e-01, -7.0743e-01, -4.9003e-02,  3.6272e-01, -4.6486e-01,\n",
      "         -1.1245e+00, -4.1071e-01, -1.2152e-01, -1.4011e+00, -2.5361e-01,\n",
      "          5.2090e-01, -2.8749e+00,  2.7170e-01, -5.7446e-01, -7.5743e-02,\n",
      "         -1.1629e+00, -1.3754e+00, -1.0231e+00,  1.1137e+00, -2.7334e-02,\n",
      "         -2.4508e-01, -8.1204e-02, -7.7649e-01,  4.8697e-01,  2.8175e-02,\n",
      "          5.3120e-01,  2.9674e-01,  1.1202e+00, -2.0702e+00, -5.7830e-01,\n",
      "          1.2020e+00, -1.6113e+00,  4.6309e-01,  8.4288e-01,  1.5826e+00,\n",
      "         -1.0782e+00, -6.2734e-01, -4.1390e-01,  7.0913e-01, -1.8232e-01,\n",
      "         -1.2168e+00,  1.0190e+00, -3.7394e-01, -2.4045e-01,  1.4859e-01,\n",
      "          6.0511e-01, -4.5473e-01, -1.1997e-01, -9.7050e-01, -6.8761e-01,\n",
      "         -1.1273e+00, -7.9451e-01,  1.8909e-01,  2.9002e-01,  7.3133e-01,\n",
      "         -5.2690e-01, -7.9351e-01,  2.2857e-01, -1.6265e+00, -1.9188e-01,\n",
      "         -3.1878e-02,  1.8180e+00, -3.9685e-01,  1.3214e+00, -4.2122e-03,\n",
      "          1.4361e+00,  1.8831e+00,  6.3697e-02, -1.0495e+00, -8.3338e-01,\n",
      "         -1.0730e-01, -6.7859e-01,  1.8191e+00,  1.0849e+00, -7.2962e-02,\n",
      "          1.1383e+00, -1.1953e+00, -2.1427e+00, -4.6342e-01, -8.7534e-01,\n",
      "         -8.5689e-01, -1.5230e-01, -3.2956e-01,  7.6228e-01,  1.0469e-01,\n",
      "         -5.1613e-01,  1.2047e+00, -2.5228e-01, -1.9602e-01,  2.5802e+00,\n",
      "          3.9419e+00, -4.0724e-01, -4.2548e-01,  2.1695e-01, -1.6713e-02,\n",
      "          2.0783e+00, -9.0474e-01, -1.6999e-01, -1.0995e+00,  7.1961e-01,\n",
      "          5.7661e-01, -6.4909e-01, -5.2438e-01,  2.6345e-01,  4.8071e-01,\n",
      "          1.5652e+00,  1.5406e+00, -9.6846e-01,  1.4637e+00, -3.4647e-01,\n",
      "          5.3043e-01,  1.2748e+00, -9.5652e-01,  1.7468e+00, -1.8261e+00,\n",
      "          1.2777e+00,  6.7490e-01,  1.6988e-01, -2.5099e-01, -9.5547e-01,\n",
      "          2.9388e-01,  8.2380e-01,  3.5376e-01, -1.1283e+00, -3.1981e-02,\n",
      "         -1.5629e+00, -1.1134e+00,  1.4797e-01,  1.2904e-01, -1.7777e+00,\n",
      "          4.7249e-01,  8.4635e-01, -2.7086e-01, -1.6132e+00, -9.1657e-01,\n",
      "          2.4574e-01,  8.6881e-01,  2.0570e-01, -3.3039e-01,  2.7266e-01,\n",
      "         -2.1320e+00, -6.5162e-01, -7.2834e-01, -6.9880e-01, -1.0520e+00,\n",
      "          1.0305e+00, -1.4099e+00,  2.0359e+00,  3.4161e-01, -8.4469e-01,\n",
      "          5.3703e-01, -1.9203e+00,  9.5322e-02,  8.1092e-02,  5.3471e-01,\n",
      "         -5.4841e-01, -9.7121e-02, -5.6298e-01, -7.1503e-01,  3.1086e-01,\n",
      "         -1.2850e+00,  1.3569e+00, -1.7994e+00, -1.3145e+00,  2.7628e-01,\n",
      "          2.9096e-01, -3.5161e-01,  3.1105e+00, -2.2391e-01,  1.5601e+00,\n",
      "         -2.0646e+00,  3.7743e-01,  4.7035e-01,  6.9814e-01,  1.2222e-01,\n",
      "         -2.2751e+00, -1.9002e-01, -5.9816e-01,  1.4947e+00,  1.1558e+00,\n",
      "         -5.5146e-01,  7.4919e-01,  4.6668e-01,  2.9293e+00, -1.4530e+00,\n",
      "         -6.8430e-01,  1.0356e+00, -4.0649e-01, -3.8867e-01,  9.3316e-01,\n",
      "         -1.1664e+00, -6.9495e-01, -5.2783e-02, -3.6176e-01,  3.3691e-01,\n",
      "         -9.3940e-01,  4.8411e-02,  8.8681e-01,  7.0310e-01, -3.8796e-01,\n",
      "         -1.3946e+00, -1.4356e+00,  1.0125e+00, -2.0213e+00, -2.3419e-01,\n",
      "         -2.0075e+00, -1.0853e+00,  1.1483e+00, -1.9723e-02, -2.5546e-01,\n",
      "          2.2739e-01,  1.3569e+00,  2.2190e-01, -1.7612e-01,  9.1605e-01,\n",
      "          3.3055e-01,  1.5569e+00,  1.0368e+00,  1.2734e+00, -1.1985e+00,\n",
      "          5.1350e-02, -5.6379e-01, -1.1148e-01,  2.3184e+00, -7.8858e-01,\n",
      "          3.3263e-01, -1.9015e+00, -5.5203e-01,  1.2143e-01,  1.3665e-01,\n",
      "         -1.2796e+00,  1.9046e+00, -1.0906e+00,  1.1835e+00,  6.8885e-02,\n",
      "         -1.4003e-01, -3.7474e-01, -3.4741e-02,  2.2094e+00, -1.3882e+00,\n",
      "         -3.6815e-01,  1.5369e+00,  1.5148e+00, -1.3668e-01, -4.7703e-01,\n",
      "          2.3907e+00, -3.0035e-02,  3.4391e+00, -2.2051e+00, -9.7276e-01,\n",
      "          4.7286e-01, -1.1970e+00, -7.3249e-01, -1.3389e-01, -1.1751e+00,\n",
      "          1.5160e-01, -5.0709e-01,  1.3905e-01, -5.8961e-01,  3.3400e-01,\n",
      "          4.0067e-01, -2.6172e-01, -2.1804e-01, -2.1735e-01,  6.2858e-01,\n",
      "          1.5342e+00,  2.6885e-01, -8.8785e-01,  8.8219e-02, -3.5469e-01,\n",
      "          9.0322e-01, -2.1145e-01,  8.4574e-02,  1.6031e+00, -9.3139e-01,\n",
      "         -1.0302e+00, -2.2422e+00, -3.5217e-01,  1.4732e+00,  4.3311e-01,\n",
      "          7.7926e-02, -1.2573e+00, -1.8129e-01,  1.5392e+00, -1.5729e+00,\n",
      "          4.8182e-01,  1.8264e+00, -2.5123e+00,  3.4495e-02, -4.1335e-01,\n",
      "         -7.5118e-01, -1.1915e+00, -9.2414e-01,  1.8531e+00, -9.5415e-01,\n",
      "          6.7062e-01,  1.0924e+00,  2.2875e-01,  4.1846e-01,  2.6377e-01,\n",
      "         -4.8433e-01,  3.9082e-01,  1.1531e+00, -1.1964e-01, -1.7117e-01,\n",
      "          1.0844e+00, -4.1498e-01, -2.4390e+00,  1.5124e+00,  5.8649e-01,\n",
      "         -7.5307e-01,  3.0809e-01,  1.6439e-01,  8.1603e-01, -4.9705e-01,\n",
      "          1.6408e+00, -3.7288e-02,  8.6084e-01,  1.0015e+00,  1.3280e+00,\n",
      "         -4.0917e-01, -1.3924e+00, -4.9949e-01,  9.3047e-01, -1.9210e+00,\n",
      "         -9.9546e-01,  1.2831e+00,  1.0112e+00,  4.8962e-01, -1.0793e+00,\n",
      "          7.2258e-01, -1.7020e+00, -1.3499e+00,  1.0323e+00, -3.7006e-01,\n",
      "          1.0330e+00,  5.7742e-01, -2.5102e-01,  1.4535e+00, -1.9640e+00,\n",
      "         -1.3809e+00, -5.3581e-02,  1.6171e-01, -1.2948e+00,  6.1704e-01,\n",
      "          2.2176e+00,  1.7796e+00,  3.3418e-01,  4.4286e-01,  1.5830e+00,\n",
      "         -1.1167e+00, -5.5024e-01,  6.4665e-01,  6.2766e-01, -1.0762e+00,\n",
      "          8.7040e-01,  9.7243e-01, -1.0563e+00,  2.0366e-01,  1.3558e-02,\n",
      "         -1.1524e-01, -7.0520e-01, -1.8352e+00,  3.6028e-03,  7.5616e-01,\n",
      "          8.6121e-01, -5.0268e-01,  4.5091e-01, -1.4159e+00, -1.8713e+00,\n",
      "          2.3445e+00, -4.0895e-01, -4.2284e-01,  2.2491e-01,  2.6603e-01,\n",
      "          1.0949e+00,  8.6343e-01,  1.2559e+00,  4.1765e-01, -1.9190e-01,\n",
      "         -1.4853e+00, -5.5343e-01,  5.1974e-02,  9.6415e-01,  1.7517e+00,\n",
      "          7.0947e-02,  1.0294e+00,  4.9019e-01, -6.2297e-01, -1.6871e-01,\n",
      "         -1.0194e+00,  1.3064e-01,  1.3643e+00, -3.4756e-01, -4.8306e-02,\n",
      "         -3.9079e-01,  8.2430e-01,  7.0013e-01,  5.2156e-01, -1.1062e-01,\n",
      "          2.0912e-01, -8.0724e-01,  1.0371e-01, -4.6987e-01, -4.8120e-01,\n",
      "         -1.5408e-01, -1.5948e-01, -3.1025e-01, -1.0193e+00,  8.3793e-01,\n",
      "          4.1431e-01,  1.3016e-01, -5.0939e-01, -5.5939e-01,  1.5866e+00,\n",
      "         -1.6534e-01,  1.9274e-01,  4.4754e-01, -1.5054e+00, -1.6743e+00,\n",
      "         -1.2192e-01,  2.2343e-01, -3.5040e-01,  5.5761e-01, -1.0655e+00,\n",
      "         -1.3743e+00,  5.9194e-01, -6.1441e-01,  3.7863e-01, -1.5021e+00,\n",
      "          9.3464e-02,  1.9837e+00,  1.8657e-01,  7.0812e-01,  1.8251e-01,\n",
      "         -9.5839e-01, -4.6373e-01, -2.0777e+00,  8.2242e-01, -2.0312e+00,\n",
      "         -5.7776e-01, -1.1866e-01,  1.4913e-02,  5.1561e-02, -3.9810e-01,\n",
      "          1.6594e-01, -3.4697e-01, -4.6824e-01,  7.5474e-01,  1.0881e+00,\n",
      "          8.5827e-01, -1.2801e+00, -2.3614e-01,  7.3262e-01, -5.5468e-02,\n",
      "         -8.3044e-01,  1.3773e+00,  3.4094e-01, -1.8415e+00, -5.9593e-01,\n",
      "          4.0230e-01,  3.8149e-01,  9.0850e-02, -1.6760e+00, -1.4280e+00,\n",
      "         -1.0958e-01,  3.7094e-01,  3.2377e-01, -1.6333e-01,  8.4945e-01,\n",
      "          2.9050e-01,  8.2465e-02,  1.0035e+00, -7.6965e-01, -7.2521e-02,\n",
      "          2.0128e+00,  5.2892e-01,  1.9360e-01,  2.6917e-01, -1.5027e+00,\n",
      "          1.0298e+00,  6.0611e-01, -1.0171e+00,  7.1154e-01,  5.9679e-01,\n",
      "         -1.5444e-01, -2.9987e-01, -6.7381e-01, -1.4535e+00,  2.6879e-02,\n",
      "         -4.8506e-01, -6.9716e-01, -1.3477e+00,  6.3094e-01, -6.4836e-01,\n",
      "         -8.7813e-03,  2.7202e+00,  5.6459e-01,  5.7411e-01,  1.1230e-01,\n",
      "         -5.8899e-01, -8.0392e-01,  2.0750e-01, -4.9942e-02,  2.8423e-01,\n",
      "          5.0471e-02, -2.7941e-01,  1.4302e-01, -4.6492e-01, -5.8890e-01,\n",
      "          1.1986e-01,  9.4271e-01,  3.7284e-02, -3.2270e-01,  6.3746e-01,\n",
      "          1.3037e+00,  5.0905e-01, -2.7957e-01, -1.3624e-01,  1.9576e-01,\n",
      "         -4.5283e-01, -8.8886e-01, -4.2744e-02, -7.5379e-01, -2.2679e-01,\n",
      "         -1.7522e-01,  9.9922e-01, -1.0352e+00,  9.3546e-01,  1.6807e+00,\n",
      "          2.9465e-01, -5.3428e-01, -8.6187e-01, -3.7340e-01, -9.7272e-01,\n",
      "         -6.5673e-01,  4.6481e-01,  2.5406e-01, -9.4712e-01, -1.3922e-01,\n",
      "          2.1644e+00, -1.4882e+00, -5.1572e-01, -1.3731e+00,  9.0656e-01,\n",
      "          3.8867e-01,  1.5515e+00, -1.9572e+00, -5.3156e-01,  1.6460e+00,\n",
      "          1.2666e-01, -1.7464e-01, -1.1346e+00,  2.0165e-01,  1.9140e+00,\n",
      "          8.2511e-01, -6.1509e-01,  7.5000e-01, -1.7011e-02, -1.2979e-01,\n",
      "          1.4018e+00,  1.1463e+00, -1.0490e+00,  8.8353e-01, -2.6842e-01,\n",
      "          8.8508e-02,  1.3226e+00,  1.3569e+00,  8.7654e-01,  1.6339e-01,\n",
      "         -6.2447e-01, -1.4906e+00, -4.3996e-01,  7.3962e-01,  2.3436e+00,\n",
      "          3.3583e-01, -5.7066e-01, -5.6982e-01,  2.7107e-01,  7.1553e-01,\n",
      "         -5.9539e-01,  7.2340e-01, -7.6663e-02, -1.5923e-01, -5.9997e-01,\n",
      "          8.1662e-01, -2.1109e+00,  1.0855e+00, -5.6445e-01,  5.3901e-01,\n",
      "          9.5636e-01, -1.0063e+00,  1.4985e+00,  5.5566e-01, -6.6794e-01,\n",
      "         -1.6065e-01, -1.2440e+00,  7.3793e-01,  5.3742e-01,  3.3873e-01,\n",
      "          9.2764e-01, -2.8035e+00,  1.8804e+00, -2.8906e-01, -9.3299e-01,\n",
      "         -2.5744e+00, -1.7403e+00,  4.1440e-01,  4.0025e-01, -7.1185e-01,\n",
      "          1.6351e+00,  7.0569e-02, -2.8294e-02,  2.1137e+00, -1.8776e+00,\n",
      "          4.1562e-02, -8.5051e-01, -1.2624e+00, -5.0630e-02,  3.8394e-01,\n",
      "          3.3773e-01,  1.8218e-01, -2.8951e-01,  5.9032e-01, -8.6996e-01,\n",
      "          5.2495e-01,  3.0928e-01,  1.4316e+00, -9.7671e-01,  2.6953e+00,\n",
      "         -7.9682e-02, -1.9178e+00, -4.6634e-01, -2.3333e+00, -1.3123e+00,\n",
      "         -6.5786e-02,  1.9661e+00,  6.0784e-01,  1.8333e+00, -1.1697e-02,\n",
      "         -1.2598e-01, -1.2318e+00,  1.4048e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for step 0\n",
      "tensor([[-0.0595]], grad_fn=<ToCopyBackward0>)\n",
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 1\n",
      "Batch\n",
      "tensor([[   0, 3226,  347, 5214,  347, 3226,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 4.3791e-01, -1.8227e+00, -1.5983e+00, -1.0462e-01,  2.0537e-01,\n",
      "         -1.8625e+00, -3.0195e+00, -1.5606e+00,  2.9451e-01, -5.0390e-01,\n",
      "          1.3679e+00,  3.3341e-01, -1.7421e-01, -4.7681e-01, -1.1221e+00,\n",
      "          6.0984e-01,  2.7306e+00,  7.8440e-01, -1.1779e+00, -2.6416e-02,\n",
      "         -4.6309e-01,  1.3808e+00, -7.2673e-01,  9.4063e-01,  1.0520e+00,\n",
      "          2.4639e-01,  2.0586e-01, -2.9791e-01,  4.2479e-01,  1.0606e+00,\n",
      "         -5.2115e-01, -1.2973e-01,  1.7814e+00,  5.7827e-01, -9.6649e-01,\n",
      "          1.4039e+00,  4.7600e-01,  2.9593e-01, -2.1452e+00,  9.2157e-01,\n",
      "          2.0323e+00,  6.8008e-01, -3.6263e-01,  1.7366e-02,  2.6814e-01,\n",
      "          1.5287e+00, -1.2206e+00,  9.4694e-01, -1.6817e+00, -2.1987e-01,\n",
      "         -5.0116e-01, -6.7292e-01, -2.1306e-01,  1.7564e+00, -4.3530e-01,\n",
      "          1.9650e+00,  1.0759e+00, -2.7774e-01,  2.6982e-02,  6.7752e-02,\n",
      "          9.8324e-01, -2.2594e-01, -2.3844e-01, -6.7413e-01,  4.5286e-01,\n",
      "         -2.4205e-03,  1.2012e+00, -4.1082e-02, -1.6279e-02,  1.1784e+00,\n",
      "          3.7161e-01,  2.0041e-01,  4.4468e-02, -9.0600e-01, -3.6312e-01,\n",
      "         -5.8681e-01, -9.0760e-01,  2.5027e-01,  2.5980e-01,  7.0430e-01,\n",
      "         -1.1489e+00,  1.1831e+00,  9.4024e-01,  1.6346e-01, -4.8697e-01,\n",
      "          4.1274e-01,  2.4656e-01, -8.4013e-01,  8.7582e-01,  3.1638e-01,\n",
      "          1.3791e-01,  1.4113e-01,  6.0020e-01, -2.8957e-01, -1.2515e+00,\n",
      "          1.5522e-01, -4.6334e-01, -1.1697e+00, -3.9078e-01,  1.7084e+00,\n",
      "         -1.1047e+00, -1.4479e-01,  1.9199e-01,  1.9539e+00,  1.4524e+00,\n",
      "         -4.4790e-01,  1.2471e+00,  5.5667e-01, -3.8212e-01, -1.1016e+00,\n",
      "         -1.3763e-01, -9.1328e-01,  2.1729e+00, -7.5508e-01,  1.5982e+00,\n",
      "          1.2356e+00, -4.3478e-01, -1.4672e-01,  4.3004e-01, -6.4151e-01,\n",
      "         -4.1232e-01,  7.4642e-02, -1.3049e+00,  1.5720e+00,  1.0971e+00,\n",
      "         -3.7975e-01,  2.4803e-01, -5.8669e-01,  5.9770e-01, -5.1734e-01,\n",
      "         -4.8344e-01, -1.7794e-02, -2.5757e-01, -1.2493e+00,  5.9766e-01,\n",
      "          1.9636e-01, -3.4417e+00, -1.4942e-01, -1.8553e-02,  6.9558e-01,\n",
      "         -1.2631e+00,  4.6145e-01, -8.5960e-01,  1.4254e+00,  6.9985e-01,\n",
      "          4.9880e-01,  7.3765e-01, -1.2655e+00, -4.6377e-01,  4.2358e-01,\n",
      "          1.5992e+00, -3.3186e-01,  3.1466e-01, -1.6028e+00,  2.2360e-02,\n",
      "          9.5051e-01, -1.8580e-01, -4.0182e-01,  9.8534e-02, -7.9988e-01,\n",
      "         -1.0168e+00,  5.4481e-01, -5.3583e-01,  9.2202e-01,  4.4908e-01,\n",
      "         -9.7262e-01,  2.1012e-02,  1.3819e+00,  2.1940e-01,  6.1534e-01,\n",
      "          1.5925e+00,  2.6396e-01, -7.1051e-01, -2.3668e+00, -1.2780e+00,\n",
      "         -1.8984e-01, -1.4515e+00, -3.5377e-02,  1.2395e+00,  2.2732e-02,\n",
      "         -6.5474e-02, -1.0820e+00, -2.4813e-01, -1.9536e+00,  9.5771e-02,\n",
      "         -1.1648e+00,  1.2190e+00,  2.8602e-01,  2.1096e-02,  9.9990e-01,\n",
      "          2.8120e+00,  2.9263e-01,  1.0704e+00, -9.2671e-01, -1.4294e+00,\n",
      "         -2.5109e-01, -1.3173e+00,  8.2891e-01,  1.7467e+00, -6.5686e-02,\n",
      "          2.0293e+00, -4.5542e-01, -1.8455e+00,  8.5809e-01, -8.4128e-01,\n",
      "         -2.2449e-01, -7.4229e-01, -1.0123e-01,  1.3187e+00, -5.3363e-01,\n",
      "          1.5995e-01,  8.8332e-01, -8.5857e-02, -1.2230e+00,  1.2948e+00,\n",
      "          1.9542e+00,  5.1534e-01, -1.3105e+00, -1.7048e-01, -8.4212e-01,\n",
      "          1.8243e+00, -1.2651e+00, -3.2294e-01, -1.0758e+00,  5.3348e-01,\n",
      "          1.8473e-01,  2.4576e-01, -1.2871e+00, -5.0117e-01,  4.3928e-01,\n",
      "          1.5648e+00,  1.6594e+00,  7.9980e-02, -2.4296e-01, -1.0743e+00,\n",
      "          7.9091e-01,  1.2070e+00, -7.3882e-01,  1.9715e+00, -1.9544e+00,\n",
      "          4.7712e-01, -1.5154e-01,  6.2324e-01,  2.3485e-01, -7.0926e-01,\n",
      "         -2.4820e-01,  3.7004e-01, -1.5784e-01, -8.2785e-01, -1.7367e-01,\n",
      "         -8.0572e-01, -1.3609e+00,  1.5161e-01, -8.6546e-02, -2.7284e+00,\n",
      "          6.8701e-01, -4.5570e-01, -6.1068e-01, -8.8486e-01, -5.4031e-01,\n",
      "          2.7904e-01,  1.6262e-01,  1.3079e+00, -1.1562e+00, -1.8723e+00,\n",
      "         -1.3306e+00, -5.8488e-01, -1.8556e+00, -5.0912e-02,  2.6967e-01,\n",
      "          1.3144e+00, -2.3902e+00,  3.4958e-01, -4.4270e-01, -6.9355e-01,\n",
      "          1.0570e+00, -2.3617e+00,  6.7092e-01, -1.9680e-01,  1.1206e+00,\n",
      "         -2.8195e-01,  3.5227e-02, -4.3989e-01,  5.2991e-01,  3.6731e-02,\n",
      "         -1.9051e+00,  1.9234e+00, -1.5895e+00, -9.6936e-01, -2.8007e-01,\n",
      "         -4.0324e-01,  4.3025e-01,  2.4832e+00, -2.3561e-01,  2.0218e+00,\n",
      "         -1.4570e+00,  8.6026e-01,  1.7469e-01,  1.8822e-01, -5.9454e-01,\n",
      "         -2.0660e+00,  6.7517e-01, -6.9615e-01, -2.1748e-01,  2.4623e-01,\n",
      "          5.5902e-02,  7.6954e-01,  1.2725e-01,  1.6551e+00, -1.0097e+00,\n",
      "         -4.9893e-01,  9.0060e-01,  6.9221e-03, -7.7636e-02, -7.8233e-01,\n",
      "         -1.7758e+00, -4.8876e-01, -5.3755e-01, -2.6764e-01,  3.3944e-01,\n",
      "         -1.1415e+00,  1.8559e-01, -2.8368e-02,  7.3285e-01,  1.5516e+00,\n",
      "         -1.8886e+00, -1.7968e+00,  3.7820e-01, -1.9275e+00,  4.6679e-01,\n",
      "         -1.1643e+00, -2.5130e+00,  4.2452e-01, -1.8874e-01,  4.0817e-01,\n",
      "          5.3245e-01,  7.8094e-01,  7.5479e-01,  1.1519e+00, -2.5854e-01,\n",
      "         -5.3611e-03,  4.7637e-02,  2.1437e+00,  2.0314e+00, -1.3916e-02,\n",
      "          5.3800e-01,  1.0053e+00, -1.0206e-01,  1.6148e+00,  3.8634e-01,\n",
      "          8.6699e-01, -9.1047e-01,  2.8078e-01,  4.9610e-01,  1.9247e-01,\n",
      "         -1.9634e+00,  2.0085e+00, -8.8510e-01,  1.3407e+00, -9.2426e-01,\n",
      "          6.7692e-01,  9.2949e-03, -1.2655e+00,  6.9271e-01, -1.6985e+00,\n",
      "         -1.3805e+00,  1.5641e+00,  1.2222e+00, -1.3374e-02, -4.6317e-01,\n",
      "          6.9467e-01, -1.8006e-03,  2.2665e+00, -2.3225e+00, -1.1218e+00,\n",
      "          1.2422e+00,  2.1754e-01, -7.3831e-02, -6.8681e-01, -1.6353e+00,\n",
      "          3.4208e-01, -1.0284e+00,  7.5139e-01, -2.1414e-01,  5.2900e-01,\n",
      "          3.7908e-01, -6.5107e-01,  6.1757e-01, -7.5106e-01,  1.0487e+00,\n",
      "          8.2757e-01,  2.5090e-01, -2.2905e+00,  8.7484e-01, -1.9413e+00,\n",
      "          1.8105e+00,  5.7403e-01,  2.8260e-01,  1.5600e+00, -7.8114e-01,\n",
      "         -1.6133e+00, -1.3786e+00, -2.3723e-01,  1.0931e+00,  6.9958e-01,\n",
      "         -5.0267e-01, -7.1381e-01, -1.3535e-01,  2.1104e+00, -5.3560e-01,\n",
      "          1.3338e-01,  1.1739e+00, -2.5181e+00, -7.1417e-01,  4.0189e-01,\n",
      "         -5.5935e-01, -7.5488e-01, -1.0221e+00,  1.8697e+00, -2.0205e-01,\n",
      "          9.8793e-01,  6.9156e-01,  7.3147e-01,  4.8260e-01, -7.7198e-01,\n",
      "         -1.3233e+00,  3.7271e-01,  1.2641e+00, -1.3659e-01, -6.8327e-01,\n",
      "          5.3449e-01, -7.3831e-01, -1.4615e+00,  1.4865e+00,  5.0906e-01,\n",
      "         -1.6066e+00,  6.5149e-01, -9.9016e-01,  8.5461e-01,  6.0035e-01,\n",
      "          7.1110e-01, -8.8223e-02, -5.8485e-02,  3.2256e-02,  2.1038e+00,\n",
      "          3.4130e-01, -9.8846e-01,  1.1124e+00,  1.2859e+00, -1.2897e+00,\n",
      "         -2.3866e-02,  6.8013e-01,  2.6932e+00,  4.6336e-02, -1.3817e+00,\n",
      "          1.2649e+00, -1.0628e+00, -5.2653e-01,  1.2904e+00, -6.1002e-01,\n",
      "         -6.3345e-01, -7.4058e-02, -1.4854e+00,  1.4483e+00, -1.5150e+00,\n",
      "         -7.2021e-02,  2.0863e-01,  3.4755e-01,  1.7001e-02, -5.1476e-01,\n",
      "          1.8928e+00,  1.8058e+00,  1.5034e+00,  1.2069e-02,  4.5765e-01,\n",
      "          7.9751e-01,  1.1441e-01,  1.3748e+00,  9.9392e-01,  2.2371e-01,\n",
      "          6.4389e-02,  5.8693e-01, -7.4479e-01,  5.6188e-01, -5.0950e-02,\n",
      "         -8.6778e-01,  1.8602e-01, -2.2598e+00,  2.1115e-01, -3.2963e-01,\n",
      "         -4.7839e-01,  1.9843e-02,  1.0058e+00, -8.5683e-01, -2.0361e+00,\n",
      "          5.7924e-01,  2.7202e-02, -1.5631e-01,  2.7570e-02, -1.5767e+00,\n",
      "          5.3257e-01,  1.1271e+00,  7.7508e-01, -2.7197e-01, -4.5467e-01,\n",
      "          3.1853e-03, -2.4618e-01, -3.7753e-02, -2.1767e-01,  1.8133e-01,\n",
      "          1.2264e+00,  1.7823e+00,  2.3539e-01, -1.0881e+00, -4.6080e-01,\n",
      "         -6.8037e-01,  5.2835e-01,  1.6810e+00,  1.0133e+00,  6.3238e-01,\n",
      "         -7.3029e-01,  1.1481e-01,  1.5395e+00,  6.4278e-01, -2.1116e-01,\n",
      "         -4.3828e-01, -9.1289e-01,  8.1981e-01, -4.2375e-01, -3.2720e-01,\n",
      "         -8.2339e-01,  2.9377e-01, -1.8734e+00, -8.0026e-01,  5.8117e-01,\n",
      "          5.5886e-01,  3.1138e-01, -2.0615e-01, -4.8104e-01,  1.4235e+00,\n",
      "         -3.9636e-01,  2.4344e-01,  8.8064e-01,  5.4777e-01, -3.6426e-01,\n",
      "          2.1892e+00, -7.1667e-01,  4.7207e-01,  1.9750e-02, -1.7890e-01,\n",
      "         -8.2786e-01, -9.8814e-01,  5.4562e-01,  3.9325e-01, -2.2730e-01,\n",
      "          5.9603e-02,  2.0304e+00,  4.6137e-01,  4.5389e-01,  1.0059e+00,\n",
      "         -5.6298e-01, -4.4021e-01, -1.7055e+00,  2.8243e-01, -9.6288e-01,\n",
      "         -4.1154e-01,  2.3720e-01, -5.5162e-01, -1.0207e-01, -6.5574e-01,\n",
      "         -4.6963e-01,  2.2188e-01,  5.4488e-02,  2.7707e-01,  5.1050e-01,\n",
      "          7.2633e-01, -1.0471e+00, -2.2914e-01,  4.5703e-01,  6.3479e-01,\n",
      "          1.1331e-01, -1.9914e-01, -4.6456e-01, -1.7183e+00, -4.7135e-01,\n",
      "         -2.8608e-01, -6.8349e-01, -6.2720e-02, -1.2336e+00, -9.7282e-01,\n",
      "         -9.8530e-01, -1.0600e+00,  9.0051e-01,  3.9063e-02,  2.2562e+00,\n",
      "          3.3588e-01, -4.1008e-01,  2.3153e+00, -2.1235e+00, -1.0775e+00,\n",
      "          1.7088e+00,  9.4397e-01, -9.8691e-01,  3.3534e-01, -1.5951e+00,\n",
      "         -6.2076e-01,  3.7510e-01, -8.0415e-01,  1.3867e+00, -3.6695e-01,\n",
      "         -3.2160e-01,  1.1591e+00,  3.7102e-01, -4.4227e-02, -3.2448e-01,\n",
      "         -5.5863e-03, -1.1962e+00, -1.8937e+00,  9.8386e-01, -4.7828e-01,\n",
      "          5.8592e-01,  1.2333e+00,  3.1541e-01,  1.1676e+00,  4.3974e-01,\n",
      "         -6.1665e-01, -8.8769e-02, -1.2100e-01, -6.2152e-01,  4.0959e-01,\n",
      "          4.3805e-01, -4.3552e-01,  7.4379e-01, -2.8641e-01, -4.5030e-01,\n",
      "          6.6593e-01,  7.0440e-01,  4.0933e-02, -9.2255e-01,  1.0010e-01,\n",
      "          4.1776e-01,  1.4319e+00, -5.5619e-01,  8.1591e-02, -7.9605e-01,\n",
      "         -1.9860e-01,  4.1022e-03, -1.6642e-01, -1.9032e+00, -1.7403e-01,\n",
      "          1.2661e+00,  1.6045e+00,  1.1057e-01,  1.1876e+00,  8.5840e-01,\n",
      "          4.9453e-01,  4.9996e-01,  1.1122e+00,  1.4350e-01, -6.1136e-01,\n",
      "         -2.4312e+00,  7.7416e-01, -1.5415e-01, -1.7383e+00,  4.9807e-01,\n",
      "          1.3417e+00, -1.5219e+00, -9.5547e-03, -1.5071e+00,  9.4373e-01,\n",
      "         -5.4011e-01,  1.1613e+00, -1.2252e+00, -8.7478e-01,  1.0217e+00,\n",
      "          4.2580e-01,  3.1222e-02, -1.6576e+00, -7.6727e-01,  2.2721e-01,\n",
      "         -5.2650e-01, -5.5924e-01,  9.4368e-01, -4.1771e-01, -4.9233e-01,\n",
      "          8.5118e-01,  9.4563e-01, -1.0004e+00, -2.3417e-01,  1.9063e-01,\n",
      "          7.5303e-02,  7.1779e-01,  1.9017e+00,  8.5249e-01,  6.8826e-01,\n",
      "         -1.6108e+00, -2.5112e+00,  8.5320e-03,  1.9636e-01,  2.0872e+00,\n",
      "          8.4970e-01, -1.3491e+00, -6.5375e-01,  9.5928e-01, -9.1457e-01,\n",
      "         -8.2182e-01, -3.6139e-01,  6.7005e-01, -8.7972e-01,  1.1078e-01,\n",
      "          3.5018e-01, -2.0787e+00,  1.2669e+00, -7.0009e-01, -3.1959e-01,\n",
      "          1.7513e-01, -1.9520e-01,  1.3522e+00, -6.4088e-01, -4.2254e-02,\n",
      "         -1.6473e-01, -6.4118e-01, -4.4395e-02,  1.3450e-01,  1.1052e-02,\n",
      "         -1.1821e-01, -2.2792e+00,  2.8124e+00, -1.0868e-02, -6.3110e-01,\n",
      "         -4.7400e-01, -3.9329e-01, -5.7199e-01, -2.7565e-03, -4.7139e-01,\n",
      "          1.8538e+00, -8.4049e-01,  5.9945e-01,  9.3328e-01, -8.1568e-01,\n",
      "          4.5607e-01, -1.6227e+00, -8.0773e-02, -2.1587e-01,  6.1676e-01,\n",
      "          4.1958e-01,  4.0271e-01, -3.3334e-01,  4.6391e-01, -1.9395e+00,\n",
      "          7.7442e-01,  3.9378e-01,  1.4893e+00, -3.6485e-01,  1.3978e+00,\n",
      "         -4.6260e-01, -1.5623e+00, -7.5558e-01, -1.5011e+00, -1.4292e+00,\n",
      "          3.5255e-01,  1.3258e+00,  3.4805e-01,  1.8590e+00, -6.4500e-01,\n",
      "         -3.6469e-01, -8.6590e-01,  1.9486e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 1\n",
      "tensor([[1.8987]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 2\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347,  134,  347,  347,  347, 1640, 3226,   43,  347,\n",
      "          134,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 4.4870e-01, -2.4372e+00, -2.5528e-01,  4.4155e-01,  3.7620e-01,\n",
      "         -1.7947e+00, -3.0869e+00, -1.2739e+00,  1.4585e-01,  1.8232e-01,\n",
      "          5.3203e-01,  4.6896e-01, -1.9162e-01, -1.9774e+00, -5.1410e-01,\n",
      "          2.9778e-01,  2.8210e+00,  9.6749e-01, -3.9496e-01,  6.5448e-01,\n",
      "          2.3112e-01,  1.1507e+00, -8.5486e-02,  7.2702e-01,  2.6685e-01,\n",
      "          8.9136e-01,  3.8325e-01, -3.2944e-01, -9.8874e-01,  8.3866e-02,\n",
      "         -1.0548e+00, -8.4689e-01,  2.6054e-01,  2.7950e-01, -8.9521e-02,\n",
      "          1.4434e+00,  7.0003e-01,  7.3724e-01, -2.2174e+00,  2.0201e-01,\n",
      "          1.7791e+00,  3.7002e-02, -5.4111e-01, -4.7920e-01,  6.7997e-02,\n",
      "          1.2044e+00, -2.0231e+00,  1.0609e+00, -3.0530e-01, -1.0622e+00,\n",
      "         -8.3394e-03,  2.1708e-03,  1.8356e-02,  5.4438e-01, -8.3454e-01,\n",
      "          6.5911e-01,  1.3051e+00, -2.4712e-01, -7.6566e-01, -4.0395e-01,\n",
      "          5.6803e-01, -6.4741e-01, -9.8409e-02, -2.3467e-01, -9.0339e-01,\n",
      "          8.0082e-01,  7.2767e-01, -7.3332e-01, -2.4198e-02,  1.8165e-01,\n",
      "          9.8962e-01,  3.9594e-01,  1.9223e-01, -2.3987e+00, -8.5430e-02,\n",
      "         -7.6531e-01, -4.4453e-01, -6.0847e-03,  2.4201e-01,  8.7258e-01,\n",
      "         -1.1520e+00,  7.4316e-01,  5.0736e-01,  5.0133e-01, -9.9860e-02,\n",
      "         -3.5786e-02,  2.0749e-01, -1.9990e+00,  1.3526e+00, -7.4172e-02,\n",
      "          8.2488e-01, -4.5499e-01, -5.6632e-02, -3.8070e-01, -1.5034e+00,\n",
      "          6.9323e-01, -6.0637e-01, -9.1382e-01, -7.4110e-01,  2.2991e+00,\n",
      "         -1.2893e+00,  8.8580e-01,  9.3095e-01,  2.3309e+00,  1.3376e+00,\n",
      "         -8.9476e-02,  1.3529e+00, -1.9808e-01,  8.6969e-01, -8.0883e-01,\n",
      "         -2.9904e-01, -6.8306e-02,  1.3089e+00,  1.1535e+00,  1.0786e+00,\n",
      "          1.8646e+00, -3.0376e-02, -3.7737e-02,  9.4079e-02, -8.1245e-01,\n",
      "         -3.2330e-01,  4.1079e-02, -1.1155e+00,  1.4178e+00,  1.4640e+00,\n",
      "         -3.1893e-01,  2.7895e-01, -1.1467e-01, -2.7671e-02,  1.8191e-01,\n",
      "         -6.8592e-01,  1.6047e-01, -3.7328e-01, -1.2646e+00,  6.8020e-01,\n",
      "          2.6563e-01, -2.6771e+00, -3.5543e-01, -4.2133e-01,  5.5920e-01,\n",
      "         -1.4741e+00,  3.3847e-02, -7.8859e-01,  7.1337e-01,  5.8021e-01,\n",
      "         -4.4771e-01, -2.0442e-01, -1.9400e+00, -6.8411e-01,  1.4600e-01,\n",
      "          2.0914e+00, -4.1473e-01,  6.6150e-01, -1.2475e+00, -1.1156e-01,\n",
      "          5.0831e-01, -3.6862e-01,  6.8983e-01,  1.3909e+00,  5.2612e-01,\n",
      "         -1.1882e+00,  6.9780e-01, -9.7715e-01,  4.1000e-01,  1.9012e-01,\n",
      "          4.8914e-03,  6.9627e-01,  7.8308e-01, -1.2825e-02,  2.4923e-01,\n",
      "          3.1420e-01,  6.4442e-02,  1.0500e+00, -1.6167e+00, -1.5632e+00,\n",
      "          2.2053e-01, -6.9446e-01,  5.4102e-01,  1.0742e+00,  9.7678e-01,\n",
      "         -3.1588e-01, -7.7946e-03,  6.0796e-01, -7.1493e-01,  8.5232e-01,\n",
      "         -1.0923e+00,  1.1388e+00,  5.2475e-01, -5.0185e-01,  5.0472e-01,\n",
      "          2.3366e+00,  1.4062e+00,  5.8908e-01, -1.6050e+00, -9.7641e-01,\n",
      "         -1.3354e-01, -4.9551e-02, -1.9789e-01,  1.9132e+00, -3.1401e-01,\n",
      "          1.7705e+00, -1.3158e+00, -1.8853e+00,  3.6210e-01, -7.4948e-01,\n",
      "          3.7718e-01, -1.6484e+00,  3.7140e-02,  8.5746e-01,  6.8841e-01,\n",
      "         -6.9928e-01,  6.2532e-01, -4.7342e-01, -7.0834e-01,  1.4273e+00,\n",
      "          2.9431e+00,  1.8105e-01, -1.2456e+00,  1.5695e-01, -5.8445e-01,\n",
      "          1.7543e+00, -9.0197e-01, -1.5804e+00, -3.9392e-01, -2.6451e-02,\n",
      "          1.1073e+00, -1.5529e-02, -1.1230e+00,  2.4931e-01,  1.2178e+00,\n",
      "          2.1853e+00,  1.0623e+00, -8.3006e-01,  5.8070e-01, -6.7633e-01,\n",
      "          6.6186e-01,  6.8187e-01, -4.8192e-01,  2.1335e+00, -1.2812e+00,\n",
      "          5.9774e-01, -5.0753e-02,  1.1150e+00, -7.0145e-02, -6.8461e-01,\n",
      "         -2.1797e-02,  1.5202e-01,  3.8705e-01, -7.3368e-01,  5.2459e-01,\n",
      "         -4.1561e-01, -2.0786e+00, -1.7390e-01, -3.3505e-02, -1.9334e+00,\n",
      "          6.8076e-01,  2.2067e-01, -4.5583e-01, -1.5265e+00, -1.2039e+00,\n",
      "          3.8728e-01,  1.0262e+00,  6.6207e-01, -9.6011e-01, -1.4710e+00,\n",
      "         -1.5283e+00, -8.7033e-01, -1.7296e+00, -8.3370e-02, -6.7919e-02,\n",
      "          1.4447e+00, -1.2493e+00,  1.2595e+00, -4.6847e-01, -1.2569e+00,\n",
      "          2.0752e-01, -2.6154e+00,  1.0502e+00,  7.6005e-01,  2.6867e-01,\n",
      "         -5.4264e-01, -2.1014e-01, -1.8552e-01, -8.9904e-01, -1.3394e-01,\n",
      "         -1.6878e+00,  1.9050e+00, -1.1507e+00, -9.5277e-01,  6.5800e-01,\n",
      "         -3.4515e-01,  4.0626e-01,  2.2226e+00, -1.4148e+00,  1.3767e+00,\n",
      "         -2.0151e+00,  7.7285e-01,  6.6061e-01,  8.5428e-01, -8.0000e-01,\n",
      "         -1.3115e+00, -1.1067e-01, -4.7802e-01,  1.1376e+00,  4.6596e-01,\n",
      "          7.2759e-01,  5.2167e-01, -1.7974e-01,  1.5429e+00, -2.5764e-01,\n",
      "         -6.5968e-01,  6.9728e-01, -5.4997e-02, -4.1711e-01, -1.9709e-01,\n",
      "         -1.1871e+00, -1.1817e+00, -1.5465e+00, -3.7815e-01, -4.3474e-01,\n",
      "         -8.3121e-01, -7.4553e-01,  7.2507e-02,  8.7604e-01,  5.6750e-01,\n",
      "         -1.6291e+00, -1.1376e+00,  1.9694e+00, -3.2632e+00,  1.1183e+00,\n",
      "         -3.9924e-01, -2.1551e+00,  1.5456e+00,  2.2870e-01,  6.4385e-01,\n",
      "          7.2186e-01,  9.3797e-01,  5.4958e-02,  4.4154e-01,  3.6294e-01,\n",
      "         -2.1426e-01,  1.3047e+00,  1.9441e+00,  1.5860e+00, -3.0436e-01,\n",
      "         -3.3729e-01,  3.5655e-02, -6.1703e-01,  2.4145e+00, -5.7694e-01,\n",
      "          1.3331e+00, -2.1467e+00,  6.6552e-01, -2.3735e-01,  6.9498e-01,\n",
      "         -1.3478e+00,  2.2167e+00, -3.9814e-01,  1.7997e+00, -1.0427e+00,\n",
      "          4.1011e-01, -3.9331e-01, -1.1766e+00,  1.2837e+00, -1.9523e+00,\n",
      "         -1.1127e+00,  1.3181e+00,  1.6990e+00, -2.2501e-01, -6.3641e-01,\n",
      "          5.1939e-01, -4.2367e-01,  1.7147e+00, -1.4460e+00, -8.4405e-01,\n",
      "          9.2633e-01,  3.9946e-01, -2.7499e-01, -4.5766e-01, -2.3805e+00,\n",
      "         -1.1110e-01, -1.0052e+00,  1.2875e-01,  1.4473e-01, -4.6039e-02,\n",
      "          4.2289e-01, -5.8375e-01,  2.9181e-01, -6.9464e-01,  6.2255e-01,\n",
      "          1.4844e+00,  3.0315e-01, -2.4072e+00,  4.6966e-01, -1.2799e+00,\n",
      "          1.0098e+00,  4.3517e-01, -1.5956e-01,  9.1813e-01, -9.7396e-01,\n",
      "         -1.5237e+00, -1.1574e+00, -1.4522e+00,  1.6421e+00,  7.1334e-03,\n",
      "          1.3905e+00, -7.8670e-02,  1.6015e-01,  1.5875e+00,  3.9091e-01,\n",
      "          7.8280e-01,  4.6519e-01, -2.0081e+00, -1.6200e+00, -7.0663e-01,\n",
      "         -2.5798e-01, -3.6845e-01, -7.6364e-01,  1.8952e+00, -1.0438e-01,\n",
      "          1.2754e+00,  4.4065e-01, -6.4395e-01,  3.5015e-01, -7.6671e-01,\n",
      "         -1.0246e+00,  1.2101e+00,  8.0504e-01,  1.9077e-01, -9.9372e-01,\n",
      "          6.3347e-01, -1.4450e-01, -1.0510e+00,  1.5523e+00,  7.1820e-01,\n",
      "         -1.0926e+00, -5.4594e-02, -2.6359e-01,  3.6055e-02,  9.3415e-01,\n",
      "          1.6413e+00,  2.3784e-01,  4.1028e-01,  8.6899e-01,  8.8427e-01,\n",
      "         -1.1645e-02, -1.0339e+00,  8.7470e-01,  4.6591e-01, -2.4752e+00,\n",
      "          3.1853e-01,  7.8855e-01,  1.9784e+00,  7.2856e-01, -1.8702e+00,\n",
      "          8.6927e-01, -5.5800e-01, -1.2008e+00,  4.5854e-01, -7.6162e-01,\n",
      "          1.8149e-01, -8.0977e-01, -5.4339e-01,  1.0568e+00, -2.0715e+00,\n",
      "         -1.1456e+00,  6.4038e-01,  3.1826e-01, -6.3708e-01, -6.9378e-01,\n",
      "          1.9679e+00,  1.6139e+00,  1.1299e+00,  5.7301e-01,  8.3652e-01,\n",
      "         -7.0992e-01,  1.0511e+00,  1.0651e+00,  1.1643e+00, -1.1131e+00,\n",
      "         -1.5644e-01,  1.1966e+00, -2.2548e-01,  7.6712e-01,  5.6394e-01,\n",
      "         -6.0369e-01,  2.3835e-01, -2.2049e+00,  1.0229e+00,  2.4908e-01,\n",
      "         -5.5405e-01, -5.7575e-01,  1.2286e+00, -7.6993e-01, -2.1594e+00,\n",
      "          2.5473e+00,  2.4259e-01,  1.3896e-01,  1.6402e-01, -5.3268e-01,\n",
      "          3.9350e-01,  7.2367e-01,  1.6612e+00, -6.2775e-01, -1.6886e-01,\n",
      "         -6.2090e-01, -6.3985e-02,  5.6464e-02,  9.4069e-01,  2.7190e-01,\n",
      "          4.1164e-01,  1.8060e+00,  2.5145e-01,  3.6762e-02, -2.7712e-01,\n",
      "         -7.4903e-01,  7.5479e-01,  1.0455e+00,  1.3787e+00,  1.2660e-01,\n",
      "         -5.6957e-01,  7.2259e-01,  5.7546e-01,  1.8687e-01,  6.1348e-01,\n",
      "         -2.2304e-01, -7.9057e-01, -4.0342e-02,  2.0467e-01, -6.3500e-01,\n",
      "         -4.3618e-01,  7.1531e-01, -1.1921e+00, -8.5482e-01,  3.8480e-01,\n",
      "          2.2638e-01, -2.2338e-01, -3.8741e-01, -4.5655e-01,  1.5475e+00,\n",
      "         -2.4627e-01, -3.3624e-01,  6.4590e-01, -6.1354e-01, -4.4979e-01,\n",
      "          1.5161e+00, -1.0298e+00,  1.0101e-01, -9.0805e-02, -1.2079e+00,\n",
      "         -3.1614e-01, -3.8391e-01,  1.0354e+00, -1.1956e-01,  3.7667e-01,\n",
      "          1.7461e-01,  1.8286e+00,  9.3355e-01,  9.6974e-01,  8.1986e-01,\n",
      "         -7.8477e-01, -5.4077e-01, -1.4857e+00,  5.5246e-01, -1.0960e+00,\n",
      "          3.3577e-01, -1.3323e+00, -3.7680e-01, -3.6377e-01, -1.3088e+00,\n",
      "         -1.1521e-01,  4.2732e-01, -6.5279e-02,  3.4387e-01,  1.0794e-01,\n",
      "          9.1743e-01, -1.0368e-01, -4.7783e-01,  1.9504e-01,  9.9355e-01,\n",
      "         -1.6066e-01,  7.3212e-01, -1.3526e-01, -2.1981e+00, -2.7988e-01,\n",
      "         -1.4139e-01, -2.2248e-01,  1.3563e-01, -1.1405e+00, -1.4533e+00,\n",
      "         -8.3591e-01, -5.7581e-01,  5.7436e-01, -2.1332e-01,  1.4645e+00,\n",
      "          2.2519e-01, -6.7453e-01,  1.4358e+00, -1.1378e+00, -1.4638e+00,\n",
      "          1.2758e+00,  1.1205e+00, -3.0738e-01,  5.5099e-01, -1.4735e+00,\n",
      "         -1.7919e-01, -7.5705e-03, -7.3396e-01,  1.0754e+00,  7.6022e-01,\n",
      "         -8.8586e-01,  7.7609e-01,  1.5630e-03, -8.4639e-01, -6.3937e-01,\n",
      "         -7.2812e-01, -1.3765e+00, -9.8937e-01,  8.0651e-01, -3.0175e-01,\n",
      "         -3.3627e-01,  2.0512e+00,  4.5793e-01,  7.6969e-01, -1.4528e-02,\n",
      "         -4.3985e-01,  5.2979e-01, -2.9817e-01, -9.2725e-01, -4.8060e-01,\n",
      "          4.1474e-01, -6.7871e-01,  7.5787e-01, -9.8576e-01, -4.7148e-01,\n",
      "          5.2037e-01,  2.4748e-01, -4.3726e-01, -6.1507e-01, -6.6463e-02,\n",
      "          1.5993e-01,  1.5317e+00, -1.0143e+00, -3.7016e-01, -9.0600e-04,\n",
      "         -7.7000e-01, -4.3103e-01, -2.4000e-01, -2.9989e-01, -4.5566e-01,\n",
      "         -5.8033e-01,  1.6671e+00, -5.7434e-01,  1.8389e+00,  4.7720e-01,\n",
      "          4.6859e-01, -4.9644e-01,  1.7558e-01, -4.6974e-01,  4.3152e-01,\n",
      "         -1.3178e+00,  6.4975e-01, -1.7278e-01, -1.4505e+00,  2.6362e-01,\n",
      "          1.5290e+00, -1.9185e+00, -5.8471e-01, -2.0845e+00,  6.7436e-01,\n",
      "         -5.7144e-01,  1.5112e+00, -1.3808e+00, -8.4848e-01,  1.3805e+00,\n",
      "          6.9847e-01,  9.9019e-02, -1.3093e+00, -9.1020e-01, -4.9458e-01,\n",
      "         -1.9667e-01, -1.1050e+00, -8.1726e-02, -3.6663e-01, -4.3242e-02,\n",
      "          5.3555e-01,  1.0928e+00, -3.7899e-01,  1.4390e-01,  2.0523e-01,\n",
      "          1.5313e+00,  3.5269e-01,  1.7169e+00,  9.5628e-01, -1.3758e-01,\n",
      "         -7.6060e-01, -2.1630e+00, -3.3055e-01,  1.1268e+00,  1.6685e+00,\n",
      "          3.4376e-01, -1.7736e+00, -3.6945e-01, -2.5852e-02, -2.4456e-01,\n",
      "          5.0573e-01, -3.4116e-01,  7.7922e-01,  2.7205e-01, -4.3425e-01,\n",
      "          5.8973e-01, -2.4087e+00,  1.2611e+00, -1.3422e+00, -7.1667e-01,\n",
      "         -6.7336e-01, -3.9171e-01,  1.4768e+00,  2.0333e-02,  7.8527e-03,\n",
      "         -8.1044e-02, -5.2697e-01,  5.3205e-01,  9.7530e-01,  5.7624e-01,\n",
      "          3.6946e-01, -3.3788e+00,  3.4407e+00, -4.1234e-01, -1.4466e+00,\n",
      "         -1.0138e-01, -1.3779e+00,  2.3073e-01,  6.6138e-01, -8.9172e-01,\n",
      "          8.5631e-01,  6.6668e-01,  1.9409e-01,  2.4603e+00, -1.1770e+00,\n",
      "          4.8740e-01, -1.8886e+00,  9.3857e-02, -2.8626e-01,  8.0254e-01,\n",
      "          2.9592e-01,  1.2257e+00, -3.9841e-01,  1.7044e+00, -2.0049e+00,\n",
      "         -3.6719e-01,  2.9032e-01,  1.2621e+00, -6.9411e-01,  1.6827e+00,\n",
      "          1.2552e-01, -1.1555e+00, -1.8270e-01, -1.4909e+00, -1.0140e+00,\n",
      "          4.5097e-01,  1.5773e+00, -2.6854e-01,  1.1712e+00,  1.4918e-03,\n",
      "         -1.2322e-01, -1.7436e-01, -7.2293e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 2\n",
      "tensor([[0.8753]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 3\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,  347,  134,\n",
      "          347,  347,  347,  347,  347,  134,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 5.8061e-01, -1.7445e+00, -8.4656e-01,  4.3395e-01, -8.2793e-01,\n",
      "         -1.9261e+00, -3.2735e+00, -1.9074e+00,  6.0916e-01, -7.0895e-01,\n",
      "         -3.7076e-02, -2.9251e-01, -2.9167e-01, -1.3454e+00, -6.1565e-01,\n",
      "          3.7827e-02,  2.9174e+00,  7.4074e-01, -8.3254e-01,  9.3142e-01,\n",
      "         -4.0056e-01,  1.3970e+00,  9.5056e-02,  1.0531e+00,  6.3523e-01,\n",
      "          5.3186e-01,  7.5210e-01, -4.2838e-01,  3.4579e-01,  5.3480e-02,\n",
      "         -4.7238e-01, -3.4744e-01,  8.4852e-01,  8.7025e-01,  1.0685e-01,\n",
      "          6.8404e-01,  1.0073e+00,  3.5485e-01, -1.3464e+00, -6.5948e-01,\n",
      "          1.8588e+00,  3.5284e-02, -4.3726e-01, -1.0788e+00,  1.1924e+00,\n",
      "          3.7477e-01, -1.8904e+00,  1.6008e+00, -5.3253e-02, -4.8178e-01,\n",
      "          1.8924e-01,  9.7588e-01,  6.0019e-01,  1.4565e+00, -1.5642e-01,\n",
      "          1.1951e+00,  9.2045e-01, -6.7138e-01, -6.0935e-01, -8.8042e-02,\n",
      "          3.5392e-01, -2.3462e-01,  5.0033e-02, -5.5689e-01, -8.7526e-01,\n",
      "          5.4925e-01,  1.5224e-01, -1.0382e+00,  7.9491e-01,  6.1935e-01,\n",
      "          1.4268e-01,  5.6389e-01,  7.1865e-01, -1.9077e+00, -7.0815e-01,\n",
      "         -1.8335e-01,  4.8014e-01,  8.0342e-01, -6.8690e-01,  5.0473e-01,\n",
      "         -1.1860e+00,  6.1689e-01,  3.6377e-01,  3.0007e-01, -4.3173e-01,\n",
      "          4.2744e-01, -2.9106e-01, -1.5303e+00,  7.4284e-01,  2.4415e-03,\n",
      "          7.5381e-01,  4.2366e-01,  3.4702e-01, -3.8466e-01, -8.4092e-01,\n",
      "          6.2020e-01, -3.9188e-01, -1.2012e+00, -6.1075e-01,  2.2410e+00,\n",
      "         -1.5166e+00,  1.0852e+00, -1.8132e-01,  2.9701e+00,  1.7880e+00,\n",
      "          8.5205e-02,  1.0284e+00,  1.7540e-01,  2.2960e-02, -3.9228e-01,\n",
      "         -7.3152e-01,  1.7588e-01,  1.0770e+00,  8.3032e-01,  4.1558e-01,\n",
      "          1.7960e+00, -3.1209e-01,  2.5501e-01,  1.3581e-02, -1.2732e+00,\n",
      "         -5.0133e-01, -2.4782e-01, -2.0143e+00,  1.7866e+00,  4.3238e-01,\n",
      "          2.6319e-01,  4.2324e-01,  1.6921e-02,  1.8728e-01, -8.9285e-01,\n",
      "         -1.4748e+00, -7.5414e-02, -1.1136e-01, -5.7139e-01,  5.0394e-01,\n",
      "          7.6726e-01, -2.7019e+00, -1.2488e+00, -1.4634e-02,  2.6007e-01,\n",
      "         -7.9623e-01,  1.1389e-01, -1.0184e+00,  9.9155e-01,  5.6097e-01,\n",
      "         -3.4207e-01, -5.3909e-01, -1.1878e+00, -1.0387e+00,  2.2762e-01,\n",
      "          1.0524e+00,  2.5199e-01,  1.3521e+00, -1.0369e+00, -6.7733e-01,\n",
      "          8.9665e-01, -9.3086e-01, -4.4144e-01,  1.4321e+00,  4.3622e-01,\n",
      "         -8.9113e-01,  9.1689e-01, -1.1065e+00,  7.8228e-01,  3.3433e-02,\n",
      "         -6.8275e-01, -8.4596e-02,  1.1493e+00,  2.0447e-01,  4.2026e-01,\n",
      "          9.7866e-02,  1.0216e+00,  9.6200e-02, -1.0863e+00, -2.5973e+00,\n",
      "          7.9161e-01, -8.0616e-01, -6.4770e-01,  1.4643e+00,  3.8702e-01,\n",
      "         -3.2792e-01, -3.0677e-01,  6.5571e-01, -1.3681e+00,  3.8949e-01,\n",
      "         -1.3164e+00,  1.5360e+00, -2.7535e-02, -1.7563e-01,  2.3066e-01,\n",
      "          1.9916e+00,  1.7317e+00,  1.6505e-01,  3.2950e-01, -1.1431e+00,\n",
      "          6.7986e-01, -8.4299e-02,  1.1330e+00,  1.7257e+00,  4.0049e-01,\n",
      "          9.1244e-01, -8.8604e-01, -1.2872e+00, -3.3656e-02, -4.6553e-01,\n",
      "         -1.5178e-01, -9.1282e-01,  5.1299e-01,  2.4150e-01,  6.0098e-02,\n",
      "         -3.2253e-01,  9.1840e-01,  1.5061e-01, -1.2687e+00,  1.4575e+00,\n",
      "          2.5850e+00,  3.3083e-01, -5.7008e-01, -3.1709e-01, -4.8317e-01,\n",
      "          1.8828e+00, -8.3521e-01, -8.3053e-01, -8.3596e-01,  1.0372e+00,\n",
      "          7.6055e-01, -5.0927e-01, -3.6412e-01,  2.9809e-01,  1.1349e+00,\n",
      "          1.7678e+00,  1.7848e+00, -5.0119e-01,  7.0768e-01, -6.5439e-01,\n",
      "          1.8208e+00,  9.4568e-01, -7.7862e-01,  2.0414e+00, -1.0660e+00,\n",
      "          1.1570e+00,  3.9655e-01,  2.1026e-01,  2.2444e-02, -3.1344e-01,\n",
      "         -2.5704e-01,  5.3860e-01,  1.9412e-01, -2.1072e-01,  1.0496e+00,\n",
      "         -2.9176e-01, -2.0038e+00,  6.9037e-01,  2.0773e-01, -1.2036e+00,\n",
      "          9.2405e-01, -8.6578e-02, -2.9736e-01, -1.6439e+00, -1.2866e+00,\n",
      "         -9.0390e-02,  2.5567e-01,  7.5737e-01, -5.4937e-01, -2.0418e+00,\n",
      "         -1.6323e+00, -6.6860e-01, -9.7009e-01,  3.6756e-01, -2.2073e-01,\n",
      "          1.4031e+00, -1.7068e+00,  9.8522e-01, -1.1215e+00, -1.1111e+00,\n",
      "          7.3533e-01, -1.8048e+00,  9.1986e-01, -1.9889e-01, -3.3003e-01,\n",
      "         -5.8807e-01,  2.5933e-01, -3.0829e-01, -2.3934e-01, -2.0883e-01,\n",
      "         -1.0393e+00,  1.2635e+00, -1.5173e+00, -1.0005e+00, -5.0293e-01,\n",
      "         -1.4893e+00,  1.5354e-01,  2.5179e+00, -1.7682e+00,  1.4757e+00,\n",
      "         -2.2278e+00, -1.8440e-01,  4.9029e-01, -9.7734e-02, -2.1862e-01,\n",
      "         -2.0132e+00,  1.6167e-01, -2.8841e-01,  6.4424e-01,  3.6246e-01,\n",
      "         -5.7391e-02,  4.9140e-01, -7.5305e-01,  1.6800e+00, -1.0999e+00,\n",
      "          5.6228e-02,  4.7264e-01, -1.2991e-01, -1.3013e-01, -2.5779e-01,\n",
      "         -1.0646e+00, -1.2197e+00, -1.3852e+00, -1.8058e-01, -5.3472e-01,\n",
      "         -6.0913e-01,  1.1165e+00,  1.4048e-01,  2.3254e-01,  3.5009e-01,\n",
      "         -1.4661e+00, -1.2528e+00,  1.4684e+00, -2.1246e+00,  1.1695e+00,\n",
      "         -6.1964e-01, -1.5160e+00,  1.6504e+00,  3.7938e-01,  4.8681e-01,\n",
      "         -1.6587e-01,  1.1304e+00,  3.0614e-01,  1.1503e+00,  1.1838e-02,\n",
      "          4.5163e-01,  1.3148e+00,  1.6143e+00,  7.3751e-01,  6.9398e-02,\n",
      "         -8.5238e-01,  6.4665e-01, -9.4688e-01,  2.2750e+00, -1.3708e-01,\n",
      "          1.9355e+00, -1.2921e+00,  1.2124e+00,  1.7798e-01,  1.0856e+00,\n",
      "         -9.8489e-01,  1.7108e+00, -5.5098e-01,  9.5180e-01, -1.6797e+00,\n",
      "         -7.9646e-01, -1.0204e-01, -1.1355e+00,  1.0551e+00, -1.3583e+00,\n",
      "         -1.7008e-01,  1.5170e+00,  1.9561e+00, -5.1744e-01, -6.6015e-01,\n",
      "          1.0066e+00,  7.9226e-02,  2.6208e+00, -1.7971e+00, -9.3582e-01,\n",
      "          8.7909e-01, -6.7447e-01,  1.9055e-01, -6.9190e-01, -1.3650e+00,\n",
      "         -3.5196e-01, -1.4302e+00, -3.4780e-01,  5.6542e-01,  1.0486e+00,\n",
      "          2.9032e-01, -1.1480e+00,  3.3282e-01, -1.1714e+00,  1.0405e+00,\n",
      "          1.4111e+00, -7.5573e-02, -2.6678e+00,  3.4942e-02, -9.7276e-01,\n",
      "          1.0025e+00,  8.6672e-01, -3.7196e-02,  1.7630e+00, -1.0951e+00,\n",
      "         -1.2851e+00, -1.1990e+00, -6.5096e-01,  1.1393e+00, -9.9713e-01,\n",
      "          1.4479e-01, -6.7243e-01, -1.2844e+00,  1.6032e+00, -3.3252e-01,\n",
      "          6.5438e-01,  1.2231e+00, -1.6487e+00, -1.5675e+00, -5.7636e-01,\n",
      "         -1.3398e-01, -4.5519e-01, -9.1170e-01,  1.2401e+00,  3.5604e-01,\n",
      "          7.2719e-01,  5.8075e-01,  1.4137e-01,  8.7832e-02,  3.1546e-01,\n",
      "         -1.5392e+00,  8.1779e-01,  5.3822e-01,  2.1126e-01, -3.9038e-01,\n",
      "          8.0992e-01, -9.8310e-01, -2.0190e+00,  1.7131e+00, -4.0417e-01,\n",
      "         -2.1890e+00,  3.7529e-01, -1.7061e-01, -2.7603e-01,  2.5102e-01,\n",
      "          9.7325e-01,  8.2644e-01,  6.8011e-01,  8.8168e-01,  8.8122e-01,\n",
      "         -2.3875e-02, -3.8274e-01, -5.8991e-01,  5.0836e-01, -2.3192e+00,\n",
      "         -7.0650e-02,  8.4549e-01,  1.7679e+00,  9.8929e-01, -1.6187e+00,\n",
      "          1.0452e+00, -3.2854e-01, -6.2333e-01,  6.1018e-01, -1.1649e+00,\n",
      "          9.8439e-01,  2.3566e-01, -6.9498e-01,  1.1816e+00, -1.8108e+00,\n",
      "         -9.1445e-01,  7.9398e-01,  2.4943e-01, -5.1268e-01, -3.1982e-01,\n",
      "          2.2894e+00,  1.8072e+00,  4.9215e-01,  7.3454e-01,  1.3413e+00,\n",
      "         -7.2552e-01,  8.8314e-01,  8.5781e-01,  1.1755e+00, -9.4173e-01,\n",
      "         -1.0709e-02,  1.2500e+00, -5.6488e-01,  7.0280e-01,  7.1063e-01,\n",
      "         -3.9945e-01,  1.3798e-01, -2.8361e+00,  9.2171e-01, -1.4414e-01,\n",
      "         -3.7157e-01, -5.1922e-01,  1.6334e-01, -5.8177e-01, -9.8604e-01,\n",
      "          1.7779e+00,  2.7756e-01, -2.2044e-01,  6.2220e-01, -1.2203e+00,\n",
      "          2.6654e-01,  2.6505e-01,  1.5045e+00, -1.2294e+00,  2.1448e-02,\n",
      "         -3.4253e-01,  1.1042e-01, -4.3864e-01,  7.0331e-01,  7.8374e-01,\n",
      "         -7.6427e-02,  1.2305e+00,  1.3705e+00, -3.1924e-01,  4.1055e-01,\n",
      "         -4.2078e-01,  9.6982e-01,  1.9649e+00,  1.3326e+00, -2.2928e-01,\n",
      "         -1.3426e+00,  9.1467e-01,  8.8802e-01,  6.5154e-01,  1.2257e+00,\n",
      "         -4.2060e-01,  5.1371e-02,  4.4723e-01,  1.5990e-01, -6.3901e-01,\n",
      "         -1.0366e+00,  8.7920e-01, -4.5710e-01,  6.6724e-02,  3.4583e-01,\n",
      "         -6.8697e-01, -1.7273e-01, -5.4697e-02, -7.3172e-02,  1.2514e+00,\n",
      "          1.3211e+00,  1.6527e-01,  3.6724e-01,  2.6999e-01, -1.9138e+00,\n",
      "          1.2872e+00, -1.6467e+00,  3.3259e-01,  9.4301e-01, -1.7445e+00,\n",
      "         -2.8271e-01, -9.3746e-02, -5.1167e-01,  2.2705e-01,  3.0620e-01,\n",
      "         -5.4135e-01,  2.2247e+00, -3.7390e-01, -6.3842e-02,  5.7431e-01,\n",
      "         -7.5251e-01, -1.3049e+00, -1.8918e+00, -2.4671e-01, -9.3693e-03,\n",
      "          5.7104e-01, -5.6536e-01, -3.1097e-01, -1.9855e-01, -7.3243e-01,\n",
      "         -4.6380e-01,  7.9079e-01,  5.4672e-01,  1.4758e+00,  6.6644e-01,\n",
      "          4.8379e-02, -3.1849e-01, -7.5948e-01,  7.0691e-01,  3.5645e-01,\n",
      "          2.6566e-01,  7.8971e-01,  1.2782e-01, -1.8370e+00, -4.6681e-01,\n",
      "          5.4546e-01,  2.0534e-01,  4.2671e-01, -1.4525e+00,  8.2781e-02,\n",
      "         -3.2508e-02, -1.9515e+00,  1.0314e+00, -5.5991e-01,  3.5597e-01,\n",
      "          4.0711e-01, -1.1487e+00,  1.3637e+00, -1.3110e+00, -4.8038e-01,\n",
      "          9.3535e-01,  9.3594e-01, -1.0723e+00,  1.6288e-01, -8.8368e-01,\n",
      "         -5.3505e-01, -1.1285e-01, -2.9932e-01,  1.4953e+00, -8.0971e-02,\n",
      "         -5.2249e-01,  3.0718e-01,  2.4977e-02,  1.9396e-01, -9.3955e-01,\n",
      "         -9.8029e-02, -1.4762e+00, -6.6969e-01,  2.0640e-01, -5.4356e-01,\n",
      "         -5.0765e-01,  2.4110e+00,  4.6278e-02,  4.9846e-01, -5.9628e-01,\n",
      "         -1.9703e-01,  3.8759e-01, -6.8103e-01, -1.0593e+00, -5.5871e-01,\n",
      "          9.9372e-01,  6.2336e-01,  1.4307e+00, -1.5432e+00, -7.4532e-01,\n",
      "          8.4939e-01,  4.4148e-01, -1.5907e-01, -5.7966e-01, -9.5727e-01,\n",
      "         -7.2302e-01,  6.0365e-01, -7.2448e-01,  2.5758e-02, -6.5070e-01,\n",
      "         -1.0036e+00, -5.2112e-01, -4.0376e-01, -2.7647e+00, -5.1732e-01,\n",
      "         -2.2813e-01,  1.7823e+00, -4.5640e-01,  1.8899e+00, -1.5778e-01,\n",
      "          1.1592e+00, -7.9574e-01,  4.2745e-01,  6.3323e-01, -4.3547e-01,\n",
      "         -1.3394e+00,  1.0016e+00,  4.6051e-01, -1.2803e+00,  7.5186e-02,\n",
      "          1.9512e+00, -1.7638e+00, -1.1908e-01, -1.7018e+00,  4.2340e-01,\n",
      "         -1.3801e+00,  1.3314e+00, -2.4416e+00, -1.1953e+00,  1.4978e+00,\n",
      "          8.1302e-01,  4.5952e-01, -1.4227e+00, -1.0443e+00,  1.2668e-01,\n",
      "         -3.9870e-01, -3.2562e-01, -1.0625e-01, -3.6067e-01, -4.1876e-01,\n",
      "          1.5174e+00,  9.3059e-01, -2.1925e-01,  3.2814e-01,  2.6865e-01,\n",
      "          4.6463e-01,  1.3077e-01,  1.5339e+00, -9.6791e-03, -3.1947e-01,\n",
      "         -2.6910e-01, -1.5068e+00, -3.1607e-01,  2.1868e+00,  1.6356e+00,\n",
      "          2.1093e-02, -1.8525e+00,  5.3670e-01,  2.0690e-01, -4.4078e-01,\n",
      "          3.6863e-01, -4.2264e-01,  1.4167e+00,  2.6342e-01, -4.7851e-01,\n",
      "          5.9638e-01, -2.0524e+00,  9.9257e-01, -7.3633e-02, -6.3954e-01,\n",
      "         -7.4086e-01,  6.9487e-03,  1.2890e+00, -5.0145e-02,  1.7313e-01,\n",
      "          1.0592e-01, -8.5629e-01,  6.1104e-01, -3.3069e-01,  1.4738e-01,\n",
      "          6.4272e-01, -3.0207e+00,  2.1420e+00, -3.4469e-01, -1.1683e+00,\n",
      "         -7.3237e-01, -7.8770e-01, -1.4521e-01, -1.8072e-01, -2.0746e-01,\n",
      "          1.1311e+00, -1.0010e+00, -6.1655e-01,  2.3539e+00, -1.0238e+00,\n",
      "          1.8554e-01, -1.8371e+00, -2.7415e-01, -2.2439e-01,  5.6242e-01,\n",
      "          5.8864e-01,  7.7232e-01, -3.4731e-01,  2.1779e+00, -2.3953e+00,\n",
      "         -1.6986e-02, -2.6933e-01,  1.4266e+00, -4.6387e-01,  2.1865e+00,\n",
      "         -9.4454e-01, -1.7411e+00, -4.6768e-01, -1.1217e+00, -1.4215e+00,\n",
      "          6.8778e-01,  1.4920e+00,  7.3238e-02,  1.6582e+00,  7.8251e-01,\n",
      "         -6.8682e-01, -6.9999e-01, -1.4731e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 3\n",
      "tensor([[0.3175]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 4\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347, 1640,  347,   43,\n",
      "          347,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 0.2709, -1.9107, -0.6708,  0.7649,  0.1056, -1.4021, -2.1068, -1.0771,\n",
      "         -0.3833,  0.3272,  0.2138,  0.7258, -0.3819, -0.5004, -0.8090,  0.6733,\n",
      "          1.1188,  0.8832, -2.0892,  0.9819, -0.3008,  1.1282, -0.0262,  1.2787,\n",
      "          1.2442,  0.3798, -0.2920, -0.4930, -0.3985,  0.3712, -0.3686, -0.1515,\n",
      "          1.4529,  0.4501,  0.1628,  0.5733,  0.6101,  0.0910, -1.6421, -0.4946,\n",
      "          1.5914,  0.7647, -0.3222, -1.0639,  0.8895,  0.2434, -1.8809,  1.3042,\n",
      "         -1.0990,  0.2696, -0.0244, -0.0194,  0.8265,  0.5710, -1.0852,  1.5626,\n",
      "          1.3077,  0.0183, -0.8728, -0.2005,  0.2089, -0.3887,  0.0600, -0.6204,\n",
      "         -0.8927,  0.5313,  0.5537, -1.4740,  0.4394,  0.4407,  1.2823,  0.6927,\n",
      "         -0.2387, -2.1249, -0.6592, -0.2078,  0.2393,  0.6783, -0.4826,  0.2164,\n",
      "         -1.1073,  0.5114,  0.6854,  0.1966,  0.0745, -0.2360,  0.2812, -2.0770,\n",
      "          0.5810,  0.4907,  1.3270, -0.3301,  0.1528, -0.1307, -0.8883,  1.1826,\n",
      "          0.3349, -1.2281, -0.9405,  1.9988, -1.6879,  0.5671,  0.4371,  2.2306,\n",
      "          1.4203,  0.7819,  1.6347,  0.9399,  0.1422, -0.0650, -0.7326, -0.1316,\n",
      "          0.9130,  1.0773,  0.1382,  1.4623, -0.0531,  0.8883,  0.4628, -1.4586,\n",
      "         -0.3704, -0.0277, -1.1578,  1.5388, -0.0758, -0.3642,  0.6063, -0.7529,\n",
      "         -0.2709, -0.4362, -0.3183, -0.3808, -0.0630, -1.2419,  0.4631,  0.4593,\n",
      "         -2.7250, -0.5911,  0.1442, -0.0900, -1.4651, -0.3623, -0.7211,  0.8304,\n",
      "          1.1061, -0.3822, -1.3330, -1.7742, -1.2625, -0.1776,  1.2285, -0.2997,\n",
      "          1.2816, -0.8377, -0.5287,  1.1276, -0.6546, -0.1808,  1.0288,  0.2852,\n",
      "         -0.5616,  1.3090, -1.4278,  0.1566, -0.1610, -0.4164,  0.2365,  0.8645,\n",
      "          0.2385,  0.2642,  0.3050,  1.1519,  0.7022, -1.6652, -2.5982,  0.3690,\n",
      "         -0.4603,  0.3931,  1.3781,  0.3463, -0.8410, -0.8062,  1.4001, -0.6609,\n",
      "          0.8703, -1.0918,  0.6781, -0.0789,  0.4850,  0.5601,  1.2369,  1.6536,\n",
      "          0.4693,  0.3060, -0.9807,  1.0326, -1.0652,  1.1271,  1.0111, -0.0344,\n",
      "          1.2946, -0.4039, -1.8686, -0.1299, -0.2500,  0.3016, -0.3050,  0.1466,\n",
      "          0.5358,  0.2277, -0.8974,  0.4158, -0.4888, -1.5869,  1.2028,  2.2526,\n",
      "          0.4557, -1.2058, -0.0982, -0.5856,  0.9068, -1.4524, -0.3521, -0.6515,\n",
      "         -0.0283,  1.3734, -0.2180, -0.9412,  0.6888,  1.1061,  1.9964,  0.7936,\n",
      "         -0.6157,  0.4923, -0.1803,  1.8099,  0.3959, -0.4546,  1.8712, -0.5289,\n",
      "          1.4193,  0.1100, -0.0794,  0.8177, -0.0451, -0.2364,  1.0906,  0.4883,\n",
      "          0.1977,  0.4327, -0.3787, -2.0169,  0.5320,  0.0194, -1.1585,  1.1657,\n",
      "          0.6482, -0.6451, -0.7168, -1.5879,  0.3697,  0.5879,  1.1907, -0.4234,\n",
      "         -1.8838, -2.4493, -0.9801, -0.7443,  0.1983, -0.1098,  1.0430, -2.4441,\n",
      "          1.2007, -0.7657, -0.5647,  0.8931, -2.4827,  0.6777, -0.3659, -0.1855,\n",
      "         -0.9432, -0.0094, -0.3716, -0.1387, -0.1863, -1.2754,  1.6277, -1.6620,\n",
      "         -0.4375, -0.1846, -0.9528,  0.6500,  1.7710, -1.5286,  1.6918, -1.3710,\n",
      "          0.7462,  0.0485,  0.4238, -0.1644, -1.1917, -0.1709, -0.4049,  0.6964,\n",
      "          0.0293,  0.6269, -0.0141, -0.1025,  2.0977, -0.4749, -0.3133,  0.9120,\n",
      "          0.4302, -0.2805, -0.3042, -0.8557, -1.8643, -0.9151,  0.1956, -0.0143,\n",
      "         -0.4127,  0.8081,  0.3194,  0.6381,  0.4810, -1.1504, -1.1382,  1.8540,\n",
      "         -2.3296,  0.8753, -0.1953, -2.0834,  1.9856,  0.6441,  0.6269,  0.1276,\n",
      "          0.1313,  0.1379,  0.9098,  0.4292,  0.1147,  1.4320,  1.8697,  2.2056,\n",
      "         -0.9064, -0.5784,  0.7713, -0.8177,  1.9424, -0.5195,  2.1635, -1.5505,\n",
      "          0.8395,  1.1788,  0.8235, -1.3158,  2.0042, -0.8858,  1.2981, -1.4154,\n",
      "         -0.1238, -0.0455, -0.7058,  1.8004, -1.7412, -0.5742,  1.6766,  0.1423,\n",
      "          0.0247, -1.2565,  0.7621, -0.6570,  2.5667, -1.1260, -0.6672,  0.3690,\n",
      "         -0.5745, -0.1640,  0.0257, -2.1016, -0.1982, -1.1545,  0.0171,  0.3757,\n",
      "          0.8695,  0.2203, -1.2158,  0.1462, -0.8656,  0.5837,  1.7725,  0.0157,\n",
      "         -2.9157,  0.3170, -1.3255,  1.2650,  0.0515,  0.4385,  0.9708, -0.7147,\n",
      "         -1.7616, -0.2155, -0.6304,  1.7777,  0.1896,  0.1715, -0.7025, -0.3068,\n",
      "          1.6078, -1.2332,  0.3727,  0.4615, -1.5027, -0.2196,  0.1472, -0.3451,\n",
      "         -0.1462, -1.2512,  0.8867,  0.2874,  1.3292,  0.6329,  0.4977, -0.0681,\n",
      "          0.2242, -1.1400,  0.7784,  0.7607,  0.6339, -1.1366,  1.1468, -0.0068,\n",
      "         -2.4302,  0.8906,  0.0379, -2.1373, -0.3982,  0.4007,  0.5646,  0.5937,\n",
      "          2.1051,  0.5380,  0.7137,  0.8397,  1.1837,  0.2085, -2.0570,  0.3824,\n",
      "          1.1635, -2.5279,  0.4707,  0.6599,  1.3201,  0.0343, -1.8476,  0.8367,\n",
      "         -0.4534, -1.4534,  1.0889, -1.5045, -0.2081,  0.4749, -0.2290,  1.0760,\n",
      "         -1.3731, -1.2795,  0.1736,  0.3610, -0.2743, -0.6685,  2.2452,  1.9212,\n",
      "          0.6752,  0.7662,  0.8183, -0.3218,  0.8644,  0.5419,  0.9051, -0.3626,\n",
      "         -0.0292,  1.1387, -0.6346,  1.2109, -0.5950, -0.8386,  0.4322, -2.2837,\n",
      "          0.1042,  0.2224, -0.9520, -0.4511,  1.4243, -1.0212, -1.6977,  2.3330,\n",
      "          0.0192, -0.1665,  1.2019, -0.4331,  0.8154,  0.2723,  1.5080, -0.9201,\n",
      "          0.3941,  0.0214,  0.2844,  0.2559,  0.9461,  0.9193, -0.3046,  1.2329,\n",
      "          1.0988,  0.0724,  0.0094, -0.8923,  0.9490,  1.5306,  1.1275,  0.2470,\n",
      "         -1.4017,  0.4463,  0.2268,  0.6138,  0.8079, -0.1033,  0.0919,  0.1431,\n",
      "          0.0507, -1.1273, -0.9640,  0.0379, -0.8186, -0.5043, -0.0758, -0.3838,\n",
      "          0.2046, -0.4284,  0.3310,  2.3824,  0.7736, -0.8962, -0.2732, -0.6774,\n",
      "         -0.8023,  1.5719, -0.8078,  0.1987, -0.2775, -1.4070, -0.9769, -0.1070,\n",
      "          0.0515,  0.0088,  0.4869, -0.7216,  2.1235, -1.2367,  0.6771,  1.3619,\n",
      "          0.1579, -0.7653, -0.7282,  0.0920, -0.8696,  0.7760, -0.7788, -0.4254,\n",
      "         -0.3280, -0.7825,  0.2338,  0.2714,  0.0227,  0.8152, -0.0080, -0.1157,\n",
      "          0.4516, -0.3842,  0.7283,  0.3212, -0.3105, -0.3410,  0.5233, -2.2614,\n",
      "          0.0609,  0.1125,  1.1357,  0.1472, -0.8734,  0.2680, -0.4393, -1.8770,\n",
      "          0.9457,  0.2378,  0.6780,  0.3158, -0.4166,  1.5674, -0.6595, -0.0348,\n",
      "          1.1148,  0.6003, -1.2910,  0.1653, -1.2687, -1.1777, -0.4454, -1.0230,\n",
      "          1.7224,  0.1562, -0.2051,  1.0915, -0.5773, -0.8386, -1.3718, -0.2541,\n",
      "         -1.4129, -0.9992,  0.9266, -0.5345, -0.1963,  2.3085,  0.2950,  0.4141,\n",
      "         -1.3772, -0.0319,  1.0577, -0.3687, -0.8499, -0.4051,  0.4890, -1.0799,\n",
      "          2.3617, -1.1341, -0.8751,  0.8657, -0.2016, -0.9295, -0.9215,  0.0821,\n",
      "          0.0142,  0.7831, -0.3113,  0.0835, -0.8372, -0.4930, -0.4701, -0.4295,\n",
      "         -0.4842, -0.2743, -0.4029,  1.6170, -0.0741,  1.4929,  0.7485,  0.4832,\n",
      "         -0.2965,  0.5634, -0.0883, -0.1442, -1.2611,  1.2107,  0.2334, -1.4028,\n",
      "          0.5736,  1.4446, -1.7096,  0.1464, -1.4611, -0.0071, -0.8066,  0.6192,\n",
      "         -1.9258, -1.5023,  1.4226,  0.2037,  0.8098, -1.3461, -1.3945,  0.1902,\n",
      "         -0.5822, -0.9420, -0.0102,  0.4098, -0.1973,  1.6882,  0.7194, -0.2582,\n",
      "          0.5085,  0.2744,  0.8951,  0.3745,  2.2416,  0.4931, -0.4054, -1.0682,\n",
      "         -2.5857, -0.6833,  1.2086,  0.9869, -0.0340, -2.9242,  0.5071, -0.4612,\n",
      "         -0.6208,  0.0335,  0.3574,  0.3147, -0.1581, -1.2365,  1.3014, -2.0477,\n",
      "          1.0073, -0.5984, -0.5866, -0.4141,  0.0872,  0.2498, -0.0810, -0.0108,\n",
      "          0.6465, -0.4979,  0.1451,  0.6417,  0.5037, -0.2156, -3.7227,  2.5353,\n",
      "          0.1648, -0.9672, -0.2647, -0.8758, -0.0769,  0.3164, -0.2661,  1.9485,\n",
      "         -0.6460, -0.3949,  1.4989, -0.9588, -0.0267, -2.0657,  0.0202, -0.2234,\n",
      "          0.4593,  0.2457,  0.6107,  0.2846,  2.1228, -2.3906,  0.1898, -0.7253,\n",
      "          1.0773, -1.0549,  2.0452, -0.8847, -1.5094, -0.6656, -2.0355, -2.3930,\n",
      "         -0.5739,  1.8142, -0.3299,  1.0150,  0.9365, -0.6129, -0.2739, -0.3018]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 4\n",
      "tensor([[0.0759]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 5\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 0.4243, -2.0828, -0.6703,  0.5114, -0.5374, -1.4354, -2.5531, -1.1461,\n",
      "          0.2641, -0.0149, -0.0457,  0.1523, -0.2071, -2.0000, -0.7931,  0.1193,\n",
      "          2.1589,  1.3784, -1.9071,  1.5296, -0.4527,  0.0928,  0.2149,  1.1063,\n",
      "          1.1596, -0.0948,  0.0985, -0.6205,  0.2586, -0.0059,  0.4979, -0.4621,\n",
      "          1.1320,  0.5546, -0.2662,  0.7691,  0.0961,  0.2306, -1.0057, -0.7671,\n",
      "          1.8247,  0.8499, -0.2813, -1.7357,  1.3524,  0.0653, -1.7016,  1.7057,\n",
      "         -0.9517, -0.2279, -0.1820, -0.0580,  0.5690,  0.4202, -0.5279,  1.6493,\n",
      "          0.7993,  0.1542, -1.2402, -0.1411,  0.7957, -0.1445,  0.1623, -0.8687,\n",
      "         -0.2826,  0.4751, -0.1162, -1.4432,  0.4380,  0.4527,  0.5377,  0.6580,\n",
      "          0.3375, -2.4799, -0.6084, -0.3303, -0.0255,  0.9092,  0.2744, -0.0653,\n",
      "         -0.9507,  0.2258,  0.4988,  0.3306, -0.5164, -0.1625,  0.0876, -1.6120,\n",
      "          1.0002,  0.4633,  1.7431, -0.3149,  0.6749,  0.5268, -0.5583,  1.0521,\n",
      "          1.0829, -1.1015, -0.1483,  1.9061, -0.8451,  0.7924,  0.4088,  1.9036,\n",
      "          1.6199, -0.1789,  1.7192,  0.5310, -0.1783, -1.3382, -1.3369,  0.3255,\n",
      "          0.7924,  0.7359,  0.1146,  1.1851,  0.1611,  1.3033,  0.6144, -0.9426,\n",
      "         -0.3935, -0.2790, -1.6085,  1.5785,  0.7472,  0.1710,  0.2363,  0.1902,\n",
      "         -0.7709, -0.5622, -0.5227, -0.2718,  0.3052, -0.9865,  0.5895,  0.2242,\n",
      "         -1.9123, -0.6418, -0.6437, -0.3787, -1.1673,  0.0729, -0.9063,  0.6148,\n",
      "          1.1493, -0.0948, -0.3930, -1.3800, -1.1483,  0.5537,  0.9905, -0.8129,\n",
      "          1.5869, -1.7363, -0.7654,  0.4374, -0.7492, -0.2287,  1.2275,  0.3548,\n",
      "         -0.0103,  1.5309, -1.1047, -0.0486, -0.0691, -0.1837, -0.2187,  0.6836,\n",
      "          0.0702,  0.0785,  0.6030,  0.3011,  0.6079, -1.7060, -2.1580,  1.1054,\n",
      "         -0.2431,  0.1033,  1.0844,  0.6623, -0.2172, -1.3072,  1.1558, -1.2876,\n",
      "          1.1655, -1.5128, -0.0431,  0.4285, -0.6009,  1.6185,  1.6696,  1.6825,\n",
      "         -0.1608, -0.1333, -0.1981,  0.3054, -0.1455,  0.1456,  1.1772,  0.4325,\n",
      "          0.9522, -0.8057, -0.8887,  0.2051, -0.7904,  0.4683, -1.4864, -0.1025,\n",
      "          0.1563,  0.4582, -0.8809,  1.0670, -0.0773, -1.2207,  1.4388,  1.3595,\n",
      "          0.6022, -0.5603, -0.3078,  0.1355,  1.3022, -1.2361, -0.7713, -0.4589,\n",
      "         -0.3345,  0.7438, -0.0545, -0.5499, -0.5740,  1.1806,  2.3713,  1.3186,\n",
      "         -0.4517,  0.2167,  0.0777,  2.0024,  0.6756, -0.3508,  1.2371,  0.0254,\n",
      "          1.4962, -0.0692,  1.3234,  0.4608,  0.2407, -0.3295,  0.9957,  0.7924,\n",
      "         -0.4575,  0.8703, -0.2064, -1.7823, -0.2394,  0.3371, -1.5472,  0.7719,\n",
      "          0.3196, -0.3604, -1.1384, -1.7606, -0.2447,  0.8752,  1.2579, -0.6290,\n",
      "         -2.7782, -1.9319, -0.2025, -0.6929,  1.2801, -0.0743,  1.1286, -2.4788,\n",
      "          1.7366, -0.9589, -0.2988,  1.5728, -1.3353,  0.9221, -0.9443, -0.1901,\n",
      "         -1.5370,  0.3402, -0.0818, -0.2245, -0.4648, -1.9213,  1.0028, -1.9689,\n",
      "         -0.7230, -0.3062, -1.5636,  0.5210,  1.8131, -1.4525,  1.5912, -2.1364,\n",
      "          0.5036,  0.8310, -0.5454,  0.3887, -1.3076, -0.5646, -0.1626,  0.4135,\n",
      "          0.4513,  0.7600, -0.0949, -0.6021,  1.1088, -1.1598, -0.1680,  0.0479,\n",
      "          0.2459, -0.1208,  0.3714, -1.1500, -2.2403, -1.0696,  0.4647, -0.0453,\n",
      "          0.1128,  0.7429,  0.6511,  0.4834,  1.3793, -1.4245, -2.2421,  0.4944,\n",
      "         -2.3577,  0.6699, -0.7723, -1.1890,  1.6020,  0.5272,  0.9179,  0.6309,\n",
      "         -0.4983,  0.0558,  0.8095, -0.2619, -0.5429,  1.0732,  1.6851,  1.9499,\n",
      "         -1.1424, -0.7557,  0.5222, -0.4095,  1.4094, -0.0575,  1.8672, -1.4926,\n",
      "          0.7346,  0.8175,  1.0440, -1.2208,  1.5224, -0.4658,  1.3130, -2.0706,\n",
      "         -0.1387,  0.2601, -0.8776,  2.0929, -1.9486, -0.6059,  1.3750,  1.2840,\n",
      "         -0.6305, -0.5437,  0.8242, -0.0924,  3.0284, -1.1387, -0.5048,  0.6998,\n",
      "         -0.7001,  0.0307, -0.3489, -2.1693, -0.1347, -1.5462, -0.4182,  0.3208,\n",
      "          0.0550,  0.0608, -0.6743,  0.5410, -0.7312,  0.9020,  1.5805,  0.4683,\n",
      "         -2.8172,  0.3221, -1.2013,  0.4456,  0.7993,  0.1469,  1.0821, -0.5649,\n",
      "         -1.1019, -0.0554, -0.2682,  1.7964,  0.1505,  0.1686, -0.7934, -0.7805,\n",
      "          0.8925, -1.1103,  0.7395,  1.2069, -1.4983, -0.9896,  0.0746,  0.1520,\n",
      "         -0.1409, -1.5822,  1.3268, -0.1337,  0.3956,  0.6521,  0.1734,  0.4897,\n",
      "          0.3101, -1.6620,  0.4689,  1.0023,  0.7322, -0.8592,  0.9180, -0.6567,\n",
      "         -1.5362,  1.4946,  0.5971, -2.1775,  0.4617,  0.4767,  0.5097, -0.0265,\n",
      "          1.9921,  0.8522,  0.1156,  0.9367,  1.0839, -0.2955, -1.7283,  0.2991,\n",
      "          0.9737, -2.4005,  0.3283,  0.4927,  0.9938, -0.1424, -2.0344,  0.7931,\n",
      "         -0.7201, -1.1028,  0.6286, -1.4516, -0.2243,  0.0395, -0.6175,  0.7449,\n",
      "         -1.4899, -1.2783, -0.1753, -0.2606, -0.0515, -1.3033,  2.6299,  1.7698,\n",
      "          0.3758,  0.5772,  0.8765, -0.5936,  1.3028,  0.6459,  1.2431, -0.7773,\n",
      "          0.6864,  2.1011,  0.0549,  1.2788, -0.1274, -0.9089,  0.6797, -2.0214,\n",
      "          0.8672,  0.3977, -0.2415,  0.0973,  1.0300, -1.2091, -1.3249,  1.6696,\n",
      "          0.1208,  0.3956,  0.7180, -0.5738, -0.0833,  0.2917,  1.7164, -1.2961,\n",
      "          0.7055,  0.0123,  0.2874,  0.2873,  0.3777,  0.8801, -0.2597,  1.0053,\n",
      "          0.5171, -0.3313,  0.4053, -0.4818,  1.0546,  1.7102,  1.4165,  0.0622,\n",
      "         -0.7010, -0.0387,  0.1497,  1.6747,  1.0180, -0.5521, -0.2891,  0.0440,\n",
      "         -0.2747, -0.6366, -0.4143,  0.4846, -0.7411, -0.2068,  0.5194, -0.9991,\n",
      "          0.0474,  0.1671,  0.1488,  2.5640,  0.8450, -0.9605, -0.0289, -0.3154,\n",
      "         -1.2849,  1.9373, -1.2057,  0.0737,  0.7549, -1.6543, -0.3475, -0.0704,\n",
      "         -0.2704, -0.4286,  0.7056, -0.0057,  2.0370,  0.3484,  0.2476,  0.7655,\n",
      "         -0.5527, -0.9164, -2.0098, -0.6147, -0.6376,  0.6845, -1.2403, -0.2989,\n",
      "          0.3425, -0.8211,  0.7802,  1.0045,  0.5598,  0.9769,  0.3627, -0.7338,\n",
      "         -0.6463, -0.9213,  0.4415, -0.0427,  0.4158,  0.4120, -0.2174, -2.2308,\n",
      "         -0.0697,  0.5273,  0.8514,  0.3997, -1.2034,  0.0216, -0.8250, -2.1739,\n",
      "          0.8975,  0.0205, -0.0839,  0.2558, -0.5325,  1.2126, -1.2117, -0.8310,\n",
      "          1.5425,  0.6267, -1.7654,  0.0463, -1.3590, -1.1479, -0.7563,  0.1315,\n",
      "          2.0211,  0.0937, -1.0219,  0.6592,  0.5237, -0.4589, -1.1464,  0.0381,\n",
      "         -1.5890, -0.5371,  0.6690, -0.1891,  0.1323,  1.9123, -0.0619,  0.5083,\n",
      "         -0.3168, -0.0842,  0.7460, -1.2626, -0.9421, -0.4479,  1.0546, -0.9733,\n",
      "          1.4157, -0.7729, -0.5018,  0.7346,  0.3356, -0.7922, -1.1901, -0.0682,\n",
      "          0.0299,  1.1182, -0.7841,  0.0356, -0.5014, -0.9736, -0.3422, -0.3937,\n",
      "         -1.4503, -0.6368, -0.2556,  1.6285, -0.1932,  1.4517,  0.2524,  0.7416,\n",
      "         -0.5671, -0.1425,  0.1374,  0.3277, -0.8520,  0.7924,  0.1339, -1.2510,\n",
      "         -0.3910,  1.6998, -1.2606,  0.5778, -1.0647,  0.1280, -1.4203,  1.4180,\n",
      "         -1.8820, -1.6266,  1.2101, -0.1057,  0.5879, -1.1569, -1.5340,  0.2627,\n",
      "         -0.1856, -0.5760, -1.1082,  0.5757, -0.5780,  1.4159,  1.0057, -0.2719,\n",
      "          0.8732, -0.2551,  0.8806,  0.4500,  1.2055,  0.1710, -1.1439, -0.3575,\n",
      "         -1.7813, -0.5762,  1.8059,  1.4390,  0.5035, -2.5634,  0.4719, -0.1192,\n",
      "         -0.4706, -0.1279, -0.3080,  1.5278,  0.7089, -0.5003,  1.3323, -2.3065,\n",
      "          0.3714, -0.6167, -0.5781, -0.6736,  0.3670,  0.8134,  0.3135, -0.0350,\n",
      "          1.0866, -0.5966,  0.3502,  0.1307,  0.5635, -0.5767, -3.0500,  2.6736,\n",
      "         -0.2046,  0.2138,  0.5517, -1.4275,  0.1886,  0.5301,  0.7130,  2.0399,\n",
      "         -0.7452, -0.3221,  1.9052, -0.9309, -0.0730, -1.5978,  0.2386, -0.0865,\n",
      "          0.6659,  0.6022, -0.0099, -0.8217,  1.4468, -2.4746,  0.2634,  0.0781,\n",
      "          1.0199, -0.4139,  1.8974, -0.9764, -1.7480, -1.0423, -0.5602, -2.2133,\n",
      "         -0.8564,  1.7849, -0.4144,  0.2921,  0.6288, -0.5380,  0.1523, -0.2512]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 5\n",
      "tensor([[-0.1778]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 6\n",
      "Batch\n",
      "tensor([[   0, 3226,  347, 5214,  347,  347,  347,  347, 3226,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 8.0097e-01, -2.3588e+00, -9.4002e-01,  9.1537e-01, -2.8445e-01,\n",
      "         -1.4898e+00, -1.9576e+00, -1.0771e+00, -2.4009e-01, -5.3505e-01,\n",
      "         -2.1407e-01,  6.3307e-01, -3.7510e-01, -1.5097e+00, -8.6477e-01,\n",
      "          7.7897e-01,  2.1977e+00,  9.7886e-01, -7.3882e-01,  5.2282e-01,\n",
      "         -1.4822e-01,  8.8813e-01,  5.1067e-01,  8.2132e-01,  1.0069e+00,\n",
      "          1.7577e-01,  2.9904e-01, -1.4226e-01, -9.8972e-02,  2.7316e-01,\n",
      "          3.0184e-01, -3.8088e-01,  5.2043e-01,  6.0332e-01,  2.2400e-01,\n",
      "          1.0943e+00,  3.6645e-01,  1.5723e-01, -1.3183e+00, -7.0115e-01,\n",
      "          1.6089e+00,  7.5465e-01, -4.1092e-01, -1.1922e+00,  1.2651e+00,\n",
      "          3.1202e-01, -1.6264e+00,  1.9055e+00, -5.9628e-01, -3.3397e-02,\n",
      "          1.0464e-01, -3.5610e-01,  9.4829e-01, -9.8866e-02, -3.0607e-01,\n",
      "          1.6660e+00,  8.4230e-01, -8.8472e-02, -1.1042e+00, -5.4716e-02,\n",
      "          6.5665e-01, -6.0953e-01,  1.6916e-01, -6.2670e-01, -1.6966e+00,\n",
      "          1.4365e-02, -8.8030e-01, -1.0992e+00,  5.7165e-01,  2.5520e-01,\n",
      "          8.4346e-01,  3.8853e-01,  1.2255e+00, -2.4505e+00, -3.7699e-01,\n",
      "         -1.8867e-01, -2.6972e-01,  5.4604e-01,  1.7861e-01,  4.7448e-01,\n",
      "         -5.9331e-01,  3.8525e-01,  1.5556e-01, -6.2092e-02, -4.9215e-01,\n",
      "         -3.0214e-02, -3.4712e-02, -2.2124e+00,  9.4724e-02,  6.4140e-01,\n",
      "          1.7016e+00,  5.5780e-02,  8.6022e-02,  3.3949e-01, -5.1627e-01,\n",
      "          6.3265e-02,  5.8358e-01, -8.8028e-01, -5.6869e-01,  1.8742e+00,\n",
      "         -4.8993e-01,  7.6679e-01, -3.9829e-01,  2.2479e+00,  1.6400e+00,\n",
      "          9.1112e-02,  8.2996e-01, -3.3235e-01, -4.3888e-01, -8.8438e-01,\n",
      "         -1.3926e+00,  3.5276e-01,  2.3146e-01,  1.0165e+00,  2.0796e-01,\n",
      "          1.4766e+00, -2.5877e-03,  1.0985e+00,  1.7390e-02, -3.4079e-01,\n",
      "         -3.3650e-01, -4.5527e-01, -1.1595e+00,  1.9254e+00,  1.5021e-01,\n",
      "         -3.4166e-01,  6.0567e-01, -6.0738e-01, -4.8988e-01, -6.4627e-02,\n",
      "         -5.2631e-01, -1.5698e-01,  4.6346e-01, -8.8842e-01,  6.1391e-01,\n",
      "          2.7702e-01, -2.6937e+00, -1.1150e+00, -7.3602e-01, -4.1752e-01,\n",
      "         -2.1163e+00,  8.3451e-01, -7.0105e-01,  9.3579e-01,  5.0393e-01,\n",
      "         -7.3060e-01, -6.2215e-01, -1.4002e+00, -1.6818e+00, -5.2927e-02,\n",
      "          1.5749e+00, -7.8542e-01,  1.8802e+00, -1.2615e+00, -6.9045e-01,\n",
      "          7.4950e-01, -2.7714e-01, -4.1633e-01,  6.5463e-01,  1.3170e-01,\n",
      "         -3.4214e-02,  1.5158e+00, -6.2253e-01, -2.8671e-01,  1.9751e-01,\n",
      "          4.7585e-02,  1.8274e-01,  8.2884e-01, -2.0659e-01, -1.9838e-01,\n",
      "         -3.6876e-01,  7.4466e-01,  5.1403e-01, -1.6848e+00, -1.8367e+00,\n",
      "          8.1330e-01, -2.6858e-01,  1.9242e-01,  1.6053e+00,  2.9399e-01,\n",
      "          2.2239e-01, -1.2900e-01,  1.0767e+00, -1.5738e+00,  1.9318e+00,\n",
      "         -1.3424e+00,  9.3413e-01,  1.6621e-01, -1.1492e-01,  1.3223e+00,\n",
      "          1.6235e+00,  1.1005e+00, -9.1510e-02, -1.0160e+00, -6.6489e-01,\n",
      "          1.1367e+00, -2.1037e-01,  1.2560e+00,  8.5180e-01,  3.8561e-01,\n",
      "          9.2075e-01, -3.9819e-01, -1.2795e+00, -2.7067e-01,  4.5864e-02,\n",
      "          6.0683e-01, -1.1762e+00, -1.7876e-01,  5.8964e-02,  4.6562e-01,\n",
      "         -2.8137e-01,  8.3528e-01, -5.7366e-02, -1.2914e+00,  1.2379e+00,\n",
      "          2.1081e+00,  6.5448e-02, -5.0058e-01, -7.2609e-01,  1.6027e-01,\n",
      "          1.4806e+00, -1.5856e+00, -3.6401e-01, -9.1572e-01,  2.7995e-01,\n",
      "          8.9594e-01, -2.3128e-02, -4.6517e-01, -1.2571e-02,  1.0022e+00,\n",
      "          2.0888e+00,  1.4113e+00, -9.4195e-01,  1.8067e-01, -3.4431e-01,\n",
      "          1.4279e+00,  9.2620e-01, -5.4887e-01,  2.0759e+00, -9.2186e-01,\n",
      "          1.2555e+00,  3.4539e-01,  1.2391e+00,  2.5903e-01,  3.7404e-01,\n",
      "          2.4837e-02,  2.3909e-01,  2.3568e-01, -2.9004e-03,  9.0547e-01,\n",
      "         -7.8734e-01, -1.9398e+00,  1.7300e-01,  2.9403e-01, -1.2151e+00,\n",
      "          9.8063e-01,  6.1145e-01, -4.6069e-01, -1.2297e+00, -1.9278e+00,\n",
      "          2.1076e-01,  2.9180e-01,  1.5403e+00,  1.1598e-01, -1.8559e+00,\n",
      "         -1.5652e+00, -7.6561e-02, -7.4255e-01,  9.0669e-01,  2.1128e-01,\n",
      "          6.6973e-01, -2.2598e+00,  1.2799e+00, -6.0981e-01, -3.7297e-01,\n",
      "          1.6381e+00, -1.2671e+00,  1.3824e+00, -4.3413e-01,  3.1916e-02,\n",
      "         -1.1919e+00,  4.5978e-02,  1.1842e-01, -6.1311e-01, -6.4460e-01,\n",
      "         -1.5024e+00,  1.4759e+00, -1.4637e+00, -1.0651e+00, -5.0431e-01,\n",
      "         -1.7115e+00,  5.7809e-01,  2.3497e+00, -2.0189e+00,  1.5454e+00,\n",
      "         -2.6652e+00,  8.1240e-01,  7.5362e-01, -4.9906e-01,  1.7897e-01,\n",
      "         -1.2130e+00, -3.4923e-01, -8.5218e-01,  6.9093e-01,  4.1789e-01,\n",
      "         -2.6530e-01,  4.3859e-01,  2.3075e-01,  1.4174e+00, -6.0809e-01,\n",
      "         -6.1383e-02,  7.8517e-01,  3.4116e-02, -3.2240e-01,  3.4299e-01,\n",
      "         -1.1444e+00, -1.8358e+00, -1.6144e+00, -7.7332e-02, -9.2278e-01,\n",
      "         -1.6150e-01,  8.2744e-01,  1.0866e+00,  7.4283e-01,  7.8558e-01,\n",
      "         -8.3932e-01, -2.0014e+00,  1.4995e+00, -2.5611e+00,  5.7618e-01,\n",
      "         -7.5339e-01, -1.2980e+00,  1.9575e+00,  1.0190e+00,  1.1816e+00,\n",
      "         -2.1165e-02,  1.6221e-02,  1.0312e+00,  1.2700e+00, -3.2988e-01,\n",
      "         -6.6470e-02,  7.8682e-01,  2.1370e+00,  1.6736e+00, -1.3627e+00,\n",
      "         -5.9330e-01,  9.0611e-01, -5.1724e-01,  1.5935e+00, -5.6839e-01,\n",
      "          1.3451e+00, -2.0015e+00,  3.4467e-01,  3.7064e-01,  1.1662e+00,\n",
      "         -7.5177e-01,  9.7173e-01, -1.2063e+00,  1.1533e+00, -1.1815e+00,\n",
      "         -6.5730e-01,  2.1478e-01, -2.9331e-01,  1.2698e+00, -2.1147e+00,\n",
      "         -1.1718e+00,  6.9662e-01,  1.0593e+00, -4.7492e-01, -6.9652e-01,\n",
      "          6.6201e-01,  6.1952e-01,  2.1054e+00, -8.6072e-01, -5.7622e-01,\n",
      "          5.8033e-01, -5.5481e-01, -3.7616e-03, -4.6150e-01, -1.9308e+00,\n",
      "          1.2551e-01, -1.3356e+00, -6.9127e-01,  8.9276e-01,  9.9925e-01,\n",
      "          6.1506e-01, -5.3027e-01,  3.4418e-02, -9.2594e-01,  1.1713e+00,\n",
      "          1.4999e+00,  6.1832e-01, -2.2539e+00,  2.9505e-01, -1.4584e+00,\n",
      "          7.9069e-01,  2.4783e-01,  3.0529e-01,  1.2060e+00, -4.2076e-01,\n",
      "         -1.5196e+00, -1.6766e-02,  2.2300e-01,  2.4965e+00,  2.4533e-01,\n",
      "          1.3923e+00, -2.7846e-01, -4.0998e-01,  1.4553e+00, -3.0568e-01,\n",
      "          2.3136e-02,  1.1262e+00, -1.9277e+00, -1.4799e+00, -3.0774e-02,\n",
      "          1.7548e-01, -8.0404e-02, -1.1520e+00,  8.6199e-01,  2.2113e-01,\n",
      "          1.8004e+00,  3.1668e-01, -1.7557e-01,  5.2167e-01,  8.0871e-01,\n",
      "         -2.3164e+00,  8.0150e-01,  1.5104e+00, -4.2295e-02, -9.1418e-01,\n",
      "          2.9654e-01, -8.7652e-01, -1.8285e+00,  1.7236e+00,  5.5425e-01,\n",
      "         -2.2880e+00,  3.3964e-01,  7.1335e-01,  4.4648e-01, -4.0991e-02,\n",
      "          1.8141e+00,  9.1541e-01,  7.7411e-01,  1.5832e+00,  1.2898e+00,\n",
      "         -1.0363e-01, -1.3874e+00,  7.7675e-01, -4.5090e-01, -2.1792e+00,\n",
      "          6.9294e-01,  1.4248e-01,  1.5992e+00,  1.0969e+00, -2.1320e+00,\n",
      "          1.3394e+00,  6.8245e-02, -1.2978e+00,  2.2118e-01, -4.7819e-01,\n",
      "         -2.3686e-02,  2.1137e-01, -5.3045e-01,  9.0171e-01, -1.2437e+00,\n",
      "         -1.3380e+00, -8.6421e-01,  2.6981e-01,  3.1086e-01, -6.2468e-01,\n",
      "          2.5868e+00,  1.8531e+00,  6.1382e-01,  6.0514e-01,  8.1715e-01,\n",
      "         -6.6546e-01,  1.2028e+00,  1.4562e+00,  1.0775e+00, -5.7500e-01,\n",
      "         -3.9362e-02,  1.2423e+00,  3.1436e-01,  1.3346e+00,  4.9817e-01,\n",
      "         -1.0616e+00,  7.0365e-01, -1.4177e+00,  6.5494e-01,  2.8615e-01,\n",
      "         -4.4137e-01, -3.7675e-01,  3.5578e-01, -7.8707e-01, -9.3846e-01,\n",
      "          1.4125e+00, -5.0466e-02,  5.1608e-01,  7.5785e-01, -8.7187e-01,\n",
      "         -2.6074e-02, -1.0747e-02,  1.8896e+00, -1.3228e+00,  4.5998e-01,\n",
      "         -6.4305e-01,  8.4892e-01, -2.4729e-01,  3.9132e-01,  1.5089e+00,\n",
      "         -3.3480e-01,  3.1941e-01,  4.6243e-01,  2.2411e-01, -5.3132e-01,\n",
      "         -4.8120e-01,  1.2979e+00,  1.7449e+00,  1.1430e+00, -1.3537e-01,\n",
      "         -9.3415e-01,  7.5052e-01,  2.6525e-01,  8.6321e-01,  9.2709e-01,\n",
      "         -3.2299e-01,  9.3760e-02,  1.4452e-01, -3.8962e-01, -6.2749e-01,\n",
      "         -9.9120e-01,  4.8716e-01, -5.1642e-01,  1.3570e-01,  3.3295e-01,\n",
      "         -1.0613e+00,  3.5580e-01, -1.0381e-01,  8.6414e-01,  2.1194e+00,\n",
      "          4.8401e-01, -2.8520e-01,  4.0104e-01, -6.6336e-01, -1.2540e+00,\n",
      "          1.3890e+00, -1.3819e+00, -2.6117e-01,  3.4059e-01, -2.0581e+00,\n",
      "         -3.2222e-01,  8.8629e-02,  5.6555e-01, -4.4085e-01,  2.9618e-01,\n",
      "         -5.7122e-01,  2.0847e+00, -7.4090e-01,  4.8350e-01,  7.7891e-01,\n",
      "         -4.3658e-01, -5.8274e-01, -1.2868e+00, -1.0918e+00, -1.9862e-01,\n",
      "          7.1707e-01, -9.2772e-01, -3.1105e-01,  1.3726e-01, -1.0483e+00,\n",
      "         -6.1665e-02,  7.4982e-01,  5.6293e-01,  1.5943e+00,  3.9830e-01,\n",
      "         -7.0131e-01, -6.4936e-02, -1.5464e-01,  9.3667e-01,  1.1028e+00,\n",
      "          6.3079e-02, -2.2320e-01, -7.7522e-01, -2.0019e+00, -3.0084e-01,\n",
      "          6.9055e-01,  9.9852e-01,  5.5089e-01, -1.0849e+00, -8.4088e-02,\n",
      "         -3.2827e-01, -2.4445e+00,  7.8052e-01, -2.0686e-01,  5.8932e-01,\n",
      "          8.9231e-01, -1.3519e+00,  1.9286e+00, -4.9405e-01, -1.3896e-01,\n",
      "          8.1672e-01,  9.9932e-01, -1.3859e+00,  7.8147e-02, -1.6265e+00,\n",
      "         -3.8760e-01, -1.1140e+00, -4.2716e-01,  7.9121e-01,  9.2672e-01,\n",
      "         -1.0621e+00,  9.3538e-01,  1.9642e-01,  2.5828e-01, -1.3195e+00,\n",
      "         -8.9657e-01, -5.2060e-01, -1.0317e+00,  7.1562e-01,  1.3550e-01,\n",
      "         -4.3465e-01,  1.9256e+00,  5.4229e-02,  5.0730e-01, -1.4913e-01,\n",
      "          3.8817e-02,  3.4720e-01, -1.3089e+00, -1.3965e+00, -5.8982e-01,\n",
      "          5.6361e-01, -7.2333e-01,  1.2803e+00, -1.2257e+00, -5.4041e-01,\n",
      "          6.8717e-01,  8.0341e-01, -9.8212e-01, -1.6134e-01, -4.4887e-01,\n",
      "         -4.0002e-01,  7.3285e-01, -2.3216e-01, -5.3084e-02, -1.0615e+00,\n",
      "         -9.3108e-01, -7.6442e-01, -5.5057e-01, -1.6202e+00, -3.0443e-01,\n",
      "         -2.3601e-01,  1.6690e+00,  1.0769e+00,  1.7203e+00,  6.6790e-01,\n",
      "          4.1387e-01, -2.7422e-01,  5.8845e-01, -1.2754e-01,  3.4425e-02,\n",
      "         -1.2164e+00,  1.0120e+00,  2.2407e-01, -1.3169e+00,  7.2577e-02,\n",
      "          1.3432e+00, -1.6660e+00, -2.2810e-01, -1.0208e+00, -1.5976e-02,\n",
      "         -1.5176e+00,  9.9824e-01, -1.5095e+00, -1.3884e+00,  9.5294e-01,\n",
      "         -2.2258e-01,  3.9418e-01, -1.0743e+00, -1.5106e+00,  6.9481e-01,\n",
      "         -3.5451e-01, -1.0905e+00, -8.1796e-01, -8.3453e-02, -4.5399e-01,\n",
      "          1.7651e+00,  1.7056e+00,  2.4924e-01,  4.6635e-01, -4.3163e-01,\n",
      "          1.0149e+00,  5.0146e-01,  1.1577e+00,  5.9831e-02, -1.2076e+00,\n",
      "         -4.9987e-01, -2.0767e+00, -9.2106e-01,  5.0309e-01,  1.5820e+00,\n",
      "          2.7362e-01, -1.4887e+00,  2.9331e-01, -5.3303e-01, -8.2980e-01,\n",
      "          3.6520e-01, -1.2993e+00,  1.2399e+00, -1.6761e-01, -1.1601e+00,\n",
      "          8.1085e-01, -2.1097e+00,  6.5369e-01, -3.6318e-01, -5.9047e-01,\n",
      "         -6.6655e-01,  4.3069e-01,  2.8207e-01, -1.1292e-01,  6.1196e-02,\n",
      "          2.3377e-03, -5.8842e-01,  2.5004e-01,  4.6372e-02,  7.1137e-01,\n",
      "         -1.6779e-01, -3.3963e+00,  2.4384e+00, -6.5305e-01, -1.2421e+00,\n",
      "         -5.2436e-01, -6.9440e-01,  2.6133e-01,  6.0080e-01,  1.6819e-01,\n",
      "          1.1664e+00, -1.0611e+00,  4.7890e-02,  2.1414e+00, -1.1168e+00,\n",
      "         -5.1297e-01, -2.2263e+00, -4.8447e-01,  8.1778e-02,  7.5520e-01,\n",
      "         -6.9148e-02,  1.2001e+00, -3.0194e-01,  2.6162e+00, -2.6298e+00,\n",
      "         -3.5872e-01, -3.3928e-01,  1.0224e+00, -1.0655e-01,  1.5292e+00,\n",
      "         -1.1844e+00, -9.0050e-01, -7.8392e-01, -2.0861e+00, -1.7468e+00,\n",
      "         -3.3374e-01,  1.2171e+00, -4.7630e-01,  1.1028e+00,  1.4250e+00,\n",
      "         -9.8959e-01, -6.5631e-01, -9.3383e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 6\n",
      "tensor([[-0.0928]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 7\n",
      "Batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 0.8208, -1.6984, -0.7908,  0.9180, -0.3734, -0.5050, -2.6276, -1.3768,\n",
      "         -0.2347, -0.6648, -0.0126,  0.0626, -0.5264, -1.9604, -1.1067,  0.6111,\n",
      "          2.0304,  1.5295, -1.1764,  2.1835, -0.3581,  1.4110,  0.0748,  1.0181,\n",
      "          1.2720, -0.0400,  0.7536, -0.5156,  0.0088,  0.1932, -0.0206, -0.8059,\n",
      "          1.8167,  0.3852,  0.1656, -0.6900, -0.0750, -0.1961, -0.9424, -1.0981,\n",
      "          1.2944,  0.5761,  0.1136, -1.2303,  1.2950,  0.2648, -1.2536,  1.2749,\n",
      "         -0.7341, -0.2735, -0.2393, -0.1573,  0.6060,  0.3056, -0.8578,  0.8435,\n",
      "          1.2756,  0.1238, -0.4095, -0.2139,  0.7446, -0.4822, -0.2767, -0.5197,\n",
      "         -1.4241,  0.2843, -0.7426, -1.0099, -0.0718,  0.7088,  0.1485,  0.8810,\n",
      "          1.2733, -2.6984, -0.3485,  0.5552,  0.0067, -0.5346, -0.1637, -0.8985,\n",
      "         -0.5337,  0.4306,  0.4344, -0.1871, -0.5196, -0.0508, -0.3493, -1.9405,\n",
      "          1.0266,  0.6730,  0.7168, -0.3808,  0.3268, -0.0573, -0.4079,  0.4502,\n",
      "          1.0175, -1.0410, -0.4026,  1.7590, -1.4595,  0.3699,  0.4269,  3.1588,\n",
      "          1.9962,  0.0419,  2.3962, -0.3405, -0.0497, -1.0049, -1.3647,  0.6659,\n",
      "          0.6937,  0.9209,  1.2671,  1.0423,  0.1611,  1.0483,  0.4000, -0.9372,\n",
      "         -0.0611, -0.1592, -1.5691,  2.0396,  0.1683, -0.2110,  0.8523, -0.6160,\n",
      "         -0.2965, -0.8452, -0.8814, -0.1026,  0.2693, -1.2605,  1.0834, -0.0252,\n",
      "         -1.1415, -0.6805, -0.8766, -1.0232, -1.0819,  0.4063,  0.5066,  0.3474,\n",
      "          1.3407, -0.5477, -0.8264, -0.4947, -1.1600,  0.6490,  1.2448, -0.8166,\n",
      "          1.6338, -1.2356, -1.2337,  1.2568, -0.7059, -0.4318,  1.3791,  0.4588,\n",
      "          0.5210,  1.8964, -1.2636, -0.0467,  0.0782, -1.1656,  0.0742,  1.3986,\n",
      "         -0.1374,  0.1089,  0.6295,  1.1237,  0.2661, -1.1719, -2.5247,  1.0668,\n",
      "         -0.2661, -0.1918,  1.3766,  0.0826,  0.0205, -0.3091,  1.1275, -1.5773,\n",
      "          1.3923, -1.5071,  1.2073,  0.3145,  0.4141,  0.3715,  0.9452,  1.9907,\n",
      "          0.4366, -0.5275, -0.1883,  1.1829, -0.3410,  1.0356,  1.2991, -0.0495,\n",
      "          1.0899, -0.6094, -1.7994,  0.4003, -0.5895,  0.3370, -0.9399, -0.4194,\n",
      "          0.1177,  0.1822, -0.7760,  0.2865,  0.4277, -1.4899,  1.6817,  2.2572,\n",
      "          0.2280, -0.2915, -0.4603, -0.1832,  1.3945, -1.2164, -0.4320, -0.3960,\n",
      "         -0.2874,  0.8250, -0.5316, -0.8209, -0.2307,  0.8493,  1.3091,  1.6114,\n",
      "         -0.6857, -0.1030, -0.5345,  2.2649,  0.6359, -0.2489,  1.7149, -0.2130,\n",
      "          1.4439, -0.0918,  0.1513,  0.5280, -0.0202, -0.0992,  0.1479,  0.4972,\n",
      "         -0.3088,  0.3202,  0.0270, -1.1303,  0.1879,  0.5879, -1.3556,  0.6222,\n",
      "          0.5594, -0.2407, -1.5171, -1.9202, -0.5275,  0.3293,  1.1021, -0.2730,\n",
      "         -2.1617, -0.8727,  0.0880, -0.7523,  0.1547, -0.9622,  1.2321, -1.5031,\n",
      "          2.0393, -0.9311, -1.0428,  0.9441, -2.0174,  0.8119, -0.2865, -0.2164,\n",
      "         -1.0350,  0.1330,  0.2735,  0.1381,  0.1680, -2.0432,  1.8856, -1.8761,\n",
      "         -0.0476, -0.8428, -1.8423,  0.6751,  2.5010, -1.7321,  1.8428, -1.2793,\n",
      "         -0.5539,  0.7177,  0.0503, -0.1226, -1.3887,  0.1043, -0.2501,  0.9935,\n",
      "         -0.0455,  0.1060,  0.9947, -0.4318,  1.9730, -0.6729,  0.1311,  0.1371,\n",
      "         -0.1611, -0.1582, -0.2754, -0.7907, -1.8046, -1.1411, -0.0413, -0.1191,\n",
      "          0.3291,  1.1031,  1.2419,  0.4613,  0.9669, -1.2708, -2.2704,  1.6653,\n",
      "         -2.2436,  1.2540, -0.8850, -1.7180,  1.5609,  1.0757,  0.6620, -0.2243,\n",
      "          0.4860,  0.5882,  0.5188, -0.4910, -0.0169,  1.2494,  1.4604,  1.3791,\n",
      "         -1.0319, -0.6218,  0.6210, -0.8100,  1.7292, -0.2110,  1.5273, -1.7922,\n",
      "          0.6541,  0.0773,  0.9780, -0.7898,  1.6921,  0.1601,  1.0051, -1.4283,\n",
      "         -0.3532,  0.3133, -0.3599,  1.4014, -2.4825, -0.3592,  1.5701,  1.5323,\n",
      "          0.3305, -0.1986,  0.9220,  0.4722,  1.4498, -1.4554, -0.3798,  0.2128,\n",
      "         -0.6210, -0.2457, -0.7708, -2.1619, -0.0326, -1.7269, -0.0180,  0.8483,\n",
      "          0.1444, -0.4219, -0.6662,  0.3612, -0.6794,  0.7407,  1.6152,  0.1656,\n",
      "         -2.5935,  0.6834, -1.5613,  1.2554,  0.6775, -0.0346,  0.7859, -0.8339,\n",
      "         -1.7011, -0.7857, -0.5703,  0.7639,  0.0306,  0.2417, -0.7039,  0.0303,\n",
      "          1.4650, -0.8895,  0.5288,  0.5469, -1.5291, -1.7519,  0.0113, -0.2582,\n",
      "          0.1524, -1.0890,  0.7465,  0.4344,  1.7820,  0.5894,  0.1712,  1.3182,\n",
      "          0.5701, -1.7951,  0.9793,  1.0692,  0.6365, -1.1257,  1.0631, -0.3088,\n",
      "         -1.8991,  1.7256,  0.4064, -1.9403,  0.3657, -0.0032,  0.4140, -0.4222,\n",
      "          1.4891,  0.8716,  0.5124,  1.1585,  0.9047, -0.8098, -1.5593,  0.4851,\n",
      "          0.2622, -1.6652,  1.0538,  0.7137,  1.3065,  0.9943, -1.8358,  1.1117,\n",
      "         -0.3838, -0.9612,  0.9073, -1.8321,  0.0716,  0.7702, -0.3452,  1.0445,\n",
      "         -0.7386, -1.4020, -0.2324, -0.4448,  0.6920, -0.9846,  2.3878,  1.8512,\n",
      "          0.9039,  0.9747,  0.3385, -0.8336,  1.2205,  0.2208,  1.4002, -0.4444,\n",
      "          0.3235,  1.3238, -0.1174,  1.2926,  0.5945, -0.7085,  1.3416, -2.3309,\n",
      "          0.1190,  0.4438, -0.1683, -0.2530,  0.1915, -0.3986, -0.4972,  1.7505,\n",
      "          0.1399,  0.5947,  1.0076, -0.6041, -0.1365,  0.0051,  1.5438, -1.5856,\n",
      "          0.8200, -0.1553, -0.3990,  0.1729,  0.9237,  1.2797,  0.3447,  1.4990,\n",
      "          0.5756,  0.0323,  0.3465, -0.8960,  0.8318,  1.7807,  0.0746,  0.2005,\n",
      "         -1.0616,  1.1282,  0.3841,  0.9710,  1.1893, -0.1632,  0.8603,  0.6471,\n",
      "         -0.6589, -0.5715, -0.2167,  0.5271, -0.7700, -0.0282,  0.0286, -0.3575,\n",
      "          0.0958,  0.0773, -0.3102,  2.0582,  0.7664, -0.5241,  0.4800, -0.0957,\n",
      "         -1.3319,  1.1382, -1.0713, -0.1954,  0.6163, -1.5915, -0.0139,  0.2294,\n",
      "         -0.9069, -0.6614,  0.6878, -0.5044,  1.8570, -1.1224,  0.7155,  0.8181,\n",
      "          0.0553, -0.9544, -1.5175,  0.1759, -0.6534,  0.4220, -1.0912, -0.4928,\n",
      "          0.0126, -1.5468, -0.2166,  0.7037, -0.0340,  1.6086,  0.1797, -0.0272,\n",
      "          0.0450, -0.3900,  0.7568,  0.4762, -0.0619, -0.1283, -0.4336, -2.5321,\n",
      "          0.1714,  0.4546,  1.2094,  0.3720, -1.0325, -0.0213,  0.1798, -2.4422,\n",
      "          0.4679, -0.2468,  1.1336,  0.4754, -0.6474,  1.2640, -0.8847, -1.3149,\n",
      "          0.8250,  0.6035, -1.3394,  0.1375, -1.5516, -0.9032, -0.9690, -0.5084,\n",
      "          1.1260,  0.4218, -0.7570,  0.7090,  0.5159, -0.5746, -1.0013, -0.1823,\n",
      "         -2.0515, -0.3349, -0.0589, -0.4830,  0.2591,  2.4130, -0.0888,  0.7201,\n",
      "         -0.4513,  0.0372,  0.0609, -0.6011, -0.6555, -1.1746,  1.0027, -0.3277,\n",
      "          1.5025, -0.8120, -0.6126,  0.8183,  0.4163, -1.1928, -0.8216, -0.2119,\n",
      "         -0.8898,  0.1669, -0.8376, -0.0171, -0.5898, -1.0313, -0.7394, -0.1892,\n",
      "         -1.4076, -0.4921, -0.1794,  1.3874, -0.6156,  1.9741,  0.4429,  0.5184,\n",
      "         -0.4736,  0.8553, -0.4770, -0.3430, -0.9832,  1.1946,  0.5796, -2.0783,\n",
      "         -0.2730,  1.7516, -1.1637,  0.0901, -1.6314,  0.1001, -1.2261,  1.3358,\n",
      "         -1.6021, -1.3197,  0.7694,  0.4854,  0.9345, -1.0257, -1.2333, -0.2068,\n",
      "          0.0735, -0.5833, -0.6330,  0.0132, -0.1198,  2.2860,  1.6574, -0.5975,\n",
      "          0.8952, -0.5026,  0.3477, -0.3441,  0.6008, -0.1585, -1.1639, -0.0433,\n",
      "         -2.4166, -0.2078,  0.9100,  1.1887, -0.4092, -2.1815,  0.6554, -0.7649,\n",
      "         -0.7060,  0.2099, -0.5407,  0.8924,  0.1625, -0.8996,  0.5675, -2.0588,\n",
      "          0.0171, -0.5575, -0.8179, -1.5158,  0.2300,  0.8358,  0.1461,  0.1487,\n",
      "          0.6904, -0.9200,  0.3346,  0.3016,  0.4421, -0.6977, -2.4799,  2.7628,\n",
      "         -0.6320, -0.8168,  0.8268, -0.4382,  0.1793,  0.4371, -0.0963,  1.8571,\n",
      "         -0.9712, -0.7957,  1.6659, -0.8838, -0.4095, -1.9443, -0.2122, -0.7710,\n",
      "          0.6988,  0.5902,  0.4736, -0.4752,  1.9541, -2.2327,  0.1821,  0.1028,\n",
      "          0.6819,  0.0043,  1.3996, -1.2370, -1.3606, -1.1064, -0.7972, -1.0603,\n",
      "         -0.7568,  2.2721, -0.7932,  0.8654,  0.5140, -0.8102, -0.9490, -0.6050]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 7\n",
      "tensor([[-0.2364]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 8\n",
      "Batch\n",
      "tensor([[   0, 3226,  347, 5214,  347,  347,  347, 3226,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 1.1787e-01, -1.8342e+00, -1.1399e+00,  2.3944e-01, -4.3666e-01,\n",
      "         -1.2264e+00, -2.6622e+00, -9.1477e-01,  8.5663e-02, -9.0540e-01,\n",
      "         -3.3260e-02,  5.3155e-01, -9.2207e-01, -1.5047e+00, -9.8681e-01,\n",
      "          5.2772e-01,  1.9081e+00,  1.3240e+00, -1.4456e+00,  1.4553e+00,\n",
      "         -2.9999e-01,  9.8586e-01,  6.6720e-01,  1.0558e+00,  1.1903e+00,\n",
      "         -7.7465e-01,  4.0082e-01, -4.6296e-01, -3.0666e-01,  1.7321e-02,\n",
      "         -2.6112e-02, -8.4926e-02,  2.4772e-01, -9.6807e-02,  2.5323e-01,\n",
      "          8.8878e-01,  6.7592e-01,  1.7267e-01, -1.0844e+00, -2.5901e-01,\n",
      "          1.0404e+00,  6.8411e-01, -5.9894e-01, -1.1843e+00,  7.0478e-01,\n",
      "          9.3193e-01, -1.9878e+00,  1.7975e+00, -7.6024e-01, -2.7626e-01,\n",
      "         -1.4276e-01, -5.2466e-02,  7.9469e-01,  5.9100e-02, -2.5116e-01,\n",
      "          1.8189e+00,  5.5111e-01, -5.9324e-02, -8.9557e-01, -9.9502e-02,\n",
      "          6.6799e-01, -3.4183e-01, -3.4858e-01, -6.1465e-01, -2.1080e+00,\n",
      "          1.5401e-01, -4.8439e-02, -1.3225e+00,  4.0497e-01, -2.5241e-01,\n",
      "          9.0483e-01,  3.5647e-01,  5.1498e-01, -2.6030e+00, -5.4899e-01,\n",
      "          2.0831e-03,  1.5207e-01,  4.7651e-01,  1.9220e-01, -1.2078e+00,\n",
      "         -3.5992e-01,  8.9369e-02,  2.5565e-01,  1.9876e-01, -6.0528e-01,\n",
      "         -4.0274e-01, -2.7979e-01, -2.1088e+00,  5.6103e-01, -6.7154e-02,\n",
      "          1.5174e+00, -4.2422e-01,  6.5165e-01,  1.5373e-01, -5.9086e-01,\n",
      "          9.9865e-01,  7.4035e-01, -7.7907e-01, -1.0232e+00,  2.0724e+00,\n",
      "         -1.6121e+00,  8.7700e-01, -3.6123e-01,  1.8550e+00,  1.5559e+00,\n",
      "          2.9841e-01,  2.1069e+00,  3.3860e-01,  2.1493e-01, -7.4365e-01,\n",
      "         -8.0869e-01,  2.9579e-01,  1.1846e+00,  1.1224e+00, -7.1755e-01,\n",
      "          1.9775e+00, -1.9194e-01,  1.0001e+00,  4.1600e-01, -2.9828e-01,\n",
      "         -7.4251e-01, -1.0396e-02, -1.2669e+00,  2.0537e+00, -4.5125e-01,\n",
      "         -2.2774e-01,  6.9233e-01, -1.0498e-02,  6.0152e-01, -1.9298e-01,\n",
      "         -7.7291e-01,  4.6759e-02,  8.2362e-01, -6.9472e-01,  7.0047e-01,\n",
      "          2.7858e-01, -2.3347e+00, -8.4684e-01, -4.5949e-01, -6.6292e-01,\n",
      "         -7.8677e-01, -2.2693e-02, -9.0453e-01,  5.7927e-01,  1.0000e+00,\n",
      "         -9.6972e-01, -3.9219e-01, -1.3965e+00, -1.5021e+00,  6.3084e-01,\n",
      "          1.2032e+00, -4.5939e-01,  1.6392e+00, -1.2320e+00, -1.0477e+00,\n",
      "          8.4454e-01, -3.3354e-01, -2.3700e-01,  1.1762e+00,  6.0508e-01,\n",
      "         -3.1086e-01,  8.9412e-01, -6.4933e-01,  3.2277e-01,  3.4473e-01,\n",
      "          4.2026e-02,  1.8070e-01,  1.0142e+00, -4.2600e-01, -7.1604e-01,\n",
      "          1.5959e-01,  9.2613e-01,  3.8242e-01, -7.1742e-01, -1.8408e+00,\n",
      "          6.5943e-01, -5.3758e-01,  1.4156e-01,  1.6174e+00,  4.3130e-01,\n",
      "         -3.2404e-01, -6.3657e-01,  8.3802e-01, -7.5017e-01,  1.1087e+00,\n",
      "         -1.2309e+00,  9.1591e-01,  3.9554e-02, -5.5937e-01,  1.0187e+00,\n",
      "          1.8011e+00,  1.4564e+00, -4.9139e-02, -4.0454e-01, -2.7401e-01,\n",
      "          7.0084e-01,  1.8828e-01,  2.3987e-01,  1.3836e+00, -5.3661e-02,\n",
      "          1.1671e+00, -9.3076e-01, -1.1409e+00,  9.2519e-02, -1.5891e-01,\n",
      "          5.7774e-01, -9.1148e-01, -1.0037e-01,  7.6875e-03,  2.6923e-01,\n",
      "         -5.3373e-01,  3.4372e-01,  1.7149e-01, -8.5700e-01,  5.1351e-01,\n",
      "          1.9965e+00,  2.8596e-01, -7.8566e-01, -4.4526e-01,  6.0608e-01,\n",
      "          1.5473e+00, -1.3276e+00, -3.7027e-01, -5.8721e-01, -2.4084e-01,\n",
      "          1.1733e+00, -2.3923e-01, -6.1589e-01, -2.9639e-01,  1.1422e+00,\n",
      "          2.6060e+00,  1.3556e+00, -7.9523e-01,  1.9386e-01, -2.9343e-01,\n",
      "          2.0709e+00,  9.0448e-01, -5.5133e-01,  2.3382e+00, -7.6738e-01,\n",
      "          1.7368e+00,  3.4021e-01, -7.4034e-02,  1.0337e-01, -4.7877e-01,\n",
      "         -1.8678e-01,  6.4425e-01,  2.8743e-01, -9.2962e-01,  3.0830e-01,\n",
      "         -3.9386e-02, -1.1878e+00,  2.7722e-01,  3.8463e-01, -1.2044e+00,\n",
      "          1.1138e+00,  6.1370e-01, -4.6189e-01, -1.1615e+00, -1.2004e+00,\n",
      "         -3.1038e-01,  8.1021e-01,  1.2235e+00, -2.3201e-02, -2.8625e+00,\n",
      "         -1.6351e+00,  2.1171e-02,  1.2891e-01, -2.6075e-01, -3.9127e-01,\n",
      "          7.4367e-01, -2.2823e+00,  9.9767e-01, -1.3431e-01, -2.2571e-01,\n",
      "          1.2833e+00, -1.1448e+00,  1.0205e+00,  5.9265e-02, -6.6416e-01,\n",
      "         -1.3545e+00,  3.9468e-01, -2.8949e-01,  3.3807e-01, -2.6536e-01,\n",
      "         -2.1235e+00,  6.8272e-01, -1.7581e+00, -4.9656e-01, -5.5424e-01,\n",
      "         -1.3792e+00, -5.5876e-02,  2.9961e+00, -1.8188e+00,  1.7679e+00,\n",
      "         -2.1740e+00,  6.8464e-01,  1.0734e+00, -2.5314e-01, -1.6378e-01,\n",
      "         -1.9951e+00,  5.2182e-01, -3.7485e-01,  8.5714e-01, -1.6264e-02,\n",
      "          5.5581e-02,  7.4183e-02, -5.7009e-01,  1.8573e+00, -1.8535e-01,\n",
      "         -6.4110e-02,  4.5242e-01, -1.5845e-01, -7.1276e-01,  2.6119e-01,\n",
      "         -1.0066e+00, -1.5485e+00, -1.6307e+00,  2.7344e-02, -2.7984e-01,\n",
      "         -8.3277e-02,  8.3702e-01,  7.0911e-01,  6.9033e-01,  9.3675e-01,\n",
      "         -1.2728e+00, -1.7147e+00,  1.8328e+00, -2.1071e+00,  1.3481e+00,\n",
      "         -9.8204e-01, -1.4416e+00,  1.2535e+00,  1.7424e+00,  6.6923e-01,\n",
      "          2.9936e-02,  5.5474e-02,  2.3066e-01,  2.0397e-01, -1.5571e-02,\n",
      "          3.3938e-01,  1.5805e+00,  2.0980e+00,  2.1226e+00, -6.9783e-01,\n",
      "         -8.8167e-01,  2.5645e-01, -1.0364e+00,  1.4290e+00, -7.1970e-01,\n",
      "          2.2872e+00, -1.9441e+00,  8.5586e-01,  5.4902e-01,  7.2691e-01,\n",
      "         -7.1743e-01,  1.5641e+00,  1.0832e-01,  7.3074e-01, -1.2168e+00,\n",
      "          9.8624e-02,  1.1471e-01, -5.4005e-01,  1.6267e+00, -2.5836e+00,\n",
      "         -3.3344e-01,  1.3272e+00,  1.5233e+00,  1.7276e-01, -8.8291e-01,\n",
      "          1.0321e+00, -1.1071e-01,  1.4735e+00, -1.1727e+00, -8.0105e-01,\n",
      "          9.8115e-01, -6.2700e-01, -2.8291e-01, -1.2250e-01, -1.6153e+00,\n",
      "         -1.5622e-01, -1.2177e+00, -5.8361e-01,  1.1074e+00,  9.7461e-01,\n",
      "          1.0979e-01, -7.4447e-01,  6.1261e-01, -6.6075e-01,  3.9924e-01,\n",
      "          1.2834e+00,  6.1846e-01, -1.0371e+00,  3.6227e-03, -1.3080e+00,\n",
      "          1.4109e+00,  8.0155e-01,  4.8192e-02,  1.4443e+00, -1.3198e+00,\n",
      "         -1.9401e+00,  4.5708e-02, -4.3325e-01,  2.2370e+00,  7.9493e-02,\n",
      "          6.0745e-01, -5.9833e-01,  3.2511e-01,  9.9966e-01, -4.9552e-01,\n",
      "          4.6377e-01,  1.2605e+00, -1.5294e+00, -9.7450e-01, -2.7748e-01,\n",
      "         -6.0101e-01,  1.9292e-01, -1.5833e+00,  7.9454e-01,  2.6211e-01,\n",
      "          1.3052e+00,  3.1813e-01, -1.8540e-01,  2.0433e-01,  3.8197e-01,\n",
      "         -1.9042e+00,  6.1280e-01,  7.5987e-01,  9.8376e-01, -5.1945e-01,\n",
      "          9.7937e-01, -3.5679e-02, -1.9299e+00,  1.0370e+00,  3.5554e-01,\n",
      "         -2.2675e+00,  4.8182e-01,  6.9494e-01,  1.6423e-01, -4.1758e-01,\n",
      "          2.0575e+00,  8.4185e-01,  7.7990e-01,  8.8885e-01,  1.6913e+00,\n",
      "          2.2064e-01, -1.7239e+00,  9.9492e-01,  1.2033e-01, -2.4276e+00,\n",
      "          7.7740e-01,  9.2051e-01,  1.2105e+00,  8.1964e-01, -2.3506e+00,\n",
      "          5.5852e-01, -9.5038e-01, -1.3003e+00, -1.8677e-01, -1.2513e+00,\n",
      "          2.3884e-02,  7.2066e-02, -8.9355e-01,  5.8682e-01, -1.4124e+00,\n",
      "         -1.0533e+00, -3.1797e-01, -6.5123e-02, -6.3155e-01, -1.4427e+00,\n",
      "          2.3482e+00,  1.9509e+00,  2.2609e-01,  7.7250e-01,  6.0042e-01,\n",
      "         -8.9921e-01,  1.0844e+00,  2.5515e-01,  1.1586e+00, -4.3857e-01,\n",
      "          1.2222e-01,  1.3363e+00, -9.6641e-01,  1.3757e+00, -2.1417e-01,\n",
      "         -1.1495e+00,  9.4814e-01, -2.1085e+00,  3.4330e-01,  3.2537e-01,\n",
      "         -9.3483e-01, -2.2290e-01,  3.2982e-01, -1.4227e+00, -8.4963e-01,\n",
      "          1.3887e+00,  7.6816e-01,  2.0937e-01,  1.0285e+00, -2.1054e-01,\n",
      "         -3.9267e-01,  5.0668e-01,  1.2042e+00, -9.7306e-01,  1.9026e-01,\n",
      "         -2.2431e-01,  9.5571e-01, -1.4977e-01,  7.9345e-01,  1.1962e+00,\n",
      "          3.0255e-01,  9.0076e-01,  3.8321e-01,  8.0661e-02,  1.5358e-01,\n",
      "         -4.7321e-01,  1.3461e+00,  2.0122e+00,  4.5759e-01, -2.2066e-01,\n",
      "         -1.3841e+00,  5.2328e-01, -2.3976e-01,  9.9542e-01,  1.4731e+00,\n",
      "         -4.2063e-02,  4.7663e-01, -8.6945e-02, -4.9010e-01, -5.0408e-01,\n",
      "         -1.3106e-01,  7.2262e-01, -6.9668e-01, -1.1763e-01,  3.0235e-01,\n",
      "         -6.4262e-01, -3.4537e-02,  5.3787e-01,  7.2594e-02,  2.0942e+00,\n",
      "          1.2740e+00, -5.2238e-01, -6.3755e-02, -6.5467e-01, -1.1610e+00,\n",
      "          1.8296e+00, -1.1108e+00, -3.2269e-02,  8.1917e-01, -2.0205e+00,\n",
      "          2.1922e-01,  3.3717e-01, -3.4268e-01, -8.1307e-01,  5.8054e-01,\n",
      "         -1.0605e+00,  1.8294e+00, -2.1507e-01,  1.1265e+00,  8.0087e-01,\n",
      "         -3.7392e-01, -1.1016e+00, -1.7266e+00, -4.2728e-02, -8.5194e-01,\n",
      "          5.3229e-01, -7.9880e-01,  2.1682e-01,  2.9989e-02, -9.1036e-01,\n",
      "          2.1391e-01,  1.0352e+00,  1.7483e-01,  1.6137e+00,  6.6157e-01,\n",
      "          1.3347e-01,  2.0140e-01, -1.1398e+00,  1.3787e-01,  8.6750e-01,\n",
      "         -4.6069e-01, -3.1622e-01,  3.7138e-01, -2.0493e+00, -1.7901e-02,\n",
      "          5.9643e-01,  5.0061e-01,  1.3167e-01, -1.0825e+00,  2.0804e-01,\n",
      "         -7.2832e-01, -2.3214e+00,  4.7817e-01,  5.6434e-02,  3.5717e-01,\n",
      "          3.6955e-02, -9.2525e-01,  1.5100e+00, -9.8820e-01, -3.5466e-01,\n",
      "          1.0322e+00,  1.0778e+00, -1.0714e+00,  7.2352e-01, -1.0789e+00,\n",
      "         -1.0497e+00, -1.1690e+00, -3.0600e-01,  1.2843e+00,  4.5832e-01,\n",
      "         -1.1952e+00,  6.1600e-01,  2.7913e-01, -5.1759e-01, -1.3272e+00,\n",
      "         -2.6554e-01, -1.5044e+00, -9.7918e-01,  5.1435e-02, -7.3296e-01,\n",
      "         -2.6666e-01,  2.2848e+00, -5.8434e-01, -2.8737e-02, -3.1648e-02,\n",
      "          1.0815e-02,  5.4147e-01, -7.7809e-01, -6.1087e-01, -4.3040e-01,\n",
      "          8.9086e-01, -8.0653e-01,  1.7006e+00, -1.1835e+00, -1.1133e+00,\n",
      "          3.9592e-01,  6.1791e-01, -8.5350e-01, -5.7931e-01,  2.4231e-01,\n",
      "         -3.6009e-01,  8.6811e-01, -4.7372e-01,  1.6128e-02, -4.1258e-01,\n",
      "         -3.2266e-01, -7.4203e-01, -2.4550e-01, -5.9288e-01, -5.9859e-01,\n",
      "         -7.4140e-01,  1.3571e+00, -4.5917e-01,  1.3982e+00,  1.0016e+00,\n",
      "          3.0974e-01, -8.2564e-01,  2.3906e-01, -4.0828e-02,  5.2467e-01,\n",
      "         -1.0191e+00,  8.2626e-01,  1.9310e-01, -1.6851e+00,  1.9472e-01,\n",
      "          2.2393e+00, -1.9723e+00,  6.2386e-01, -1.1298e+00,  2.5064e-01,\n",
      "         -6.7930e-01,  1.2940e+00, -1.5135e+00, -1.2344e+00,  1.1615e+00,\n",
      "         -4.0268e-01,  6.5267e-01, -8.9750e-01, -1.7199e+00, -2.2942e-01,\n",
      "         -5.8098e-01, -9.7867e-01, -4.5752e-01,  9.8131e-02, -4.4044e-01,\n",
      "          9.9370e-01,  1.5822e+00, -8.6326e-02,  7.1178e-01, -2.5576e-01,\n",
      "          8.4395e-01,  3.1269e-01,  1.7926e+00,  7.0525e-01, -1.2137e+00,\n",
      "         -2.9197e-01, -2.6971e+00, -8.5197e-01,  9.5310e-01,  1.3119e+00,\n",
      "          5.1798e-01, -2.3658e+00,  6.9668e-01, -3.6035e-01, -2.9963e-01,\n",
      "          1.8111e-01, -8.9174e-01,  9.5384e-01,  1.4862e-01, -6.5212e-01,\n",
      "          1.0947e+00, -2.4881e+00,  1.1919e+00, -3.6557e-01, -2.6114e-01,\n",
      "         -2.8677e-01,  5.4333e-01,  1.2703e+00,  3.6061e-01, -3.9217e-02,\n",
      "          1.2254e+00, -7.1195e-01,  3.3973e-01,  2.5842e-01,  6.0484e-01,\n",
      "         -4.5563e-01, -3.4033e+00,  2.4312e+00, -4.9112e-01, -9.1376e-01,\n",
      "          1.6970e-01, -1.0580e+00,  4.0326e-01,  7.8557e-01, -3.6913e-02,\n",
      "          1.9181e+00, -3.7303e-01, -3.0516e-01,  1.9091e+00, -1.1569e+00,\n",
      "         -5.5852e-01, -1.9860e+00, -9.9198e-02, -3.1585e-01,  8.1558e-01,\n",
      "          7.1741e-01, -2.6494e-01, -4.2979e-01,  1.7263e+00, -2.5642e+00,\n",
      "          1.0972e-01,  4.8299e-02,  9.5592e-01, -4.3614e-01,  1.3718e+00,\n",
      "         -1.1925e+00, -1.6708e+00, -6.8410e-01, -8.8974e-01, -1.6574e+00,\n",
      "         -7.4558e-01,  1.8598e+00, -6.8691e-01,  9.3098e-01,  1.0579e+00,\n",
      "         -1.2838e+00, -9.4466e-01, -5.4659e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 8\n",
      "tensor([[-0.2438]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "Batch and Step: 9\n",
      "Batch\n",
      "tensor([[   0, 3226,  347, 3226,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "torch.Size([1, 411, 768])\n",
      "Finger print is:\n",
      "tensor([[ 2.5952e-01, -1.8265e+00, -7.5268e-01,  3.1614e-01, -1.0018e+00,\n",
      "         -1.0082e+00, -1.6954e+00, -1.3193e+00,  4.6654e-03, -4.3961e-01,\n",
      "          8.2553e-02,  5.6359e-01, -6.1782e-01, -2.0445e+00, -1.2499e+00,\n",
      "          8.0734e-03,  1.9109e+00,  1.3820e+00, -1.9415e+00,  2.3090e+00,\n",
      "         -7.9192e-01,  1.1506e+00,  8.3664e-01,  4.9568e-01,  1.6243e+00,\n",
      "         -7.2676e-02, -1.8150e-01, -7.8465e-01, -3.8565e-01,  2.1027e-01,\n",
      "          5.7206e-01, -8.3626e-01,  9.5166e-01,  2.7569e-01,  6.4399e-01,\n",
      "          7.9854e-01,  9.1852e-01,  1.6313e-01, -1.7189e+00, -8.7283e-01,\n",
      "          1.0352e+00,  2.8855e-01, -4.2196e-01, -9.1301e-01,  1.7971e+00,\n",
      "          5.9007e-01, -1.8180e+00,  1.4672e+00, -3.6507e-01, -5.0453e-01,\n",
      "          5.1417e-01,  2.6531e-01, -9.1940e-02,  5.0104e-01, -4.3526e-01,\n",
      "          1.6364e+00,  1.7310e+00, -2.8168e-01, -1.6075e+00, -9.7861e-02,\n",
      "          1.6971e-01, -1.2673e-01, -7.4511e-01, -1.4385e+00, -1.2500e+00,\n",
      "          2.8565e-01, -1.7060e-01, -1.5329e+00,  4.0211e-01,  5.9199e-02,\n",
      "          4.5983e-01,  4.4326e-01,  1.1130e+00, -1.9669e+00, -4.8151e-01,\n",
      "          3.7043e-01, -4.8553e-01,  4.9240e-01, -4.2404e-02, -5.1902e-01,\n",
      "         -8.3452e-01, -2.4957e-01, -1.6097e-03, -4.0132e-01, -1.0034e-01,\n",
      "         -1.1813e-02, -4.0905e-01, -2.3611e+00,  8.3373e-01,  3.3245e-01,\n",
      "          7.7256e-01, -1.0514e+00,  4.9080e-02,  1.2024e-01, -1.6857e-02,\n",
      "          5.5758e-01,  9.0512e-01, -1.0377e+00, -8.6723e-01,  1.7976e+00,\n",
      "         -1.2169e+00,  1.4504e+00, -9.6810e-02,  2.8009e+00,  1.8499e+00,\n",
      "          3.2970e-01,  1.9798e+00,  2.7774e-01, -7.5330e-01, -5.8001e-01,\n",
      "         -9.5024e-01,  6.8811e-03,  1.0186e+00,  1.0925e+00, -2.9165e-02,\n",
      "          2.1411e+00, -1.8384e-02,  1.1218e+00, -3.4751e-01, -1.1748e+00,\n",
      "         -2.4100e-01, -1.8228e-01, -1.5310e+00,  2.6405e+00, -5.8876e-01,\n",
      "         -2.9587e-01,  4.1742e-01, -3.7447e-01, -4.0214e-01,  9.0892e-02,\n",
      "         -7.1767e-01, -5.5478e-01,  7.1298e-01, -4.3898e-01,  8.3325e-01,\n",
      "          3.2991e-01, -1.9389e+00, -8.2170e-01, -5.6826e-01, -4.9016e-01,\n",
      "         -1.7949e+00,  5.3652e-01, -8.9408e-01,  1.3140e+00,  9.2036e-01,\n",
      "         -6.1194e-01, -4.5380e-01, -1.1463e+00, -9.9632e-01,  5.6898e-01,\n",
      "          5.9016e-01,  4.4109e-01,  1.7414e+00, -1.0252e+00, -8.3869e-01,\n",
      "          1.1183e+00, -2.1679e-01, -6.7204e-01,  4.5460e-01, -2.2134e-01,\n",
      "         -9.0012e-01,  1.0255e+00, -1.5784e+00,  4.2333e-01,  3.6872e-01,\n",
      "         -3.2876e-01,  1.0210e-01,  1.1959e+00,  2.4867e-02, -3.8081e-01,\n",
      "         -1.1847e-01,  1.0192e+00,  3.9139e-01, -5.9275e-01, -2.3613e+00,\n",
      "          1.1736e+00, -1.1591e+00, -5.1676e-01,  1.4587e+00,  3.9297e-01,\n",
      "         -7.1757e-01, -4.8899e-01,  9.2138e-01, -3.3837e-01,  1.0241e+00,\n",
      "         -1.1987e+00,  1.4838e+00,  4.6028e-01, -2.9198e-02,  2.4749e-01,\n",
      "          1.8324e+00,  1.7012e+00, -1.0657e-01,  4.9078e-01, -4.6597e-01,\n",
      "          1.1501e+00, -1.5750e-01,  1.2909e+00,  2.0471e+00,  3.6381e-03,\n",
      "          6.9572e-01,  7.6315e-02, -1.3938e+00, -8.0985e-02, -1.0662e+00,\n",
      "          4.8806e-01, -1.0436e+00, -3.5955e-01, -1.1584e+00,  5.9157e-01,\n",
      "         -3.2289e-01,  3.4758e-01,  3.9180e-02, -4.5016e-01,  1.4449e+00,\n",
      "          2.0317e+00,  3.3318e-01, -6.8736e-01, -9.3340e-01,  2.3153e-01,\n",
      "          1.7716e+00, -5.9475e-01, -1.3008e-01, -1.9028e-01, -1.1342e-01,\n",
      "          7.8057e-01, -3.5093e-02, -3.2091e-01, -1.4116e+00,  1.5493e+00,\n",
      "          2.6299e+00,  1.0308e+00, -6.2493e-01, -1.2647e-01, -3.2375e-01,\n",
      "          1.7836e+00,  7.7043e-01, -5.1407e-01,  1.7450e+00, -3.0468e-01,\n",
      "          1.4219e+00,  1.6875e-01, -4.1703e-02,  8.0691e-01,  8.4024e-01,\n",
      "         -2.0713e-01,  1.2148e+00,  8.1401e-02, -9.0721e-01,  8.2556e-01,\n",
      "         -2.8609e-02, -1.3688e+00,  2.2475e-01,  5.7721e-01, -1.3243e+00,\n",
      "          5.5777e-01,  9.5854e-01, -4.0683e-01, -1.5023e+00, -1.3923e+00,\n",
      "         -6.0087e-02,  2.4390e-01,  5.9506e-01, -6.3850e-02, -3.3324e+00,\n",
      "         -1.5669e+00, -4.0529e-01, -4.6975e-01,  6.2407e-01, -5.3619e-01,\n",
      "          8.8196e-01, -2.5577e+00,  1.5484e+00, -5.3819e-01, -7.3700e-01,\n",
      "          1.2599e+00, -1.5107e+00,  6.6825e-01,  2.4158e-01, -2.2331e-01,\n",
      "         -1.7816e+00,  1.2593e-01,  1.9748e-02, -6.7949e-01, -6.6267e-01,\n",
      "         -1.7390e+00,  1.2086e+00, -1.2306e+00, -1.6398e-01, -5.5000e-02,\n",
      "         -2.1769e+00,  8.1482e-01,  1.8059e+00, -1.6570e+00,  1.2684e+00,\n",
      "         -1.3631e+00,  7.2745e-01,  7.3759e-01, -6.3312e-01,  4.4211e-01,\n",
      "         -9.6569e-01, -1.5193e-01, -4.5830e-01,  1.1129e+00, -7.9869e-01,\n",
      "          1.8345e-01, -1.1333e-02, -3.5481e-01,  2.0996e+00, -5.2515e-01,\n",
      "         -3.0560e-01,  3.3060e-01, -9.8670e-01, -8.1123e-01,  1.3790e-02,\n",
      "         -1.0179e+00, -1.8867e+00, -1.3933e+00,  6.2152e-01, -1.8215e-01,\n",
      "          5.6918e-01,  7.7443e-01,  1.8171e+00,  6.3269e-01,  5.4055e-01,\n",
      "         -9.7622e-01, -2.4214e+00,  1.7236e+00, -1.5867e+00,  9.9571e-01,\n",
      "         -1.0320e+00, -6.8678e-02,  1.4240e+00,  1.2923e-02,  1.0830e+00,\n",
      "          3.8463e-01,  1.8679e-01,  6.7901e-01,  7.8224e-01, -1.9879e-01,\n",
      "          4.8505e-02,  4.2113e-01,  1.9575e+00,  1.5919e+00, -1.7435e+00,\n",
      "         -4.3831e-01,  9.3170e-01, -1.4122e+00,  6.4910e-01,  3.9221e-01,\n",
      "          1.1085e+00, -2.0416e+00,  4.6261e-01,  7.3533e-01,  1.5811e+00,\n",
      "         -9.0833e-02,  1.0384e+00,  1.4876e-02,  8.7183e-01, -1.5735e+00,\n",
      "         -3.3831e-01,  5.3021e-01, -7.5662e-01,  1.4244e+00, -2.6946e+00,\n",
      "         -6.9073e-01,  1.0694e+00,  1.6484e+00, -3.0280e-01,  5.3094e-02,\n",
      "          6.2381e-01,  4.9214e-01,  1.6551e+00, -1.5428e+00, -1.0729e+00,\n",
      "          5.2084e-01, -2.3450e-01, -1.7409e-01, -7.1705e-01, -2.2405e+00,\n",
      "         -1.0221e-03, -1.4712e+00, -2.0264e-01,  5.9446e-01,  1.1587e+00,\n",
      "         -7.6220e-01, -5.7065e-01,  4.0304e-01, -9.4600e-01,  8.4472e-01,\n",
      "          1.0625e+00,  2.6053e-02, -2.8749e+00,  2.3917e-01, -8.5685e-01,\n",
      "          1.2095e+00,  1.2447e+00, -1.0869e-01,  3.5144e-01, -8.8379e-01,\n",
      "         -1.4846e+00,  1.0416e-02, -1.4041e-01,  1.4887e+00,  2.0740e-01,\n",
      "          3.7215e-01, -6.9233e-01, -8.7712e-01,  5.9623e-01, -4.0515e-01,\n",
      "          3.0837e-01,  1.1549e+00, -9.5618e-01, -1.6139e+00, -1.1006e-01,\n",
      "         -1.1063e-01,  2.5209e-02, -1.1283e+00,  6.0267e-01,  3.7029e-01,\n",
      "          1.4528e+00,  1.1707e+00, -2.5182e-01,  1.2871e-01,  1.0167e+00,\n",
      "         -1.7345e+00,  4.9787e-01,  1.5189e+00,  6.5076e-02, -7.0220e-01,\n",
      "          1.0600e+00,  1.5730e-01, -2.1543e+00,  5.1224e-01,  2.0771e-01,\n",
      "         -1.4431e+00,  3.4913e-01,  4.2977e-02,  1.1620e-01, -8.2933e-01,\n",
      "          1.3083e+00,  1.1749e+00, -1.8446e-01,  1.0439e+00,  1.7274e+00,\n",
      "         -3.0045e-02, -1.6397e+00,  8.1744e-02, -2.0816e-01, -2.3114e+00,\n",
      "          9.7958e-01,  2.7552e-01,  1.2227e+00,  1.1762e+00, -1.5805e+00,\n",
      "          1.1802e+00, -6.5597e-01,  1.1469e-01,  1.1377e+00, -1.0833e+00,\n",
      "         -7.2842e-01, -4.6973e-01, -4.8175e-01,  3.8912e-01, -1.1127e+00,\n",
      "         -1.3967e+00, -1.6239e-01,  6.5235e-02,  1.1670e-01, -7.4897e-02,\n",
      "          1.8950e+00,  1.3265e+00,  7.6718e-01,  1.0641e+00,  6.7336e-01,\n",
      "         -5.9437e-01,  1.8545e-01,  1.1007e-01,  1.2462e+00, -9.0195e-01,\n",
      "          5.8953e-01,  1.9406e+00, -5.3099e-01,  1.3819e+00, -2.7639e-01,\n",
      "         -1.2608e+00,  9.5263e-01, -1.9495e+00,  1.5584e-01,  7.6972e-01,\n",
      "         -4.3656e-02, -9.1311e-02, -5.2678e-02, -7.6136e-01, -7.3994e-01,\n",
      "          1.5777e+00,  3.0042e-01,  2.0388e-01,  6.0271e-01, -5.4599e-01,\n",
      "          7.1768e-01,  4.4379e-01,  1.6008e+00, -1.0910e+00,  7.6630e-01,\n",
      "         -8.3867e-01, -1.0265e-01, -7.5477e-02,  2.2220e-01,  8.8729e-01,\n",
      "          3.3814e-01,  1.4774e+00,  2.3894e-01, -7.3862e-01,  6.7891e-01,\n",
      "         -6.0297e-01,  1.2242e+00,  1.3881e+00,  1.1571e+00, -7.2336e-02,\n",
      "         -6.7099e-01,  8.6360e-01,  2.6079e-01,  1.0044e+00,  1.2600e+00,\n",
      "         -6.0121e-03, -7.0438e-02,  6.9473e-02, -5.4047e-01, -8.4567e-01,\n",
      "         -5.3112e-01,  4.0831e-01, -8.2772e-01, -1.2470e-01,  6.9374e-01,\n",
      "         -8.4273e-01,  5.6660e-01,  6.4696e-01,  9.0584e-01,  1.0817e+00,\n",
      "          1.0050e+00,  8.7479e-01,  4.1547e-01, -2.3813e-01, -1.1684e+00,\n",
      "          1.3037e+00, -1.2557e+00,  6.8211e-01,  5.9704e-01, -1.6549e+00,\n",
      "          6.8806e-02, -1.6262e-01, -1.2180e+00, -4.1203e-01,  1.4264e-01,\n",
      "         -1.0926e+00,  1.9839e+00, -5.8722e-01,  1.0877e+00,  7.0286e-01,\n",
      "         -7.0176e-02, -4.7986e-01, -1.7142e+00, -2.8366e-01, -7.0671e-01,\n",
      "          3.5043e-01, -8.3452e-01, -9.5220e-01, -2.5254e-01, -9.1835e-01,\n",
      "          1.4232e-01,  6.1594e-01,  2.8744e-01,  1.1148e+00,  7.2327e-01,\n",
      "         -3.4426e-01, -3.8864e-01, -2.4388e-01, -6.0379e-02,  5.2006e-01,\n",
      "          1.6723e-01,  3.2573e-01,  4.6551e-01, -2.2616e+00,  7.9466e-02,\n",
      "          8.2930e-01,  1.3597e+00,  5.7955e-01, -1.1034e+00,  2.1639e-01,\n",
      "          2.2930e-01, -2.5969e+00,  6.3924e-01,  1.6039e-01,  9.8972e-01,\n",
      "          7.1002e-01, -7.7779e-01,  1.6300e+00, -1.6745e-02,  9.3925e-01,\n",
      "          1.5096e+00,  1.0694e+00, -1.7570e+00,  6.4034e-01, -5.1114e-01,\n",
      "         -6.6571e-01, -8.9416e-01, -4.3164e-01,  1.7188e+00, -5.0366e-01,\n",
      "          1.6519e-01,  7.0004e-01,  6.7439e-01,  4.9963e-01, -3.6536e-01,\n",
      "         -5.5823e-01, -1.3493e+00, -1.5262e+00,  1.6980e-01,  1.0459e-02,\n",
      "         -6.2936e-01,  2.1373e+00,  7.9845e-01,  8.7760e-02, -9.9696e-01,\n",
      "         -7.0612e-01,  4.0371e-01, -6.9202e-01, -1.1514e+00, -8.8682e-01,\n",
      "          9.3486e-01, -2.8468e-01,  1.6082e+00, -1.0423e+00, -5.3156e-01,\n",
      "          3.7972e-01,  3.4010e-01, -1.4560e+00, -6.9403e-01, -1.4449e-01,\n",
      "         -4.3563e-01,  1.7717e+00, -2.0944e-01, -5.2829e-02, -6.2852e-01,\n",
      "         -1.4858e-01, -1.1764e+00, -4.3491e-01, -1.4845e+00, -1.5647e-01,\n",
      "         -4.8885e-01,  1.2744e+00, -1.1373e-01,  1.2437e+00,  1.6612e-03,\n",
      "          5.6990e-01, -2.5294e-01,  2.4689e-01, -3.0866e-01,  1.1568e-01,\n",
      "         -1.4090e+00,  6.4594e-01, -5.0395e-01, -1.5131e+00,  1.7999e-01,\n",
      "          1.8739e+00, -1.7082e+00,  6.4213e-01, -9.8322e-01,  1.5954e-01,\n",
      "         -9.5975e-01,  1.6132e+00, -1.8403e+00, -1.3881e+00,  6.2853e-01,\n",
      "         -3.3194e-01,  9.0065e-01, -9.6867e-01, -1.6281e+00, -2.9858e-01,\n",
      "          1.9547e-01, -1.2403e+00, -3.2697e-02,  4.2082e-01, -3.6966e-01,\n",
      "          1.4917e+00,  1.4326e+00,  2.0576e-01,  6.0274e-01,  5.7220e-02,\n",
      "          7.1575e-01,  2.8405e-01,  1.0593e+00,  4.1726e-01, -3.6006e-01,\n",
      "          3.6370e-01, -2.1124e+00, -1.4509e-02,  1.2801e+00,  8.5133e-01,\n",
      "          2.8308e-04, -2.6934e+00,  5.7071e-01, -4.0357e-01, -2.8941e-01,\n",
      "         -1.6451e-01, -7.5164e-01,  6.3743e-01,  5.9939e-01, -1.0293e+00,\n",
      "          1.0283e+00, -2.1615e+00,  1.0410e+00, -2.6530e-01, -2.1029e-01,\n",
      "         -6.4926e-01,  5.3283e-01,  7.0988e-01,  1.7099e-01, -5.3121e-01,\n",
      "          2.1922e-01, -4.9624e-01,  1.8009e-01,  5.2996e-01,  4.2031e-01,\n",
      "         -1.6802e-01, -2.4995e+00,  1.9555e+00, -2.8573e-01, -2.4413e-02,\n",
      "         -5.3393e-01, -7.2748e-01, -3.9689e-01, -1.1043e-01,  2.3883e-02,\n",
      "          1.8449e+00, -1.3843e-01, -5.9022e-01,  2.3894e+00, -9.2367e-02,\n",
      "         -4.2542e-01, -1.1609e+00, -5.1781e-01, -1.1706e+00,  7.0225e-01,\n",
      "          2.1744e-01,  3.0128e-01, -5.2498e-01,  1.8322e+00, -2.7091e+00,\n",
      "          3.3068e-01, -2.7456e-02,  6.8225e-01, -5.1360e-01,  1.5763e+00,\n",
      "          3.3662e-01, -1.6349e+00, -1.0084e+00, -1.9524e+00, -2.3618e+00,\n",
      "         -7.6761e-01,  2.1760e+00, -7.4378e-01,  6.4453e-01,  7.9907e-01,\n",
      "         -1.7335e+00, -1.8416e+00, -8.6080e-02]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 9\n",
      "tensor([[-0.3289]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of one step\n",
      "--------------------------------------------------------------------------------\n",
      "End of one Epoch\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(\"Training epoch: %s/%s\" % (epoch+1, 1))\n",
    "    train(model, optimizer, scheduler, loss_fn, train_dataloader, device)\n",
    "    print('End of one Epoch')\n",
    "    print('|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'PolymerSmilesTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(file_path):\n",
    "    dataset = pd.read_csv(file_path, header=None).values\n",
    "    train_data, valid_data = train_test_split(dataset, test_size=0.2, random_state=1)\n",
    "    return train_data, valid_data\n",
    "\n",
    "config = RobertaConfig(\n",
    "        vocab_size=50265,\n",
    "        max_position_embeddings=514,\n",
    "        num_attention_heads=12,\n",
    "        num_hidden_layers=6,\n",
    "        type_vocab_size=1,\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "    )\n",
    "\n",
    "tokenizer = PolymerSmilesTokenizer.from_pretrained(\"roberta-base\", max_len=175)\n",
    "model = RobertaForMaskedLM(config=config).to(device)\n",
    "config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*c1ccc(C(=O)c2ccc(*)cc2)cc1\n",
      "['*', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'c', '2', 'c', 'c', 'c', '(', '*', ')', 'c', 'c', '2', ')', 'c', 'c', '1']\n",
      "tensor([   0, 3226,  438,  134,  438,  438,  438, 1640,  347, 1640, 5214,  673,\n",
      "          43,  438,  176,  438,  438,  438, 1640, 3226,   43,  438,  438,  176,\n",
      "          43,  438,  438,  134,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1])\n",
      "torch.Size([175])\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = split('data/P1_practice.csv')\n",
    "data_train = LoadPretrainData(tokenizer=tokenizer, dataset=train_data, blocksize=175)\n",
    "data_valid = LoadPretrainData(tokenizer=tokenizer, dataset=valid_data, blocksize=175)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15 \n",
    "    )\n",
    "text = train_data[3][0]\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "print(data_train[3]['input_ids'])\n",
    "print(data_train[3]['input_ids'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0218, -0.0088, -0.0123,  ..., -0.0149,  0.0252, -0.0157],\n",
      "        [ 0.0205, -0.0039, -0.0430,  ...,  0.0280, -0.0170, -0.0392],\n",
      "        [ 0.0166,  0.0135,  0.0256,  ...,  0.0286,  0.0371, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([175, 768])\n",
      "tensor([-2.1791e-02, -8.8455e-03, -1.2305e-02,  1.4296e-02, -4.5281e-03,\n",
      "         9.2819e-03, -1.0018e-02,  2.4248e-03,  2.3112e-02,  1.5983e-02,\n",
      "         1.0988e-02,  1.2026e-04,  1.7883e-02,  7.0547e-03, -1.5568e-02,\n",
      "         2.8132e-02, -4.7467e-04, -3.9683e-02,  1.8832e-02,  1.2122e-02,\n",
      "         2.3052e-02, -2.6296e-02, -8.4875e-03, -5.8106e-03, -2.8457e-03,\n",
      "         1.3718e-02, -2.0315e-02, -2.0668e-02, -3.9749e-03, -1.0557e-02,\n",
      "        -1.7580e-02, -7.2370e-03, -1.4162e-02,  8.7720e-03, -2.5846e-02,\n",
      "         5.0436e-03, -1.1075e-02, -2.2960e-02,  2.6327e-02,  3.8541e-03,\n",
      "        -1.6907e-02, -1.3026e-03, -2.1925e-02,  4.4012e-02, -1.5941e-02,\n",
      "         1.2153e-02, -2.3260e-02, -1.0231e-02, -5.7317e-03,  1.1349e-02,\n",
      "         1.0934e-02, -3.2722e-03,  2.7983e-02, -2.0640e-02,  1.8826e-02,\n",
      "        -1.1052e-02, -1.3778e-02,  1.5510e-02,  2.1901e-02,  9.5982e-04,\n",
      "        -2.3382e-04, -2.3478e-03,  3.9654e-02,  1.7800e-02,  4.1234e-02,\n",
      "         2.4781e-02,  1.4884e-02,  1.6816e-02, -7.7914e-03, -4.3163e-03,\n",
      "        -2.4009e-02, -1.2294e-02, -2.7149e-02,  2.6017e-03, -2.1834e-02,\n",
      "         3.9356e-03, -1.7928e-02, -1.0616e-02,  8.7488e-03, -7.4442e-03,\n",
      "         4.2787e-02, -9.5107e-03,  2.0062e-02,  1.8187e-04, -3.1805e-02,\n",
      "        -2.4573e-02,  3.7166e-02,  2.3105e-02, -1.4870e-02, -9.4572e-03,\n",
      "        -3.8724e-03, -4.7570e-02, -1.1879e-02,  5.8425e-03,  1.8503e-02,\n",
      "        -1.8622e-03,  2.8713e-02, -2.5012e-02,  3.4415e-02, -3.0343e-02,\n",
      "         1.9842e-02,  5.3544e-03, -6.1654e-05, -5.3505e-03,  3.5201e-02,\n",
      "        -2.5325e-02,  1.3645e-02,  1.4347e-02,  9.0031e-03,  2.1304e-03,\n",
      "        -1.6182e-02,  1.5066e-02, -1.2049e-02, -2.8127e-03,  2.3092e-02,\n",
      "        -4.1679e-02,  3.9654e-02, -6.9243e-03,  1.0891e-02, -1.6134e-02,\n",
      "         5.2929e-03,  1.4644e-02,  9.1966e-04, -2.0933e-02, -1.6700e-02,\n",
      "         4.6262e-03, -2.0132e-02,  5.0856e-03, -2.1447e-02,  8.2631e-03,\n",
      "        -1.3797e-02, -3.1305e-02,  2.7007e-03, -8.4603e-03,  3.1264e-02,\n",
      "         1.0676e-02,  4.8335e-03, -3.3383e-02,  8.4737e-03, -1.9162e-02,\n",
      "        -2.8001e-02, -5.4990e-03,  2.7769e-02,  3.2492e-02, -2.7543e-02,\n",
      "         3.3574e-02,  5.5551e-02,  1.7459e-02, -7.3341e-03,  2.5512e-02,\n",
      "         2.6895e-02, -1.1352e-02, -1.2296e-02,  4.5689e-03, -1.7865e-02,\n",
      "        -5.7739e-03,  2.3046e-02,  3.5214e-03, -2.4340e-03, -1.1524e-02,\n",
      "        -2.6995e-02, -3.1558e-02,  2.4498e-04,  1.3686e-02, -2.3318e-02,\n",
      "        -1.1856e-02, -9.1263e-03, -1.8829e-02, -1.2119e-02, -3.0092e-02,\n",
      "        -2.6111e-03,  2.9691e-02,  3.2117e-02, -2.0702e-02, -2.5147e-02,\n",
      "         4.2746e-02,  1.0035e-03, -3.4215e-02,  8.3592e-03,  9.4289e-03,\n",
      "         1.1494e-02,  1.3834e-02,  1.5308e-02,  3.5923e-03, -8.5882e-03,\n",
      "         9.3394e-03, -3.2630e-02, -1.2564e-02, -5.3878e-03, -5.8168e-03,\n",
      "        -1.4981e-02, -4.7215e-02, -3.4905e-02, -2.1165e-03,  1.2969e-02,\n",
      "        -1.6734e-02,  2.8012e-02, -1.1513e-02, -9.6948e-03, -6.2583e-03,\n",
      "        -2.6952e-02,  1.0465e-02, -4.6347e-03, -2.2927e-02, -4.9451e-03,\n",
      "         7.1432e-03,  2.2506e-02,  7.1634e-03,  1.1261e-02,  1.4855e-02,\n",
      "        -1.9259e-02,  5.1527e-03,  4.0818e-02, -1.0451e-02,  8.7648e-03,\n",
      "         3.4671e-03, -2.1851e-02,  5.8572e-03, -9.8736e-03,  3.5952e-03,\n",
      "         8.3022e-03, -6.0858e-03,  1.4706e-02, -1.7764e-03,  9.4649e-03,\n",
      "        -4.2393e-02,  8.8518e-03, -4.5685e-02, -8.1443e-03,  1.2181e-02,\n",
      "        -1.6675e-02, -2.5592e-02,  2.1269e-02, -3.1693e-02,  7.2674e-03,\n",
      "         3.9541e-03, -3.3710e-02,  2.7316e-02, -2.0660e-03,  1.6042e-02,\n",
      "         2.2654e-02,  5.0551e-03, -1.6445e-02, -1.3180e-02,  1.1256e-02,\n",
      "        -2.2833e-02,  1.0412e-02,  1.3805e-02, -2.9639e-02,  9.4129e-03,\n",
      "         2.0040e-02, -3.3699e-02,  1.7710e-02, -1.6326e-02,  1.0712e-02,\n",
      "         1.8905e-02, -2.4340e-03,  1.0570e-02, -2.8080e-02,  2.4563e-02,\n",
      "        -1.0228e-02,  3.0309e-02, -3.0819e-02,  3.7825e-02,  1.9635e-02,\n",
      "        -2.7489e-02, -1.1361e-02,  3.4192e-02,  2.6235e-02, -1.1529e-02,\n",
      "         5.1798e-02, -4.3217e-02, -6.5996e-03, -8.3254e-04,  5.6292e-02,\n",
      "        -2.4516e-02, -8.2438e-03, -1.1085e-02, -1.1776e-02, -2.5471e-03,\n",
      "         5.5271e-03, -5.9786e-03, -3.8042e-02,  4.4325e-03, -3.9492e-03,\n",
      "        -5.1616e-03,  1.0290e-02,  3.6448e-04, -6.7238e-03,  5.7977e-03,\n",
      "         2.1881e-02,  7.8456e-03, -3.9474e-02, -3.4208e-02, -8.9756e-03,\n",
      "         1.5761e-02,  2.8317e-03, -1.6028e-03, -2.8276e-03, -1.2664e-02,\n",
      "        -4.9155e-02,  3.8690e-02,  1.0468e-03,  9.0862e-03, -1.9180e-02,\n",
      "         2.4457e-03, -1.2233e-02, -1.2211e-02, -2.8630e-02, -1.8394e-02,\n",
      "        -4.2633e-02,  2.3832e-02,  2.2877e-02, -9.4441e-03,  2.8159e-02,\n",
      "        -1.8478e-02, -4.1323e-02,  7.0724e-03, -4.7949e-02,  4.7369e-04,\n",
      "         3.3053e-02, -1.8657e-02,  3.5336e-03, -1.4750e-02, -7.9282e-03,\n",
      "         2.8924e-02, -3.3462e-02, -1.2898e-02,  7.7938e-03,  8.6486e-03,\n",
      "        -1.5277e-04, -3.2143e-03, -6.8645e-04,  1.1242e-02, -1.0721e-02,\n",
      "         1.8293e-02, -3.0475e-02,  5.6879e-03,  2.1978e-02, -3.4803e-02,\n",
      "        -1.8917e-02, -3.9507e-02,  1.7214e-02, -3.0546e-03,  5.4931e-03,\n",
      "        -9.2082e-03,  1.2535e-02, -3.2324e-03,  1.0017e-02,  1.8707e-02,\n",
      "        -1.9729e-02, -1.4987e-02, -1.8919e-03,  6.3928e-03,  2.7031e-02,\n",
      "        -4.0593e-04, -2.7960e-02,  1.6551e-02, -1.1295e-02,  7.6886e-03,\n",
      "         2.0222e-02, -2.4763e-02, -3.2842e-02,  2.0411e-02, -4.5255e-03,\n",
      "        -8.9011e-03, -2.2604e-02,  5.3859e-03, -1.4724e-02, -1.0028e-02,\n",
      "        -2.0727e-04, -1.8042e-02, -4.5307e-02,  8.5792e-03, -2.7329e-03,\n",
      "         1.7329e-02,  1.2298e-02,  1.4180e-02,  8.2738e-03, -2.3069e-02,\n",
      "         1.1164e-03,  1.6400e-02,  1.2131e-02, -2.4985e-05, -1.1698e-02,\n",
      "        -1.8011e-02,  2.8399e-03,  2.7915e-03,  4.9413e-03, -3.7227e-02,\n",
      "         1.1706e-02, -7.9369e-03,  2.3346e-02, -4.0189e-02,  1.5590e-02,\n",
      "         3.0903e-02, -5.5781e-03,  1.0934e-02, -2.5883e-03,  1.1811e-03,\n",
      "        -8.9298e-03, -4.2979e-02, -1.7949e-02,  3.9565e-03, -2.4849e-02,\n",
      "         3.1338e-02,  4.4370e-04,  9.7462e-03, -2.0795e-02, -9.0615e-03,\n",
      "        -2.3028e-02, -1.4430e-03,  6.8478e-03, -3.6952e-02,  1.6949e-02,\n",
      "        -1.5957e-02,  2.5591e-02, -8.4257e-03, -1.2385e-02, -1.7574e-02,\n",
      "         2.4719e-02,  4.4020e-02, -9.9012e-03, -3.6362e-03, -4.0769e-03,\n",
      "        -2.1257e-02,  1.1799e-02,  2.4899e-02,  1.1458e-02,  3.5030e-03,\n",
      "         7.4046e-03, -2.5635e-02,  1.4857e-02,  4.0563e-02, -1.9483e-02,\n",
      "         1.2002e-02,  1.9647e-02, -1.9117e-02, -2.9669e-02, -6.1923e-03,\n",
      "         1.1618e-02, -5.7776e-03, -1.5647e-03,  1.5331e-02,  9.6312e-03,\n",
      "         3.9067e-02, -8.6262e-04, -3.8561e-02,  1.6444e-03, -9.9577e-03,\n",
      "         6.9925e-03,  1.9950e-02, -1.8268e-03, -1.5459e-02,  1.0947e-03,\n",
      "         2.3605e-03,  8.9932e-04,  4.8922e-02,  1.5363e-02,  2.4695e-02,\n",
      "         2.8150e-02, -1.1946e-02,  9.6915e-03, -2.6078e-03,  1.4485e-03,\n",
      "         3.0307e-04, -2.2904e-02,  2.0783e-02,  1.6093e-02, -8.5567e-03,\n",
      "         5.4758e-02,  8.6973e-03,  4.4852e-02,  4.2944e-03,  7.9702e-04,\n",
      "         2.4271e-02, -1.7344e-02, -5.8689e-03, -5.4411e-03,  3.6262e-02,\n",
      "         5.0003e-03,  5.2577e-03,  2.1688e-02,  6.9747e-03, -2.9175e-02,\n",
      "        -8.9436e-04,  4.3760e-02, -3.8347e-02, -1.3794e-02,  8.3448e-03,\n",
      "         2.9424e-02, -3.5196e-04, -2.3574e-03, -4.8707e-03, -1.6189e-02,\n",
      "         1.8990e-02, -2.6200e-02,  1.7285e-02, -4.6157e-04, -1.2850e-02,\n",
      "         1.3819e-03,  1.1713e-02,  3.3572e-02,  2.5739e-03, -2.1055e-02,\n",
      "        -2.1808e-02, -1.6160e-02,  2.9498e-02,  5.3247e-03, -2.1849e-02,\n",
      "        -1.0751e-02,  2.7389e-03,  6.9241e-03,  6.8180e-02,  3.7695e-02,\n",
      "         1.8365e-02,  3.4373e-02, -1.8703e-02,  1.4639e-02,  1.2364e-02,\n",
      "        -1.8629e-02, -5.9751e-03,  1.0866e-02,  4.2737e-03, -1.0101e-02,\n",
      "         2.2053e-02, -3.8524e-02, -5.1089e-03,  2.4233e-02, -1.8177e-02,\n",
      "         1.0155e-02,  1.1439e-02,  1.2530e-02, -1.6500e-02, -2.0496e-02,\n",
      "        -1.6233e-02, -2.7368e-02,  2.5964e-03, -1.9342e-02, -1.4929e-02,\n",
      "         8.6907e-03, -7.4914e-03,  3.4734e-02,  2.3344e-02,  1.9988e-02,\n",
      "         2.0690e-02,  2.0536e-02,  2.9014e-02,  1.6578e-02,  2.9564e-03,\n",
      "         6.8360e-03,  3.5100e-02, -2.8767e-02, -7.3685e-03,  1.2423e-02,\n",
      "         1.4097e-02, -6.4773e-05,  1.6307e-02, -2.9515e-02,  1.7630e-02,\n",
      "         1.1804e-02, -3.3281e-03,  4.2777e-02,  5.1289e-03,  8.9878e-03,\n",
      "        -8.8929e-03,  3.0672e-02, -1.4270e-02, -6.5862e-03,  2.7542e-02,\n",
      "        -1.3636e-02,  2.6346e-02, -1.2639e-02,  2.4153e-02,  1.2942e-02,\n",
      "         2.6011e-03, -1.6171e-02,  1.0742e-02,  1.8308e-02,  1.0794e-02,\n",
      "         1.2517e-03,  3.4699e-03,  3.0393e-02,  2.0470e-02, -2.9806e-02,\n",
      "        -3.8137e-02,  2.4812e-02,  7.5975e-03, -1.0062e-02,  1.7639e-02,\n",
      "        -3.1472e-02, -1.4091e-02,  2.8909e-02, -1.6597e-02,  1.6205e-02,\n",
      "         1.4202e-02, -2.8473e-02, -1.2279e-02, -1.0052e-02, -3.0960e-04,\n",
      "        -2.9084e-02,  1.2572e-02, -1.1305e-02,  2.9557e-02, -1.4707e-02,\n",
      "        -3.7718e-02,  8.3188e-03,  4.3214e-03, -4.1500e-03,  1.2049e-02,\n",
      "        -2.5366e-02,  8.7526e-03, -3.9645e-02, -1.1927e-02,  1.6943e-02,\n",
      "        -3.0807e-02, -1.2577e-02,  3.0065e-02, -3.9693e-03, -2.8799e-03,\n",
      "        -2.5111e-02,  3.0988e-02,  1.4640e-02, -2.9990e-02,  3.1669e-02,\n",
      "         4.8008e-02,  1.6406e-02,  1.1994e-02, -3.5906e-02, -3.3812e-03,\n",
      "         7.4987e-03, -3.0773e-02,  3.9535e-03, -1.1213e-02,  7.7656e-03,\n",
      "         1.4458e-02, -2.5638e-02, -3.7832e-03, -2.1019e-02, -1.2931e-02,\n",
      "        -4.2086e-03, -8.8080e-03, -1.8995e-02,  3.2991e-03, -2.6019e-02,\n",
      "        -2.0325e-02, -6.3903e-03,  1.9315e-04,  5.5782e-03,  2.9046e-03,\n",
      "        -2.1812e-02, -6.7326e-03, -2.5703e-03, -1.4704e-03, -4.5899e-02,\n",
      "         5.6526e-02,  1.9671e-02, -3.0553e-02, -7.3086e-04,  1.3820e-02,\n",
      "        -3.1142e-03, -2.4025e-02,  1.7986e-02, -7.3417e-05, -3.2209e-02,\n",
      "        -2.0556e-02,  1.6769e-02, -2.6768e-02, -5.0984e-03, -1.4948e-02,\n",
      "        -2.9084e-02,  5.0852e-03,  2.1591e-02, -3.0335e-02, -1.0911e-02,\n",
      "        -6.5924e-03, -3.5702e-02, -2.7467e-02, -9.2889e-03,  2.4157e-03,\n",
      "         3.3211e-02,  2.2878e-02, -1.3340e-02, -1.5117e-02,  2.4474e-03,\n",
      "        -2.0056e-03,  1.0786e-03, -3.3261e-02,  2.1682e-02, -1.6839e-02,\n",
      "         1.1660e-02, -1.6387e-02, -1.8770e-02,  2.8425e-02,  1.2407e-02,\n",
      "        -5.0941e-03,  7.3265e-03,  2.5504e-04, -8.4936e-03,  9.7550e-03,\n",
      "        -5.3746e-03,  1.2484e-03, -3.2481e-03, -2.0695e-02,  2.2719e-02,\n",
      "        -7.6189e-03,  5.5623e-03,  2.9160e-02,  1.3217e-02,  1.1248e-02,\n",
      "        -1.4601e-02,  7.4313e-03, -2.0653e-02,  5.9470e-03,  3.8244e-02,\n",
      "        -2.0556e-02,  3.6426e-02,  2.6595e-03, -9.1057e-03,  8.4585e-03,\n",
      "        -2.6444e-02, -3.8153e-02, -3.8435e-03, -2.9911e-02,  4.8170e-02,\n",
      "         1.5643e-02, -1.6494e-02,  9.4929e-03, -9.6794e-04, -1.9389e-02,\n",
      "        -2.9486e-02, -2.6132e-02,  2.1516e-03, -2.3045e-02,  9.3763e-03,\n",
      "        -3.6406e-02, -6.0706e-03, -6.8209e-03,  2.5455e-02, -4.6072e-02,\n",
      "        -1.3999e-02,  2.8347e-02, -1.5658e-02,  7.1814e-03,  3.1780e-02,\n",
      "         3.7194e-02, -1.9301e-02,  1.7648e-03,  6.5179e-03,  2.3093e-02,\n",
      "         2.7087e-02,  2.5491e-02,  5.9710e-03, -2.2043e-02, -1.4987e-02,\n",
      "        -1.5570e-03,  9.7745e-03, -1.5916e-03,  4.8396e-03,  1.4245e-02,\n",
      "         4.0931e-03, -1.9373e-02, -1.1366e-02,  1.9865e-02,  1.3883e-02,\n",
      "        -1.4908e-02,  2.5219e-02, -1.5676e-02], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.roberta.embeddings.word_embeddings(data_train[3]['input_ids'])\n",
    "print(embeddings)\n",
    "print(embeddings.size())\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
