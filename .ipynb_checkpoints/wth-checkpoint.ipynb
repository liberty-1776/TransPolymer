{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\Python310\\lib\\site-packages\\transformers\\trainer_pt_utils.py:211: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: Optional[torch.device] = torch.device(\"cuda\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downstream_Dataset class is called\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, RobertaModel, RobertaConfig, RobertaTokenizer\n",
    "from PolymerSmilesTokenization import PolymerSmilesTokenizer\n",
    "from dataset import Downstream_Dataset, DataAugmentation, LoadPretrainData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import R2Score\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data = pd.read_csv('data/practice.csv')\n",
    "len(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*C*</td>\n",
       "      <td>0.671870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*CC(*)C</td>\n",
       "      <td>0.440891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*CC(*)CC</td>\n",
       "      <td>0.439301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*CC(*)CCC</td>\n",
       "      <td>0.571796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*CC(*)CC(C)C</td>\n",
       "      <td>0.575343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>*CC1CCC(*)C1</td>\n",
       "      <td>0.711080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>*CC(*)CCCC1CCCCC1</td>\n",
       "      <td>0.349564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>*C=CCCC*</td>\n",
       "      <td>-0.710518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>*C=CCC*</td>\n",
       "      <td>-0.358177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>*C=C*</td>\n",
       "      <td>-2.691151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              smiles     value\n",
       "0                *C*  0.671870\n",
       "1            *CC(*)C  0.440891\n",
       "2           *CC(*)CC  0.439301\n",
       "3          *CC(*)CCC  0.571796\n",
       "4       *CC(*)CC(C)C  0.575343\n",
       "5       *CC1CCC(*)C1  0.711080\n",
       "6  *CC(*)CCCC1CCCCC1  0.349564\n",
       "7           *C=CCCC* -0.710518\n",
       "8            *C=CCC* -0.358177\n",
       "9              *C=C* -2.691151"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data.iloc[:, 1] = scaler.fit_transform(train_data.iloc[:, 1].values.reshape(-1, 1))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'PolymerSmilesTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*CC(*)CCCC1CCCCC1\n",
      "['*', 'C', 'C', '(', '*', ')', 'C', 'C', 'C', 'C', '1', 'C', 'C', 'C', 'C', 'C', '1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,  347,  134,\n",
       "         347,  347,  347,  347,  347,  134,    2,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PolymerSmilesTokenizer.from_pretrained(\"roberta-base\", max_len=411)\n",
    "text = train_data['smiles'][6]\n",
    "print(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "train_dataset = Downstream_Dataset(train_data, tokenizer, 411)\n",
    "train_dataset[6]['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ckpt/pretrain.pt were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ckpt/pretrain.pt and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-6.5901e-03, -3.0273e-02,  1.0452e-02,  6.0735e-03,  1.6869e-02,\n",
       "        -7.4226e-03, -1.9216e-04,  8.4486e-03,  9.9861e-05, -1.9007e-02,\n",
       "         3.1266e-02,  4.0982e-02, -2.1137e-02, -4.1473e-02, -4.8484e-04,\n",
       "         2.7060e-02, -1.8944e-02, -1.0499e-02,  3.6727e-02,  2.8344e-02,\n",
       "         5.6940e-02, -6.6101e-03,  2.4843e-02, -1.3782e-02,  2.5544e-02,\n",
       "         1.3999e-02,  3.3548e-03, -5.6537e-02,  2.7440e-02, -1.6908e-03,\n",
       "        -3.0152e-02,  7.9863e-04,  2.8650e-02, -3.7253e-02,  7.0821e-03,\n",
       "         1.0565e-02,  1.5476e-02, -2.9742e-02,  4.6331e-02,  9.5752e-03,\n",
       "         3.5777e-02, -8.0191e-03, -1.9469e-03, -2.0554e-02, -3.2674e-02,\n",
       "         4.0174e-02, -7.9052e-03,  6.7482e-03,  2.2553e-03,  2.7931e-02,\n",
       "         5.4660e-02,  9.5607e-04,  2.4311e-02, -5.5689e-03,  1.6109e-02,\n",
       "        -3.4241e-02,  8.7432e-03,  1.9810e-02, -8.8660e-03,  7.2772e-03,\n",
       "        -9.3102e-03,  1.0731e-02, -1.2353e-04, -1.4927e-02, -2.0251e-02,\n",
       "        -2.7089e-02, -9.5798e-03,  6.1575e-02, -2.8431e-02, -3.4994e-02,\n",
       "        -2.2993e-02, -4.2987e-02, -1.8563e-02, -4.1493e-02,  3.8978e-02,\n",
       "         1.9113e-02,  2.4433e-02,  4.7105e-02, -3.8399e-03, -4.9744e-02,\n",
       "        -6.8228e-02, -6.8136e-04,  3.4340e-03, -4.7614e-02, -1.3518e-02,\n",
       "         4.1785e-02, -2.1471e-02,  2.5401e-02, -2.5873e-02, -8.6131e-02,\n",
       "        -1.1671e-02, -8.5002e-02, -5.5094e-03, -8.6594e-03,  1.3737e-02,\n",
       "        -3.4854e-02, -1.6406e-02,  1.8185e-02, -2.2840e-02, -4.5839e-02,\n",
       "         2.1798e-02,  5.4250e-02,  8.4576e-03,  5.7765e-02,  3.8277e-02,\n",
       "         4.4480e-02,  7.8704e-02, -2.0388e-02,  3.2406e-02,  3.3100e-02,\n",
       "         2.7559e-02,  8.4986e-03, -2.3512e-02, -7.4984e-03,  8.6288e-03,\n",
       "         4.8544e-02,  2.0938e-03,  1.3851e-02,  4.7545e-02,  1.6221e-02,\n",
       "         3.4708e-02, -3.9386e-02, -1.9059e-02, -1.7101e-02, -4.7520e-02,\n",
       "        -2.0314e-02, -2.4383e-02,  6.2630e-02, -3.2860e-02,  3.3010e-02,\n",
       "         1.2564e-01, -5.2957e-03,  1.2537e-03, -2.1701e-02, -7.3878e-03,\n",
       "        -2.9019e-03, -6.1040e-02, -4.3241e-02, -2.1943e-02, -3.7361e-02,\n",
       "        -3.1649e-02, -3.4212e-02,  6.2411e-02,  1.6465e-03, -1.9244e-02,\n",
       "         8.5851e-03,  5.3990e-02, -6.6477e-03,  1.3057e-02,  2.2057e-02,\n",
       "        -8.5933e-03, -4.3393e-03, -9.4500e-03, -1.3365e-02,  1.2499e-02,\n",
       "        -2.9774e-02,  8.0730e-03, -5.2389e-02, -7.1603e-03, -2.0460e-02,\n",
       "        -7.9127e-03, -2.9752e-02, -2.4553e-03, -1.2596e-02, -1.3937e-02,\n",
       "        -3.6056e-02, -2.4409e-02, -4.4589e-02, -9.4993e-02,  2.2768e-02,\n",
       "         1.5086e-02, -2.2316e-02, -7.8282e-02, -4.2486e-02,  7.2754e-05,\n",
       "         4.2804e-02, -2.0463e-02,  2.6951e-02, -1.8493e-02, -2.9836e-02,\n",
       "        -1.9854e-04,  1.9273e-02,  1.2432e-02, -1.0836e-02,  6.0528e-02,\n",
       "        -9.7952e-03, -1.1429e-02,  1.3931e-01,  3.1228e-02, -6.4220e-02,\n",
       "        -2.9261e-02, -2.3055e-02,  2.5766e-02,  1.3478e-02, -6.4695e-02,\n",
       "         3.8260e-02, -3.7902e-02,  1.7107e-02,  1.4244e-02,  2.4134e-02,\n",
       "         1.8708e-02,  1.8243e-02,  1.2370e-02,  1.9654e-02, -1.2712e-02,\n",
       "         9.4879e-03,  6.1681e-03, -3.6787e-02,  5.5356e-02, -1.4332e-02,\n",
       "        -7.6049e-03, -3.6390e-02,  3.3026e-02,  4.0281e-03,  8.1291e-02,\n",
       "        -1.8114e-03, -3.1016e-02,  4.0858e-03, -1.4446e-03,  2.4152e-03,\n",
       "        -2.9267e-02,  1.9104e-02, -2.3024e-02, -3.7859e-02,  4.6457e-03,\n",
       "         1.4243e-02, -1.5710e-02, -5.3045e-03, -8.0267e-03,  2.1990e-02,\n",
       "        -3.8049e-04, -6.3379e-02,  3.1269e-03, -2.2442e-02,  6.4880e-02,\n",
       "         5.5743e-03,  2.8432e-02,  2.3638e-02,  1.3207e-02,  3.2959e-02,\n",
       "        -2.1044e-02, -1.2233e-02,  4.6198e-03,  6.9777e-03, -4.0380e-02,\n",
       "         6.4383e-03, -1.9755e-02, -3.1810e-02, -1.2006e-02,  5.7193e-02,\n",
       "        -2.3793e-02,  5.0507e-02, -4.2784e-02,  2.0083e-02, -2.6002e-02,\n",
       "        -2.9316e-02,  8.3723e-03, -3.7716e-02,  1.1169e-02, -2.4375e-02,\n",
       "        -1.1084e-02,  6.0821e-02, -2.5305e-02, -1.2053e-02,  2.8552e-03,\n",
       "        -5.6494e-02, -6.2991e-03, -6.7013e-02, -5.8186e-03, -4.2305e-03,\n",
       "         4.7443e-02,  6.9741e-02,  3.5257e-03, -7.5313e-02,  5.4222e-03,\n",
       "         3.9520e-02, -4.0843e-02, -8.0579e-03, -5.4606e-03, -4.4398e-02,\n",
       "        -2.4779e-02,  4.7052e-02, -4.4199e-02,  2.0972e-02, -2.0710e-02,\n",
       "         4.5789e-03,  4.9785e-04,  6.7943e-02,  3.2311e-03, -1.5537e-02,\n",
       "        -1.4358e-02, -2.2760e-02,  1.9794e-02,  8.9712e-03, -2.0073e-02,\n",
       "        -6.9717e-02,  4.1929e-02,  1.8761e-03, -3.7546e-03,  6.3884e-02,\n",
       "         2.1578e-02,  3.1592e-02,  1.8440e-02,  5.5160e-02, -2.9230e-02,\n",
       "        -2.0348e-03,  5.0068e-02,  3.0139e-03, -3.6419e-03,  1.5489e-02,\n",
       "         4.4928e-02,  2.7166e-02,  5.5643e-02, -2.2134e-02, -7.9708e-02,\n",
       "        -2.4465e-02, -3.2018e-02, -4.7271e-03, -6.8544e-02, -4.1123e-03,\n",
       "         9.6143e-03,  2.6496e-02,  3.6954e-02, -3.7683e-02,  3.4751e-02,\n",
       "        -3.0049e-02,  1.6636e-02, -1.4511e-02,  3.4720e-02,  6.9481e-03,\n",
       "        -4.3293e-03, -1.3644e-02, -6.1972e-02,  3.0734e-02, -4.0715e-02,\n",
       "        -1.6032e-02,  2.0423e-02,  1.1997e-02,  1.7687e-02,  4.2399e-02,\n",
       "        -7.6239e-03,  4.6618e-03, -3.6088e-02, -2.2161e-02,  1.4840e-02,\n",
       "        -6.0305e-03, -2.1840e-03, -1.5143e-02, -9.8559e-03, -2.9112e-02,\n",
       "         2.2626e-02,  1.5954e-02, -1.4504e-02,  2.7488e-02, -3.0254e-02,\n",
       "         3.7273e-02, -1.4265e-02, -2.5846e-02,  7.3139e-02, -2.0595e-03,\n",
       "         5.0800e-02,  4.3503e-02,  1.7414e-03,  9.3687e-02, -1.5947e-02,\n",
       "        -3.1667e-03,  4.6709e-02, -3.6532e-02,  4.5078e-02,  9.4711e-03,\n",
       "         4.6065e-02,  1.1137e-02, -6.6962e-03, -1.9513e-02, -2.8566e-02,\n",
       "         2.7834e-02,  1.7508e-02,  1.0166e-01,  6.0581e-02,  6.8540e-02,\n",
       "        -7.1939e-03, -3.8328e-02, -4.5113e-02,  2.3354e-02,  6.6034e-02,\n",
       "         3.1705e-03,  5.4064e-03,  3.0842e-02,  4.9758e-02,  2.1252e-02,\n",
       "        -2.9906e-02,  3.3028e-02, -1.3590e-04, -9.2143e-03,  2.4080e-02,\n",
       "        -2.9300e-02,  3.2137e-02,  3.4608e-02, -1.0373e-02,  4.2124e-02,\n",
       "        -6.5943e-03,  2.3610e-02, -1.0908e-03, -7.4411e-03,  1.3998e-03,\n",
       "        -2.6128e-03, -2.2660e-02,  3.0651e-02, -3.5572e-02,  4.6597e-02,\n",
       "         2.5983e-02, -7.3550e-03,  2.8565e-02,  5.8054e-02, -1.5904e-02,\n",
       "        -6.3859e-02,  5.4357e-02,  8.1437e-03, -2.1464e-02,  5.2289e-02,\n",
       "        -4.2149e-02, -3.1661e-02,  1.4245e-02, -4.2902e-02, -2.9134e-02,\n",
       "        -4.8411e-02, -3.9055e-02,  1.2708e-02,  7.0667e-02, -3.2644e-02,\n",
       "         4.2491e-02,  2.7789e-02,  8.4213e-03, -6.0211e-02,  9.1563e-03,\n",
       "         1.3136e-02,  3.1423e-02,  4.2294e-02,  1.4042e-02,  8.3110e-03,\n",
       "        -5.3872e-03, -3.9978e-03, -2.3108e-02, -2.3223e-02, -4.5802e-03,\n",
       "        -5.5258e-04, -3.1401e-02,  2.1772e-02, -2.6292e-02, -8.0303e-03,\n",
       "        -1.6644e-03,  2.0651e-02, -3.1484e-03, -4.8638e-02,  4.9416e-02,\n",
       "        -6.3119e-02,  6.9956e-02,  1.5378e-02,  9.2774e-03,  1.7766e-03,\n",
       "        -6.4034e-02,  1.3277e-02, -3.1839e-03, -1.9181e-02, -1.0016e-02,\n",
       "         7.7324e-02, -1.9588e-02,  2.6010e-02, -2.4356e-02,  2.2272e-02,\n",
       "        -1.1751e-02, -4.0125e-02, -1.2651e-02,  2.2005e-02, -1.1604e-03,\n",
       "         4.1064e-03,  8.6235e-03, -1.2996e-02,  4.0712e-02,  1.9510e-02,\n",
       "        -3.7377e-02,  1.3867e-02,  4.3006e-03,  6.0419e-02,  5.3292e-02,\n",
       "        -1.5814e-02,  4.6505e-02,  1.3342e-02, -3.5949e-02,  4.8245e-02,\n",
       "        -1.9295e-02, -2.9888e-02,  8.5234e-02, -2.5045e-02,  3.1161e-02,\n",
       "        -2.9353e-02, -1.7905e-02,  1.4017e-02,  2.1078e-03,  2.2804e-02,\n",
       "         8.0441e-03,  2.6234e-02, -8.2115e-03,  7.6653e-03,  3.5011e-02,\n",
       "        -8.2691e-03, -3.3343e-02, -3.4832e-02, -2.0009e-03, -4.8049e-02,\n",
       "         5.5961e-02,  5.0642e-02,  2.8939e-02, -2.0054e-02,  1.2186e-02,\n",
       "         5.4823e-02,  3.1385e-02, -3.4648e-02,  4.6334e-03,  3.4754e-02,\n",
       "         4.8816e-02, -3.5697e-02,  8.8472e-02,  5.3757e-02, -2.2724e-02,\n",
       "         2.9882e-02,  1.7340e-02, -5.0945e-02, -1.5952e-02, -1.1384e-02,\n",
       "         3.5664e-02, -3.6841e-02, -6.5946e-03,  5.4903e-02, -4.9367e-04,\n",
       "         1.1941e-02,  2.6201e-02,  1.5872e-02, -1.7005e-02, -3.6974e-02,\n",
       "         1.7685e-02,  2.0916e-02, -1.7292e-02,  3.4341e-02,  6.0981e-03,\n",
       "        -4.0844e-02,  6.2888e-03, -3.0668e-02, -2.1804e-02,  1.5044e-02,\n",
       "         3.7960e-02,  5.5269e-03, -3.0814e-02, -2.2103e-02,  3.3649e-02,\n",
       "        -3.5173e-02,  4.5840e-02, -1.9011e-02, -2.5159e-02, -7.9399e-02,\n",
       "         7.7826e-02,  4.1036e-02, -2.4337e-02,  4.6432e-02, -4.4177e-02,\n",
       "         4.1587e-02, -1.7150e-02, -6.2546e-03, -1.1812e-02, -2.6143e-03,\n",
       "         1.2373e-02, -1.1210e-03,  2.4276e-04, -2.1732e-03,  3.8833e-02,\n",
       "         4.7932e-02,  1.4315e-02, -1.1427e-02, -5.6679e-02, -1.3137e-02,\n",
       "        -2.7368e-02,  1.1111e-01, -4.3850e-02, -5.8643e-03, -1.1591e-02,\n",
       "         3.4656e-02, -3.2783e-03, -3.3710e-02,  1.3877e-02, -7.6983e-02,\n",
       "        -3.3119e-02, -2.1456e-02,  3.0375e-02,  1.7151e-02, -5.3346e-02,\n",
       "        -1.0133e-02, -2.2320e-02,  3.5144e-02,  3.5926e-02, -3.1312e-02,\n",
       "        -5.6428e-03,  2.5273e-02, -5.1110e-02,  2.4049e-02,  4.7395e-02,\n",
       "        -4.1702e-02,  4.2462e-02, -1.8999e-02,  1.8329e-02, -6.9585e-02,\n",
       "         1.3421e-02,  1.1165e-02,  6.1928e-02,  5.1561e-03, -3.2108e-03,\n",
       "        -3.0049e-02,  3.0984e-03,  1.0356e-02,  2.0548e-02, -1.2752e-02,\n",
       "        -1.5690e-02,  8.4802e-03, -4.6178e-03,  3.2923e-02,  2.3891e-02,\n",
       "         9.0643e-03, -7.7983e-02, -1.7617e-02, -1.1251e-02,  1.1087e-03,\n",
       "         1.5659e-02,  6.2011e-02, -8.0817e-02,  4.0540e-02, -2.1126e-02,\n",
       "        -3.8826e-02,  1.2601e-02, -3.1418e-02,  1.0544e-02, -2.4395e-02,\n",
       "         2.0202e-02,  2.4665e-03, -1.1469e-03, -2.6330e-02,  3.2127e-02,\n",
       "        -8.1545e-03, -4.1858e-02, -1.5011e-02,  2.5539e-02, -3.8043e-02,\n",
       "        -1.8105e-02, -2.7716e-02, -2.6680e-03, -5.5364e-03, -5.9777e-02,\n",
       "        -2.7591e-02, -2.4097e-02, -6.1980e-03,  2.7969e-02,  1.7478e-02,\n",
       "         9.2262e-04, -8.8178e-03, -4.1398e-03, -5.2409e-02, -3.2518e-02,\n",
       "         9.6245e-04,  3.8235e-02, -5.4744e-02, -1.0151e-02,  7.1734e-03,\n",
       "        -1.0426e-02,  4.1949e-02,  6.3495e-02,  8.7019e-03, -5.1651e-03,\n",
       "         2.1017e-02, -2.5522e-02, -1.8867e-02,  2.8826e-02, -2.9409e-02,\n",
       "         3.5835e-02,  2.7026e-02,  3.8970e-03, -8.0007e-02, -2.9295e-02,\n",
       "         5.0742e-03,  3.4798e-02,  3.5388e-03,  8.2460e-04, -1.0046e-02,\n",
       "        -7.2873e-03, -8.1588e-02, -1.4771e-02, -2.7193e-02, -4.4700e-04,\n",
       "         1.0757e-02, -3.8934e-02,  4.7224e-02,  4.4128e-03,  3.7715e-02,\n",
       "        -5.3018e-03, -4.0575e-02,  1.4318e-02,  6.6633e-03, -1.9957e-02,\n",
       "         8.1182e-02,  1.0262e-02,  3.9407e-03,  1.4064e-03,  6.9488e-04,\n",
       "        -4.4096e-02,  1.6100e-02, -4.8162e-03, -9.8598e-03, -3.9835e-02,\n",
       "         4.2888e-02, -1.4127e-02,  6.1560e-03,  2.9601e-02, -1.6333e-02,\n",
       "        -5.0029e-02,  1.3981e-02,  4.4488e-02,  3.4870e-02,  7.6951e-03,\n",
       "         3.5172e-02,  6.9713e-02,  3.2886e-02, -2.2482e-02,  7.5631e-03,\n",
       "        -6.3517e-03,  9.7199e-04, -3.7633e-02,  2.7245e-02,  2.8904e-02,\n",
       "        -1.5305e-02,  1.8926e-02,  9.7883e-03,  5.0295e-02, -2.0348e-02,\n",
       "         5.6180e-02,  3.9837e-02,  1.1906e-02, -2.9332e-02,  3.2395e-04,\n",
       "        -3.3811e-02,  7.8157e-03, -1.9346e-02, -4.7958e-02, -2.1880e-02,\n",
       "        -2.0233e-02,  3.6127e-02, -3.0514e-03,  6.0270e-02, -5.0225e-02,\n",
       "         4.5722e-04, -4.1267e-02, -7.7774e-03,  4.9479e-02, -3.4232e-02,\n",
       "        -5.9095e-02,  4.2140e-02,  1.5190e-02, -4.1618e-02, -1.5311e-02,\n",
       "         5.8206e-03, -1.5307e-02, -7.8603e-03], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig(\n",
    "            vocab_size=50265,\n",
    "            max_position_embeddings=514,\n",
    "            num_attention_heads=12,\n",
    "            num_hidden_layers=6,\n",
    "            type_vocab_size=1,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "PretrainedModel = RobertaModel.from_pretrained('ckpt/pretrain.pt')\n",
    "embeddings = PretrainedModel.embeddings.word_embeddings(train_dataset[6]['input_ids'])\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class DownstreamRegression is called\n"
     ]
    }
   ],
   "source": [
    "class DownstreamRegression(nn.Module):\n",
    "    print('Class DownstreamRegression is called')\n",
    "    def __init__(self, drop_rate=0.1):\n",
    "        super(DownstreamRegression, self).__init__()\n",
    "        self.PretrainedModel = deepcopy(PretrainedModel)\n",
    "        self.PretrainedModel.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        self.Regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.PretrainedModel.config.hidden_size, self.PretrainedModel.config.hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.PretrainedModel.config.hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.PretrainedModel(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.last_hidden_state[:, 0, :] #fingerprint\n",
    "        print(f'Finger print is:')\n",
    "        print(logits)\n",
    "        print(logits.size())\n",
    "        output = self.Regressor(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, loss_fn, train_dataloader, device):\n",
    "    print('Train func is called')\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print(f'Step: {step}')\n",
    "        print('Batch')\n",
    "        print(batch)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        print('Input ids of batch')\n",
    "        print(input_ids)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        prop = batch[\"prop\"].to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).float()\n",
    "        print('Output for step',step)\n",
    "        print(outputs)\n",
    "        loss = loss_fn(outputs.squeeze(), prop.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DownstreamRegression(drop_rate=0.1).to(device)\n",
    "model = model.double()\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, 1, shuffle=True, num_workers=8)\n",
    "train_features = next(iter(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,    2,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Parameters for scheduler\"\"\"\n",
    "steps_per_epoch = train_data.shape[0] // 1\n",
    "training_steps = steps_per_epoch * 1\n",
    "warmup_steps = int(training_steps * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "                    [\n",
    "                        {\"params\": model.PretrainedModel.parameters(), \"lr\":  0.00005,\n",
    "                         \"weight_decay\": 0.0},\n",
    "                        {\"params\": model.Regressor.parameters(), \"lr\": 0.0001,\n",
    "                         \"weight_decay\": 0.01},\n",
    "                    ],\n",
    "    \t\t\t\tno_deprecation_warning=True\n",
    "                )\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                        num_training_steps=training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1/1\n",
      "Train func is called\n",
      "Step: 0\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.5718])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-0.5176, -0.9323, -0.1437,  0.0531,  0.2703, -0.3818,  0.3870,  1.0132,\n",
      "         -1.6560,  0.5084, -0.3352, -0.5865,  1.7164, -0.3647, -0.9678,  0.6875,\n",
      "         -0.0872,  1.0151,  0.0847, -1.0124,  1.1203, -0.0944, -1.8041,  0.3186,\n",
      "          0.1512,  1.0526, -0.6302, -0.1237,  0.4636, -0.0404, -1.0653, -0.5420,\n",
      "          1.3747,  0.9958,  0.4591,  0.8262,  1.1500, -0.6663, -0.4408, -0.2712,\n",
      "          0.2931,  0.1988, -0.8942, -0.6872,  1.6694,  0.9793, -1.7019,  0.4316,\n",
      "          0.9035,  2.0879, -0.6509, -0.6382, -1.2922,  0.6469, -1.5470, -0.1580,\n",
      "          1.8387, -2.3704, -0.0434, -0.0338, -1.5362, -0.2429,  0.3083, -0.8494,\n",
      "         -1.0947, -0.3313,  2.6257,  0.5236,  0.8672,  0.1499, -0.7313, -0.2622,\n",
      "          0.9914,  0.5841, -0.4783, -1.9337,  0.2523,  2.2559,  0.9692,  2.4260,\n",
      "         -0.9839,  0.6863,  0.9184, -0.1630, -0.1944,  1.4205, -0.6316, -1.0018,\n",
      "          0.2669, -0.2657, -0.6631,  0.7172,  0.1877, -0.3247, -0.4893,  0.6222,\n",
      "         -1.0715, -0.1783, -1.9464, -0.5989, -1.4300, -1.9083,  0.1840, -1.1414,\n",
      "         -0.8417,  0.1509, -1.5436,  0.0547, -0.6349, -0.7230,  0.0787,  0.4024,\n",
      "          0.7075,  1.6077,  0.7720, -0.2082,  0.3860,  1.3025, -0.6117, -0.9323,\n",
      "         -1.4254,  0.0872, -1.7472,  0.4326, -0.0685,  0.3262, -0.6465,  0.5168,\n",
      "          1.2878,  1.0049,  0.9119, -1.0995, -0.9814,  0.3643, -1.0648,  0.7250,\n",
      "         -0.5550,  0.5050, -1.4585,  1.2872,  0.0035, -0.6724,  1.5673, -0.1828,\n",
      "          1.3385, -1.1465,  2.0224, -0.4178, -1.2356,  1.4532,  1.4950,  0.0116,\n",
      "          0.3469, -0.6005, -0.9778,  0.6559, -0.5343, -2.1721,  0.2086,  2.2315,\n",
      "         -0.7099,  1.9475,  0.9476,  0.7620,  0.4363, -0.0322, -0.1529, -0.5373,\n",
      "         -0.5810,  0.8107,  0.2644, -1.6149,  0.7522, -0.4455, -0.6618, -0.0600,\n",
      "         -1.4181,  1.1935, -0.9224,  1.0956,  0.3216,  0.1373, -0.8848,  0.6434,\n",
      "          0.2590, -2.5748, -1.0862,  0.8952,  0.8488,  1.2525,  1.2797,  0.0661,\n",
      "          1.1916, -1.0847, -0.4598, -0.7799,  0.6444, -0.0198,  0.4456, -0.7808,\n",
      "         -0.6530,  1.1392,  0.2200,  0.5620,  0.0479, -0.3361, -0.6717,  0.1946,\n",
      "         -0.9672, -0.1790,  0.7619,  0.3128, -2.0306, -0.9393,  1.3428,  0.1503,\n",
      "         -0.6324,  2.1069,  1.6775, -0.4339, -0.2436, -1.2741,  2.1523, -0.0861,\n",
      "          1.6955,  0.5609, -0.0659,  0.8140, -0.9383,  0.2888,  1.4030,  1.2069,\n",
      "         -0.6762,  1.2940, -0.0308,  0.4085, -0.8397,  0.3087,  0.1449,  0.4590,\n",
      "          0.9773,  1.2779,  0.0859, -0.0481, -0.1328, -0.8453, -0.9588, -0.9945,\n",
      "          1.4893, -0.3201, -1.2838,  0.0942,  0.7921, -0.0506, -0.4782,  0.9386,\n",
      "          1.0762, -0.1073, -0.7262, -0.1743,  0.0820,  2.7410, -1.1662, -1.7187,\n",
      "          0.6710, -1.3705,  0.8919,  0.1751,  0.2271,  1.2255,  1.1675, -1.4652,\n",
      "          0.1275, -0.3638, -1.0557, -0.3795, -0.5273, -0.3628, -1.6232, -0.1830,\n",
      "         -1.1389,  1.6457,  0.6858, -0.7044, -1.1519,  0.0359,  0.8567, -2.1053,\n",
      "         -0.8176,  2.5202, -0.7026, -0.9427,  0.2049,  0.0434, -1.0398,  0.7563,\n",
      "         -0.5433,  1.3966, -0.5767, -0.6424,  1.2750, -1.4138, -1.0098,  0.3086,\n",
      "          0.6590, -0.0725,  1.5190,  0.1820, -1.0388, -1.1618,  1.1124,  0.0040,\n",
      "          0.1846,  0.1493, -1.6727, -1.0464,  0.1615,  1.2205, -1.4739,  1.0862,\n",
      "          0.5465,  0.9238, -0.0831, -1.0096,  0.6099,  1.6893,  0.5776, -0.2878,\n",
      "          0.0516,  1.3237, -1.0238, -1.4776,  0.3011,  2.2531,  0.5511, -0.8336,\n",
      "          1.3581,  1.0464,  0.7136,  0.5250,  1.2761, -0.6854, -1.4924, -0.7388,\n",
      "         -0.6611,  0.9293,  1.4345, -1.1590,  0.8136, -1.0920,  1.5957, -1.0151,\n",
      "          1.0317, -0.6228,  0.1054,  0.1088, -1.1060, -0.8359, -0.6798,  0.0557,\n",
      "         -2.5824,  0.2161,  0.9453, -2.0041, -0.3205,  1.9120, -2.0343, -0.0651,\n",
      "         -0.9970, -0.5817, -0.6189, -0.1424, -0.1241, -1.6746, -0.4041, -0.3320,\n",
      "          0.2676,  0.5702, -1.0121, -1.1233, -0.3923, -0.6594, -1.7374,  1.7433,\n",
      "          1.8580,  1.1210, -1.1691,  0.3131, -0.2783, -0.2237,  0.0150,  1.0432,\n",
      "         -0.3458,  1.1891,  1.1885,  0.2441, -1.5694, -0.3436, -0.7363,  0.5227,\n",
      "          0.0460, -0.7353, -0.0938, -1.6896, -0.1755, -0.3291,  1.4827, -2.2639,\n",
      "         -1.0249, -0.2502,  1.6009,  1.1300,  1.3287,  0.8114, -1.4803, -0.4023,\n",
      "         -1.2490,  1.7549, -0.0285, -0.3349,  1.4729, -0.1051,  0.6563, -0.6736,\n",
      "          1.7883, -1.0039, -0.1917, -0.0244,  0.2158,  0.3450,  0.5993,  0.8865,\n",
      "          0.0268,  0.3227,  0.8143,  0.7294, -0.2421,  0.6295,  0.5538, -0.9194,\n",
      "          0.2423, -0.7126,  2.1970,  0.4457,  0.0937,  0.1035, -0.0390,  0.9577,\n",
      "         -0.1024,  0.7694,  0.5034,  0.9183, -1.4347,  1.1727,  0.6076, -2.1122,\n",
      "          1.0882,  1.3575,  0.2122,  0.6810, -1.1392, -0.1714,  0.3154,  1.8205,\n",
      "          0.1545,  0.8688, -0.7722, -0.2458, -0.1441,  0.2798,  1.1244,  0.1076,\n",
      "          0.7373,  0.5586,  0.3660, -0.9581,  0.5829,  0.2210,  0.0444,  1.9900,\n",
      "         -0.4209, -0.3532, -0.8411,  1.3331, -0.8769, -0.1465, -0.1782, -1.6996,\n",
      "          0.0109,  0.4685,  0.0083, -0.6393, -0.0399, -0.8859,  1.1437,  0.0573,\n",
      "         -0.6915, -0.4190,  1.6572,  0.8528, -1.5549,  0.1650, -0.5906, -0.3877,\n",
      "          0.8218, -0.2258, -0.4763,  0.2451, -1.7484,  0.3046, -1.5822, -0.2909,\n",
      "          0.1641,  1.5256, -1.1716, -0.3517,  0.0347,  1.0344,  0.6862,  0.1694,\n",
      "          1.5774,  0.2320, -0.0778,  0.8562, -0.6419,  0.0216,  0.8648,  1.7311,\n",
      "         -0.1661, -0.2333,  1.1523, -0.2619, -2.2228,  0.9358, -0.0690,  0.3442,\n",
      "          0.0756,  1.9981,  0.6146,  0.1635,  2.0693,  0.1283, -1.6263, -0.7052,\n",
      "         -0.6141,  0.4004, -0.9259, -0.9423, -0.0634, -0.9313,  0.8468, -1.8001,\n",
      "         -0.2218, -0.8149,  0.8112,  1.5150,  0.8641, -2.6078,  0.0046, -0.1158,\n",
      "         -1.2825, -0.2708,  0.0490, -0.9398, -0.4458, -0.8312, -0.0507,  0.5576,\n",
      "          0.6035, -1.0344, -0.2565,  0.8172,  0.9175,  0.2489,  0.3616, -1.8954,\n",
      "         -0.3984, -2.2908, -0.9572, -0.8901, -1.8869, -0.2639,  1.1965, -0.7652,\n",
      "         -0.0481,  0.2001, -1.4927,  1.0646,  0.1605, -0.4566,  0.1526, -0.5248,\n",
      "         -0.1633, -0.2610, -0.3307, -0.7583,  2.6709,  1.0693,  1.3558,  0.7920,\n",
      "         -2.0398, -0.5097, -1.8052, -0.1472, -0.5393,  0.2257,  0.3384, -0.4181,\n",
      "         -0.4510,  0.4242,  1.7431, -0.6667, -1.2676, -0.0806,  0.2196,  0.5406,\n",
      "         -0.0940, -0.8863,  1.3090,  1.1444, -0.1681,  1.7039, -1.3363,  0.1268,\n",
      "         -1.2658, -0.1579,  0.5387, -1.5710, -0.4575,  0.7977, -1.7356,  1.0954,\n",
      "         -0.5123,  2.4553, -0.9942,  0.5102, -0.0865, -0.6187,  0.7977,  0.0973,\n",
      "         -0.3577, -0.5691,  1.0815,  0.3106, -0.3649, -0.9358,  0.5376, -1.9875,\n",
      "         -0.2395,  0.6098, -2.3111,  2.1466,  1.9829, -0.7587, -1.2548,  0.1559,\n",
      "         -1.1381,  0.5197, -1.4365,  2.0122, -1.7365,  0.0730,  0.9137, -0.0518,\n",
      "          0.3744,  0.4026,  0.5839, -1.5150,  1.3632,  0.4458, -1.0589, -1.2709,\n",
      "         -0.3626, -0.4432,  1.2792,  1.0821,  2.3936, -1.1627,  0.2734, -0.8804,\n",
      "         -1.5950,  0.1692,  1.2123,  1.1835, -0.2062,  0.2190, -2.7438, -0.5733,\n",
      "          3.1627,  1.1918, -0.2752,  1.0080,  0.4474, -0.5522,  0.2439,  0.6720,\n",
      "          0.0210,  0.9265, -0.8971,  0.7845,  1.6423,  0.0781, -0.9426,  1.7382,\n",
      "         -0.6685,  0.3501, -0.1186, -1.5482,  0.8057,  0.1468,  0.0040,  0.0676,\n",
      "          1.1669,  0.5453, -1.7200, -0.7318, -0.2447,  0.5191,  0.0566, -0.2247,\n",
      "         -0.1512,  1.1409, -0.7729,  0.2499, -0.0550,  0.3224,  0.3155, -0.2206,\n",
      "          0.3450, -0.3127,  0.4314, -0.5620,  1.0696, -1.7410, -0.7658,  0.4211,\n",
      "          1.0334,  0.7638, -0.3563, -1.9371, -0.1784, -0.9457,  0.8603, -0.9373,\n",
      "         -1.0572, -1.4316, -0.2605,  0.7751,  0.6777,  1.1436, -0.8206, -0.7702,\n",
      "         -0.6894, -1.5490, -1.9209,  0.5132, -0.5345, -0.4979, -0.9596, -0.0865,\n",
      "          2.3006,  0.3572, -2.0851,  0.9282,  0.4576, -0.2096, -0.1587,  1.9270]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 0\n",
      "tensor([[0.0576]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.4409])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.5534e+00,  2.7567e-01, -1.2933e+00, -7.8015e-02, -2.2873e-01,\n",
      "         -1.9417e-01,  9.1421e-02,  3.2733e-01, -5.8334e-01, -3.9408e-01,\n",
      "          4.9815e-03, -1.5047e-01,  7.5608e-01, -1.0887e+00,  2.0428e-01,\n",
      "          2.8007e-01, -1.2897e+00,  1.4330e+00,  6.8047e-01, -1.1429e+00,\n",
      "          1.7842e+00, -4.8101e-01, -1.1378e+00,  3.4928e-01, -9.0068e-02,\n",
      "          1.6767e-01,  8.9688e-01,  2.4907e-01,  1.2012e-01, -3.3601e-01,\n",
      "         -2.6699e+00, -1.8285e-01,  1.0820e+00,  6.9763e-01, -2.1867e-02,\n",
      "          5.6788e-01,  1.2935e+00, -1.6080e+00, -2.2069e-01, -8.3560e-01,\n",
      "          8.0224e-01, -3.4031e-01, -3.6311e-01, -1.0672e+00,  1.0817e+00,\n",
      "          3.5406e-01, -1.7523e+00,  1.1903e+00,  1.0075e+00,  1.5641e+00,\n",
      "         -1.2203e+00, -1.4758e+00,  4.0510e-02,  1.8507e+00,  3.5201e-01,\n",
      "          5.9461e-01,  9.4151e-01, -1.5747e+00, -2.6512e-02, -6.2502e-01,\n",
      "         -3.6678e-01, -2.4905e-01, -1.0677e+00, -9.3057e-01, -4.4377e-02,\n",
      "         -5.2738e-01,  1.1964e+00,  5.5764e-01,  2.4531e+00, -1.1740e+00,\n",
      "         -1.4189e+00,  1.1926e+00,  5.6973e-01, -1.0916e-01,  3.0628e-01,\n",
      "         -1.0141e+00,  3.0995e-01,  7.5941e-01,  1.2418e+00,  7.1092e-01,\n",
      "         -3.7919e-01, -2.7255e-01,  1.0437e+00,  6.9387e-01, -4.8368e-01,\n",
      "          2.0419e+00, -8.6168e-01, -1.8672e-01,  6.0929e-01,  8.6466e-01,\n",
      "         -7.8239e-01,  6.6239e-01,  4.0335e-01,  4.8356e-01, -1.3485e+00,\n",
      "         -6.3119e-01, -6.5852e-01,  1.8465e-01, -1.8428e+00,  6.8421e-02,\n",
      "         -2.2072e+00, -2.3920e+00,  1.7698e+00, -2.8161e-01, -7.1217e-01,\n",
      "         -2.1265e-01, -1.3187e+00,  1.2641e+00,  7.9607e-01, -1.6003e-01,\n",
      "         -1.9378e-01, -5.4719e-01,  1.9136e-01,  3.6803e-01,  2.3710e+00,\n",
      "         -3.0732e-01, -8.5923e-03,  2.4743e+00, -7.0054e-02,  2.0641e-01,\n",
      "         -1.0556e+00,  6.2130e-02,  1.7568e-01,  1.4286e-01, -7.1555e-01,\n",
      "          5.9821e-02, -1.1510e+00,  1.8486e-01,  7.9609e-01,  4.4472e-01,\n",
      "          4.7079e-01, -9.2672e-01, -4.8712e-01,  2.4939e-02, -8.1619e-01,\n",
      "          1.5337e+00, -1.1135e+00, -1.2133e-01, -1.3158e+00,  2.6805e-01,\n",
      "         -3.7570e-01, -5.7280e-01, -4.2127e-02, -1.6179e+00,  8.8987e-01,\n",
      "         -1.3570e+00,  9.2301e-01, -1.5963e+00, -8.2803e-01,  1.2461e+00,\n",
      "          6.9465e-01,  3.7503e-01, -1.2227e+00,  5.0414e-01,  1.5531e-01,\n",
      "          1.9322e+00, -1.7626e+00, -1.1231e+00,  3.7393e-01,  3.1458e+00,\n",
      "         -7.7038e-01,  1.8729e+00,  6.1813e-02,  1.3807e-01,  1.1052e+00,\n",
      "         -1.5416e+00, -1.7442e-01,  2.6801e-03, -8.2464e-01,  4.4113e-01,\n",
      "         -4.2401e-01, -7.1066e-01,  3.1504e-01, -8.7116e-02, -3.1784e-01,\n",
      "          4.4646e-01, -2.8407e+00, -1.7776e-01,  1.1032e-01,  1.4197e+00,\n",
      "          2.1515e-01,  1.8008e-01, -2.5641e-01,  1.1307e+00, -3.1310e-01,\n",
      "         -3.4430e-01, -6.0677e-01,  8.3941e-01, -8.2870e-01,  7.6050e-01,\n",
      "          5.1741e-01, -3.9907e-01,  1.2478e+00,  5.4277e-02,  9.2377e-01,\n",
      "         -1.8107e+00,  1.3720e+00, -1.3359e+00,  9.3649e-01, -1.2010e+00,\n",
      "          3.4243e-01,  3.4233e-01, -4.3831e-01,  4.7963e-02, -4.5605e-01,\n",
      "         -1.8912e+00, -2.0188e+00, -3.1043e-01,  1.2279e-01,  2.5682e-01,\n",
      "          6.3152e-01,  5.0755e-01, -1.5470e-01, -1.8375e-01,  1.5297e+00,\n",
      "          1.5857e+00, -4.3080e-02,  1.4294e+00,  4.9229e-01,  5.0029e-01,\n",
      "         -3.7597e-01, -7.4037e-01, -1.0389e-01,  2.1179e-01,  1.3421e+00,\n",
      "          1.4299e-01, -5.4846e-01,  1.3753e+00, -2.3729e-01, -1.4079e+00,\n",
      "          5.3961e-01, -1.2509e-01, -1.0556e+00,  3.7143e-01, -3.1173e-01,\n",
      "          3.0113e-01, -1.3315e+00, -3.0353e-02,  4.3884e-01,  9.4137e-01,\n",
      "          2.5412e+00,  7.6527e-01,  6.8896e-03,  5.8206e-01, -8.2730e-01,\n",
      "          1.1010e-01, -1.7536e-01, -3.3422e-01,  1.4964e+00, -3.2788e-01,\n",
      "         -1.5590e+00,  2.2938e+00,  1.6590e-01, -5.4643e-01,  2.2306e+00,\n",
      "          5.1424e-01, -3.8905e-01, -5.8319e-02, -1.1563e+00, -1.0027e-01,\n",
      "         -1.7339e-01,  1.0803e+00, -8.4694e-01, -7.4940e-01,  3.8970e-01,\n",
      "         -2.4357e-01,  2.7662e-01, -3.5631e-01,  5.4177e-01, -7.1833e-03,\n",
      "         -4.0237e-01, -7.1380e-01, -9.1155e-01,  1.6602e-01,  2.6371e-01,\n",
      "         -1.9417e+00, -1.9587e+00,  5.7550e-01, -1.3932e-01,  2.1066e-01,\n",
      "         -1.2736e+00,  1.4274e+00,  4.1799e-01,  5.0443e-01, -3.6445e-01,\n",
      "         -1.7471e+00,  3.6634e-01, -1.7039e+00, -1.6537e+00,  1.0966e+00,\n",
      "         -2.5221e-01, -9.5898e-02,  1.0807e+00, -3.4839e-02, -2.6556e-01,\n",
      "          3.5445e-01, -1.3121e+00, -5.5640e-01,  2.1744e-01, -9.5464e-01,\n",
      "          1.6534e-01, -2.0673e+00, -6.2753e-01,  3.1874e-01,  1.2120e+00,\n",
      "          5.5904e-01,  2.9755e-01,  6.2040e-01,  1.3322e+00, -8.9634e-01,\n",
      "         -2.1474e-01,  4.9337e-01, -4.3623e-01,  5.7747e-01, -1.0686e+00,\n",
      "         -1.5659e+00,  9.5605e-01,  9.9969e-01, -2.7951e+00,  1.5101e+00,\n",
      "         -9.6462e-01,  7.4722e-01,  9.9891e-01, -1.2695e+00, -3.0023e-01,\n",
      "          2.3270e+00, -4.2546e-01,  1.4502e-01,  2.2678e-01,  2.4335e+00,\n",
      "          5.5760e-02, -1.7897e+00, -2.5345e-01,  1.0545e+00,  6.6456e-01,\n",
      "         -4.4633e-01,  7.7431e-01,  2.8813e+00,  4.1373e-01, -6.3018e-01,\n",
      "          1.3972e+00, -1.3140e+00, -1.6803e+00, -8.8586e-01, -4.7254e-02,\n",
      "         -2.3072e-01,  1.6256e+00, -1.2731e-01,  1.2848e-01, -2.7711e+00,\n",
      "         -7.0491e-01, -2.4205e-01,  6.3125e-01, -1.0213e-01, -1.4440e-01,\n",
      "          1.1633e+00, -1.6070e+00, -3.8464e-01,  7.6456e-01,  1.6049e-02,\n",
      "         -1.5614e+00,  9.9698e-01,  1.3968e+00, -3.0003e-01,  7.0273e-01,\n",
      "          2.1763e+00, -1.5306e+00,  2.5688e-01, -6.5672e-01, -8.2624e-01,\n",
      "         -2.1434e-01,  1.7230e+00, -1.6446e+00, -6.7445e-01, -8.4725e-02,\n",
      "         -6.0746e-02, -6.2091e-01,  1.0980e-02, -1.3150e+00, -9.1914e-01,\n",
      "          1.1647e+00, -1.4578e+00, -9.5445e-01,  2.1477e+00,  2.3339e-01,\n",
      "         -3.6540e-02, -1.3091e+00,  9.2713e-01, -1.0944e+00, -3.8505e-01,\n",
      "          6.3508e-02,  1.8054e-02,  2.3100e-01,  1.4053e+00,  1.3554e+00,\n",
      "          7.8257e-01,  3.0341e-01,  1.7288e-02,  7.5452e-01, -1.9561e+00,\n",
      "         -3.8873e-01, -6.9773e-01,  2.8019e-01, -9.2099e-01,  8.0209e-02,\n",
      "         -6.9681e-01,  8.0801e-01, -8.1491e-01,  8.3230e-01, -4.2262e-01,\n",
      "          1.9111e+00, -1.8419e-01,  1.2762e+00,  1.6875e+00, -2.3758e+00,\n",
      "         -3.3537e-01, -1.6003e+00,  5.7068e-01,  7.7557e-01,  1.9752e-01,\n",
      "         -1.8273e-01, -5.4046e-01,  8.3440e-01, -1.8020e+00,  1.7322e+00,\n",
      "         -8.9252e-01, -9.8610e-01,  5.1698e-01, -1.3506e+00,  9.9446e-01,\n",
      "          3.3040e-01,  1.0613e+00,  2.0838e-01,  2.9433e-01,  8.0594e-01,\n",
      "          1.3318e+00, -2.9301e-01,  3.8982e-01,  9.7364e-02, -1.2787e+00,\n",
      "          1.3075e+00,  2.4179e-02,  1.3718e+00, -2.4989e-02, -7.0377e-01,\n",
      "         -3.6119e-01,  2.5567e-01,  6.0362e-01, -1.0160e+00,  9.2244e-01,\n",
      "          1.1276e+00,  3.1415e-01, -7.0069e-01,  2.3986e+00, -7.1071e-01,\n",
      "         -1.6200e+00,  2.0874e+00, -1.3725e-01,  3.7529e-02,  8.1274e-01,\n",
      "         -5.4888e-01,  7.6401e-01,  1.2331e+00,  2.3494e+00, -5.3195e-01,\n",
      "          1.0828e+00, -9.7389e-01,  4.5361e-01,  8.2621e-01, -1.0243e+00,\n",
      "          1.6640e+00, -9.4573e-02, -2.7709e-02,  1.0823e+00,  3.7475e-01,\n",
      "         -3.5306e-01, -1.6196e+00,  6.3610e-01, -5.0974e-01, -9.5899e-02,\n",
      "         -7.6149e-01, -1.8169e-01, -5.0871e-01, -2.6354e-01, -1.6297e+00,\n",
      "         -7.9540e-01,  9.1449e-02, -2.8483e+00,  1.0613e-01,  3.5883e-01,\n",
      "         -5.9851e-01, -1.3400e-01, -3.0835e-01, -1.1714e+00,  6.7958e-01,\n",
      "          2.3662e-01, -1.6353e+00, -1.6215e+00,  7.9108e-01,  6.0115e-01,\n",
      "         -9.3556e-01,  6.0879e-01,  7.3142e-01, -1.5147e+00,  2.1235e-01,\n",
      "         -1.7330e+00,  3.0201e-01, -2.5000e-01, -1.8724e+00, -9.4796e-02,\n",
      "         -3.5477e-02, -1.1160e-01,  2.6531e+00,  8.9411e-01, -1.4761e+00,\n",
      "         -2.7673e-01, -6.2595e-01,  5.1490e-01, -4.4959e-01,  4.3532e-01,\n",
      "          9.2303e-01,  8.1866e-01,  1.9311e-01,  6.2975e-01,  1.0438e-01,\n",
      "         -3.9107e-01,  1.2131e+00,  8.9440e-01, -1.0662e+00, -5.2143e-03,\n",
      "          1.1476e+00, -2.2809e-01, -1.3298e+00,  2.6039e-01, -7.8771e-01,\n",
      "          1.1116e+00,  9.8579e-02,  1.8254e+00, -4.0342e-01,  2.1039e-01,\n",
      "          1.9479e+00, -1.3500e+00, -4.5042e-01, -4.8062e-02, -1.2146e+00,\n",
      "         -4.8182e-01, -4.3095e-02, -1.1521e+00,  4.7082e-01, -9.0566e-01,\n",
      "          1.7340e-01, -1.0425e+00, -1.0015e-01, -5.6331e-01,  9.1443e-01,\n",
      "          1.4580e-02,  7.6942e-01, -1.4020e+00,  5.8903e-01,  7.0081e-01,\n",
      "          1.1522e+00,  1.6299e-01,  2.9248e-01, -7.5922e-01, -6.3646e-01,\n",
      "         -1.5155e+00, -2.4278e-01, -2.3764e-01,  5.1108e-01,  2.9569e-01,\n",
      "          1.0668e+00,  3.3422e-03,  1.4546e+00,  2.0598e+00,  1.2726e+00,\n",
      "         -7.1369e-01,  3.6449e-01, -2.7636e+00, -8.1456e-01, -8.7652e-01,\n",
      "         -1.9852e+00,  3.0984e-01,  9.5827e-01, -1.8236e+00, -4.2597e-01,\n",
      "          2.0156e+00, -7.5793e-01,  1.3039e+00,  6.1458e-01,  8.5370e-01,\n",
      "          1.2613e+00, -7.3291e-01,  4.0397e-01, -1.8129e+00, -1.2027e+00,\n",
      "         -5.2060e-01,  5.5337e-01,  1.6233e+00,  2.9078e+00, -3.7811e-02,\n",
      "         -1.5812e+00,  5.1293e-01, -1.3057e+00, -2.4983e-01, -4.2099e-01,\n",
      "          3.0040e-01, -1.2354e-01,  1.0149e+00,  2.4489e-01,  8.4106e-01,\n",
      "          1.8472e+00, -3.8866e-01, -1.2397e+00, -5.5691e-01, -4.0608e-01,\n",
      "          4.5455e-03, -1.1748e+00,  5.2909e-01,  2.0083e+00,  5.0283e-02,\n",
      "          4.2427e-01,  6.9855e-01, -7.2824e-01, -2.8415e-02, -5.1838e-01,\n",
      "         -6.7592e-01,  2.1286e+00, -4.1954e-01, -7.1908e-01,  1.2660e+00,\n",
      "          2.6196e-01,  4.3834e-01, -4.4042e-01,  2.4023e+00, -1.7335e+00,\n",
      "          5.2168e-02,  2.1049e-01, -2.7405e-01,  4.4698e-01, -3.7569e-01,\n",
      "         -7.2803e-01,  4.6331e-01,  2.3257e+00, -9.4050e-01, -2.4612e-01,\n",
      "         -5.8487e-01,  3.4751e-02, -1.8996e-01,  6.9720e-01,  4.0001e-01,\n",
      "         -3.4324e-01,  1.4875e+00,  6.1387e-01,  7.3107e-01, -2.9298e-01,\n",
      "          2.7104e-01,  2.6216e-01,  1.6174e-01, -1.3638e+00,  7.6814e-01,\n",
      "         -6.6216e-01,  5.1875e-01,  1.0542e+00,  1.7217e+00, -1.3881e+00,\n",
      "          6.6786e-01,  3.0081e-02, -3.8129e-01,  5.8113e-01, -9.9294e-02,\n",
      "         -1.4067e+00, -1.8427e+00,  5.8667e-01, -1.5529e-01,  1.3502e+00,\n",
      "          9.0702e-01,  1.8033e+00, -1.3092e+00, -3.5837e-01,  5.1396e-02,\n",
      "         -1.7127e+00, -5.1625e-01,  3.4475e-01,  2.4943e-02,  7.0852e-01,\n",
      "         -1.3873e+00, -1.1115e+00, -2.0668e-01,  1.2502e+00,  2.0318e+00,\n",
      "         -8.9558e-01,  6.0281e-01,  3.9913e-01,  7.7645e-01, -5.8835e-01,\n",
      "          3.1680e-01,  1.4203e-01,  1.8939e-03, -8.4020e-01,  9.3438e-01,\n",
      "          1.4544e+00, -4.4705e-01, -2.7207e+00,  1.0199e+00, -6.5707e-01,\n",
      "          2.3912e-01, -7.3257e-01, -1.9467e+00,  1.0327e+00, -4.7008e-01,\n",
      "          1.1844e-01, -1.3686e-01,  1.0750e+00,  7.1185e-01,  2.6880e-02,\n",
      "         -1.2188e+00, -3.5131e-01,  1.6102e+00, -8.4928e-01, -4.3979e-02,\n",
      "          5.7030e-01,  9.5574e-01, -4.0035e-01, -3.8779e-01,  4.5669e-01,\n",
      "         -3.7620e-01,  1.0809e+00, -1.5178e+00, -3.4734e-01, -2.9173e-01,\n",
      "          4.8793e-01,  1.1324e-01,  1.0491e+00, -7.7640e-01, -1.1364e+00,\n",
      "          1.2058e+00,  7.2041e-01,  5.0206e-01,  1.6887e-01, -1.1904e+00,\n",
      "         -2.9671e-01, -6.0900e-01,  6.0929e-01,  6.9917e-01,  1.0340e+00,\n",
      "         -6.4300e-01, -9.0129e-01,  5.3796e-01, -4.0469e-01,  2.8874e-01,\n",
      "          1.9361e-01, -1.3499e+00, -1.9758e+00, -7.2780e-01, -2.2146e+00,\n",
      "          6.9334e-01,  6.4406e-02,  4.4978e-01, -5.6140e-01, -4.6876e-01,\n",
      "          1.8473e+00, -2.5058e-01, -2.4258e+00,  1.8157e+00, -3.3567e-02,\n",
      "          4.8816e-01, -7.9617e-02,  4.0033e-02]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 1\n",
      "tensor([[0.6612]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347, 5214,  347,  347,  347,  347, 3226,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([-0.7105])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347, 5214,  347,  347,  347,  347, 3226,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[ 1.6022e-02, -1.5981e-01,  5.9132e-01, -8.4123e-02,  5.0214e-01,\n",
      "          4.8114e-01, -3.7365e-01, -1.8599e-01, -1.3166e+00, -2.7860e-01,\n",
      "         -5.7727e-01, -1.4124e-01,  6.7427e-01,  3.5830e-01, -1.1931e+00,\n",
      "          3.5697e-01,  1.2948e+00,  1.1396e+00, -7.5037e-01,  2.2823e-01,\n",
      "          7.9666e-01, -4.8419e-02, -4.8901e-01, -3.2543e-01,  1.6370e-01,\n",
      "          3.8533e-01, -9.9311e-02, -7.6897e-02,  6.8176e-01,  3.8696e-01,\n",
      "         -1.4987e+00, -2.6842e-01,  4.6302e-01,  1.0446e+00,  1.7751e+00,\n",
      "          1.1138e+00,  3.0718e-01, -1.2784e+00, -1.0815e+00,  6.1009e-02,\n",
      "          2.9930e-01, -3.6056e-01, -2.5187e-01,  1.9350e-01,  2.1515e+00,\n",
      "          1.2598e+00, -7.8736e-01,  1.4958e+00,  4.9044e-01,  1.1736e+00,\n",
      "         -6.9822e-01,  2.2786e-01, -1.3730e+00, -8.8197e-02, -1.0219e+00,\n",
      "          1.9139e-01,  7.4659e-01, -1.0790e+00, -1.9622e-01, -9.5479e-02,\n",
      "         -1.3634e-01,  8.0483e-01,  3.3182e-01, -6.7995e-01, -7.0442e-01,\n",
      "          3.3767e-01,  1.9553e+00,  8.8487e-01,  4.3764e-01,  2.6104e-02,\n",
      "         -7.9914e-01, -1.1700e+00, -1.4149e-03, -9.6573e-02, -6.3864e-01,\n",
      "         -2.1791e+00, -4.1913e-01,  1.0425e+00,  5.6010e-01,  2.4492e+00,\n",
      "         -1.1738e+00,  8.8594e-01, -3.9530e-01,  9.1472e-01, -4.2106e-02,\n",
      "          6.8480e-01, -2.0815e-01, -6.2976e-01,  3.1142e-01,  4.4376e-01,\n",
      "         -1.4252e+00,  1.1444e+00,  4.2589e-01, -3.8702e-01, -1.5751e+00,\n",
      "          2.2729e-01, -1.8511e+00, -1.0299e+00, -2.1367e+00, -4.5318e-01,\n",
      "         -8.9958e-01, -1.8455e+00, -5.2194e-02, -1.6605e+00, -1.2728e+00,\n",
      "          5.2652e-01, -1.0768e+00,  3.0086e-02,  6.6614e-02, -1.2520e-01,\n",
      "          3.3788e-01,  3.1187e-02,  3.3154e-01,  1.2674e+00,  2.7492e-01,\n",
      "         -3.7711e-01,  6.1618e-01,  1.1347e+00,  3.2558e-01, -6.4406e-01,\n",
      "         -1.7911e+00,  9.7945e-02, -1.5284e+00,  8.3238e-01, -7.3882e-02,\n",
      "          2.3717e+00, -1.1662e+00, -5.5559e-02,  1.9458e+00,  9.0458e-01,\n",
      "         -3.9750e-01, -1.5104e+00, -9.1710e-01, -1.2465e-01, -1.3255e+00,\n",
      "          1.5359e+00, -1.2487e+00, -1.6499e-03, -2.3909e+00,  1.0043e+00,\n",
      "         -4.0012e-01, -2.7133e-01,  9.2397e-01, -1.2438e+00,  9.8518e-01,\n",
      "         -1.3618e+00,  1.6573e+00, -2.4366e-01, -1.1631e-01,  1.6637e-01,\n",
      "          2.0070e+00,  4.6711e-01, -7.4421e-01, -7.8097e-01, -1.3785e+00,\n",
      "          1.0153e+00, -7.9196e-01, -2.1690e+00,  7.7340e-01,  7.6114e-01,\n",
      "         -6.0270e-01,  3.0106e+00,  1.7880e-02,  7.4421e-01,  4.6249e-01,\n",
      "         -2.6216e-01, -3.9600e-01, -9.5707e-01, -6.5893e-01,  1.6004e+00,\n",
      "          3.3816e-01, -1.4981e+00, -4.1168e-01, -3.5315e-01, -9.6144e-01,\n",
      "         -2.8976e-01, -9.5134e-01,  1.2761e+00,  9.7900e-01,  8.2648e-01,\n",
      "          7.9113e-01,  2.5923e-01, -5.0212e-01,  1.6872e+00,  3.0064e-01,\n",
      "         -2.1960e+00, -4.5228e-01,  2.0389e-01,  5.2490e-01,  1.8895e+00,\n",
      "          1.8408e+00, -1.9672e-01,  8.3540e-01, -1.2148e+00, -3.1510e-01,\n",
      "          6.9955e-01, -3.0397e-01, -2.0658e-01,  1.8421e+00, -3.1405e-01,\n",
      "         -8.2401e-01,  5.2550e-01,  7.4942e-02, -3.7501e-01,  7.8466e-01,\n",
      "          3.5937e-01, -2.8980e-01, -1.6763e-01, -5.9451e-01, -6.5417e-02,\n",
      "          6.2619e-01,  4.9959e-01, -9.1325e-01, -1.5639e+00,  5.2369e-01,\n",
      "          4.0738e-01, -6.2396e-01,  8.7304e-01,  6.1714e-01, -1.8485e-01,\n",
      "         -3.6727e-01, -1.5741e+00,  1.7954e+00,  9.9923e-01,  1.2119e+00,\n",
      "          4.1726e-01, -1.2279e-01,  3.5177e-01, -7.0640e-01,  2.9235e-01,\n",
      "          2.1344e-01,  4.1329e-01,  8.5969e-01,  4.4518e-01, -7.2643e-03,\n",
      "          2.9800e-01, -1.1080e+00, -8.4982e-02,  6.1552e-01,  6.2095e-01,\n",
      "          1.4607e+00,  9.2638e-01,  3.7494e-01, -2.2125e-01,  4.7586e-01,\n",
      "          1.6132e-01,  8.1103e-01, -6.8765e-01,  1.4174e+00,  5.3317e-01,\n",
      "         -1.9554e+00, -4.3449e-01,  2.5213e-01, -5.7489e-01, -1.5234e-01,\n",
      "          6.3833e-01,  1.7326e+00, -2.3427e-01, -6.3207e-01, -8.0884e-01,\n",
      "          3.1077e-01,  1.8203e+00, -4.9558e-01, -1.6084e+00,  7.6816e-01,\n",
      "         -1.9622e+00,  8.6188e-01,  8.3586e-01,  8.1252e-01,  1.1749e+00,\n",
      "          1.0838e+00, -1.3704e+00, -2.3553e-01, -1.1175e-01, -1.1675e+00,\n",
      "         -1.2795e+00,  3.0801e-01, -3.0608e-01, -1.3182e-01, -2.0711e-01,\n",
      "         -9.4717e-01,  1.5867e+00,  7.7085e-01, -1.0071e+00, -1.8436e-02,\n",
      "          4.3960e-01, -4.1053e-01, -1.5315e+00,  5.6884e-01,  3.1865e+00,\n",
      "         -5.7711e-01, -1.4549e+00,  1.8733e-01, -1.0691e+00, -9.0991e-01,\n",
      "          8.5028e-01, -5.4789e-01,  5.1855e-01, -3.1729e-01,  5.3390e-01,\n",
      "          9.9141e-01, -1.3191e+00, -9.3239e-01, -2.0776e-01, -1.6253e-01,\n",
      "         -5.0627e-01,  1.8048e+00,  1.5083e-01, -9.5334e-01, -7.8597e-01,\n",
      "          5.8101e-01,  9.6931e-02, -4.2478e-01,  8.1707e-01, -1.4663e+00,\n",
      "         -1.4855e+00,  4.0776e-01,  1.7398e+00, -1.0466e+00,  1.9007e+00,\n",
      "         -1.9981e-01,  3.7026e-01,  8.9752e-01, -1.6605e+00, -1.6801e-01,\n",
      "          1.1583e+00,  2.5249e-01,  4.2815e-01,  2.0572e-01,  1.5937e+00,\n",
      "         -8.6149e-01, -1.5361e+00, -4.6654e-01,  1.2395e+00,  1.1891e+00,\n",
      "         -3.1791e-01,  9.5535e-01,  3.2643e+00,  8.8009e-01,  2.2985e-01,\n",
      "          1.2886e+00, -7.6458e-01, -1.2449e+00, -1.0579e+00,  4.2595e-01,\n",
      "         -8.4287e-02,  5.7424e-01, -3.1463e-01,  2.9333e-01, -7.3567e-01,\n",
      "          9.6624e-01, -1.3962e+00,  4.0880e-02, -5.3415e-01, -6.9138e-01,\n",
      "          2.7800e-01, -1.1607e+00, -3.3413e-02, -1.3410e+00,  1.1097e+00,\n",
      "         -1.4210e+00, -1.7641e-01,  4.6558e-02, -2.2911e+00,  4.4493e-02,\n",
      "          1.8746e+00, -2.0566e+00,  4.0609e-01, -2.9325e-02,  2.1916e-01,\n",
      "         -7.6462e-01,  2.9547e-01,  3.1074e-01, -1.4457e+00, -8.6453e-01,\n",
      "          7.9624e-01, -1.3322e+00, -1.3396e-01, -6.4693e-01, -1.1478e+00,\n",
      "         -1.0684e-01, -4.3950e-01, -5.1719e-02,  1.4114e+00,  9.8122e-01,\n",
      "          8.8943e-01, -5.2137e-01,  5.7911e-01, -2.5186e+00, -5.3038e-01,\n",
      "         -1.4479e-01,  1.4741e+00, -2.7726e-01, -4.0682e-01,  1.0634e+00,\n",
      "         -3.1570e-01, -1.3266e+00, -1.0356e+00, -6.2396e-01,  1.8945e-01,\n",
      "         -3.9050e-01, -6.0865e-01,  6.9667e-01, -2.1360e+00,  5.8358e-01,\n",
      "          6.1269e-01,  8.1637e-01, -2.9904e+00, -8.3067e-01, -1.5264e+00,\n",
      "          7.3092e-01,  3.2893e-01,  1.4230e+00,  1.8137e+00, -1.5501e+00,\n",
      "         -6.6991e-01, -1.6724e+00,  1.2902e+00,  2.6776e-01, -1.0745e+00,\n",
      "          9.0197e-01,  3.1276e-01,  8.0202e-01, -4.5529e-01,  1.6083e+00,\n",
      "         -1.2759e+00,  1.9793e-01,  4.8833e-01,  1.3324e-01,  6.9113e-01,\n",
      "          5.3422e-01,  4.0319e-01, -4.5445e-02,  1.3495e-01,  2.2441e-01,\n",
      "          1.4973e+00, -8.4215e-01,  7.4609e-01, -6.0278e-01, -9.9575e-01,\n",
      "          3.5341e-02, -4.6081e-02,  1.2457e+00,  1.0840e-02, -1.4492e-01,\n",
      "         -6.2412e-01,  5.4511e-01,  7.6754e-01, -4.9091e-01,  8.1823e-01,\n",
      "          1.6270e-01,  9.8388e-01, -1.0166e+00,  6.8863e-01,  6.2424e-01,\n",
      "         -2.4342e+00,  1.2948e+00,  7.4635e-01,  1.4307e+00,  1.2888e-01,\n",
      "         -6.0401e-01, -5.9618e-01, -4.7008e-01,  1.3039e+00,  3.8787e-01,\n",
      "          2.9714e+00, -1.7873e-02, -6.5563e-01, -1.3905e-01,  6.7066e-01,\n",
      "          9.4462e-01,  4.2128e-01,  1.1181e+00,  8.4720e-01, -4.5749e-01,\n",
      "         -9.9537e-01,  8.2726e-01,  5.7890e-01,  1.0179e+00,  3.4361e-01,\n",
      "         -4.2144e-01, -1.2729e+00, -1.8496e-01,  2.6699e-01, -8.6299e-01,\n",
      "         -3.6261e-01, -7.0979e-02, -1.5272e+00, -6.3646e-01,  7.3606e-01,\n",
      "         -9.2555e-01, -3.9944e-01, -8.0446e-01, -6.8271e-01,  1.5167e+00,\n",
      "          1.2273e+00, -7.0350e-01, -4.0585e-01,  1.6705e+00,  9.8180e-01,\n",
      "         -1.0323e+00,  2.6038e-01, -5.9757e-01, -3.5751e-01,  9.3733e-02,\n",
      "          1.7075e-01, -9.9650e-02,  2.8860e-01, -1.6230e+00, -6.8873e-02,\n",
      "         -2.3158e+00, -3.0041e-02,  2.2450e+00,  1.3625e+00, -2.2340e+00,\n",
      "          4.1867e-01, -5.9532e-01,  1.6418e-01, -2.3938e-01,  9.2452e-01,\n",
      "          2.2753e+00, -1.9257e-01, -3.7290e-01,  1.1394e+00, -7.5648e-01,\n",
      "         -4.6234e-01,  6.2633e-01,  1.1387e+00, -5.4489e-02, -5.3541e-01,\n",
      "          2.1836e+00, -1.1831e+00, -2.5474e+00, -1.3124e-01, -2.0599e-01,\n",
      "          7.3675e-01,  5.6987e-02,  1.6323e+00,  7.4488e-01, -1.9636e-01,\n",
      "          2.0036e+00,  3.4227e-01, -2.1596e+00, -1.1610e+00, -8.4435e-01,\n",
      "          4.7543e-01, -7.0528e-01, -6.4718e-01,  4.6726e-01, -1.0196e+00,\n",
      "          1.0210e+00, -1.3849e+00, -2.1987e-01, -3.8445e-01,  9.0162e-01,\n",
      "          9.2811e-01,  5.6792e-01, -3.0955e+00, -1.5927e-01,  4.5171e-01,\n",
      "         -3.9010e-01,  3.2273e-02,  1.9073e-01, -1.8248e-01, -1.4001e-01,\n",
      "         -1.0556e-01, -6.0167e-01,  6.0538e-01, -5.7689e-01, -7.2851e-01,\n",
      "          1.1751e+00,  1.7109e+00,  6.7170e-01,  3.3152e-01, -1.6140e-01,\n",
      "         -8.5905e-01, -3.4322e-01, -2.2833e+00, -1.4153e+00, -1.0489e+00,\n",
      "         -1.5202e+00, -5.1431e-01,  8.3005e-02, -1.3948e+00, -7.0254e-01,\n",
      "         -1.2141e-01, -1.0473e+00,  1.1496e+00,  1.5205e-01, -6.5351e-01,\n",
      "          4.6184e-01, -1.1328e+00,  9.8633e-01, -6.7174e-01,  2.3571e-01,\n",
      "          2.0183e-01,  3.1072e+00,  6.8391e-01,  7.8716e-01,  1.9294e-01,\n",
      "         -1.5533e+00, -3.4815e-01, -1.2364e+00, -1.1427e-01,  3.5444e-01,\n",
      "          1.1690e+00,  6.4869e-01,  7.0523e-01, -1.4041e+00,  2.0378e-01,\n",
      "          6.1912e-01,  3.5982e-01, -1.2803e+00, -1.0517e-01,  9.6226e-02,\n",
      "          9.5018e-01,  9.8104e-01,  4.8404e-02,  2.1955e+00,  8.1017e-01,\n",
      "         -1.1855e+00,  4.3885e-01, -7.0331e-01, -1.3574e-01, -1.7410e+00,\n",
      "          4.7544e-01,  6.0690e-01, -1.1924e+00, -8.3150e-01,  1.0663e+00,\n",
      "         -1.7731e+00,  2.6094e-01, -3.8104e-01,  2.7048e+00, -1.9435e+00,\n",
      "          6.1482e-01, -2.7373e-01, -1.1967e+00,  8.6558e-01,  6.0453e-01,\n",
      "          4.8258e-01, -9.1712e-02,  4.9168e-01, -5.9108e-01, -8.1194e-01,\n",
      "         -1.1341e+00, -6.3575e-02, -1.1228e+00,  5.0305e-01,  4.3489e-01,\n",
      "         -2.3215e+00,  2.2429e+00,  1.7509e+00, -5.7592e-01, -1.3535e+00,\n",
      "          1.1333e+00, -6.5716e-01,  6.1653e-01,  8.0469e-02,  7.2820e-01,\n",
      "         -8.1154e-01,  4.2305e-01,  5.5954e-01, -6.2589e-01,  3.5556e-01,\n",
      "          1.2146e-01,  3.2120e-01, -1.9743e+00,  1.2275e+00, -2.9006e-02,\n",
      "          2.7035e-01, -4.1661e-01, -1.4024e+00, -2.1839e-01,  1.8354e+00,\n",
      "          2.6201e-01,  1.8962e+00, -1.1187e+00,  8.5706e-01, -1.4408e+00,\n",
      "         -7.9158e-01,  2.6794e-02,  1.2294e+00,  8.0664e-01,  3.3383e-01,\n",
      "          5.8686e-02, -2.4136e+00, -2.9620e-01,  1.9410e+00,  1.5704e+00,\n",
      "         -1.4717e-01,  1.2997e+00,  4.1183e-01, -6.6864e-02,  3.6301e-01,\n",
      "         -1.3086e-01,  2.3716e-01,  6.1762e-01, -1.4804e+00,  4.3462e-01,\n",
      "          1.4510e+00,  5.3697e-01, -3.9745e-02, -5.2636e-01,  4.0403e-01,\n",
      "         -2.1622e-01, -2.6598e-01, -1.2148e+00,  9.4595e-01,  4.4657e-01,\n",
      "         -1.9374e-01, -8.9710e-01, -3.7487e-01,  8.0205e-01, -1.3013e+00,\n",
      "         -1.1287e+00,  5.7365e-03, -8.9065e-03,  6.7933e-02, -5.0632e-02,\n",
      "          6.3974e-01,  9.6989e-01, -1.3049e+00,  1.0392e+00,  1.6012e+00,\n",
      "         -8.5863e-01,  2.0003e+00, -8.0612e-01,  1.6409e+00, -6.0578e-01,\n",
      "          5.5217e-01, -1.3654e+00,  1.0318e+00,  2.1426e-01, -1.3577e+00,\n",
      "          1.7407e+00,  6.6839e-01,  6.1582e-01, -9.4361e-02, -2.0151e+00,\n",
      "          2.1282e-01, -6.5381e-01,  1.6433e+00, -4.1833e-02, -1.2588e+00,\n",
      "         -7.1489e-01, -1.4882e+00,  4.7780e-01,  5.4645e-01, -4.6733e-02,\n",
      "         -1.1663e+00, -9.6264e-01, -6.9460e-01, -1.7378e+00, -1.4909e+00,\n",
      "          2.9769e-01, -4.4405e-01, -7.8961e-01, -5.6210e-01,  8.3024e-01,\n",
      "          2.7804e+00,  6.1674e-01, -1.8955e+00,  6.2758e-01,  4.2825e-01,\n",
      "         -3.6376e-01, -9.6084e-03,  1.4569e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 2\n",
      "tensor([[0.8934]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347,  134,  347,  347,  347, 1640, 3226,   43,  347,\n",
      "          134,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.7111])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347,  134,  347,  347,  347, 1640, 3226,   43,  347,\n",
      "          134,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.1973e+00, -9.5036e-01, -1.4005e+00,  3.1944e-01, -4.4918e-01,\n",
      "         -4.1396e-01,  4.3614e-01,  1.5200e+00, -9.0357e-01,  2.9340e-02,\n",
      "         -9.7804e-01, -2.1252e-01,  1.4124e+00, -1.3414e+00, -3.8566e-01,\n",
      "          6.7411e-01, -2.6797e-01,  1.0360e+00,  5.5758e-02, -1.1081e+00,\n",
      "          1.7604e+00,  1.4461e-01, -2.0461e+00,  6.1891e-02, -1.2013e-01,\n",
      "         -2.7144e-01,  5.4939e-01,  7.6004e-01,  5.3355e-01,  1.4416e-01,\n",
      "         -1.5914e+00, -1.9301e-02,  1.0941e+00,  1.0883e+00,  6.9332e-01,\n",
      "          6.9192e-01,  1.4406e+00, -1.6830e+00, -4.0580e-01, -1.5336e-01,\n",
      "          1.3125e+00, -1.3299e-01, -7.5407e-01, -9.6390e-01,  1.9866e+00,\n",
      "          1.7948e+00, -1.3673e+00,  5.8346e-01,  4.7074e-01,  1.4296e+00,\n",
      "         -2.2345e+00, -1.8230e+00,  8.0099e-01,  1.5195e+00, -6.7120e-01,\n",
      "         -1.1788e-01,  6.7573e-01, -6.7971e-01, -1.1193e+00, -1.0796e+00,\n",
      "         -1.8614e+00, -5.0268e-01, -4.9444e-01, -6.5205e-01,  1.1664e-01,\n",
      "          1.9378e-01,  1.1446e+00,  9.2861e-01,  2.0625e+00, -6.4326e-02,\n",
      "         -9.6706e-01,  4.6181e-01,  4.9227e-01,  5.3605e-01, -4.9613e-01,\n",
      "         -1.0285e+00,  2.6552e-01,  2.1225e+00,  1.9395e+00,  1.5235e+00,\n",
      "         -1.3773e+00,  8.4971e-01,  9.2075e-01,  1.0171e+00,  6.1354e-02,\n",
      "          1.1162e+00, -6.3639e-01, -2.1591e-02,  2.8822e-02, -6.1392e-01,\n",
      "         -1.0227e+00,  1.3492e+00,  1.2022e-02,  5.9948e-01, -1.8540e+00,\n",
      "         -1.1286e-01, -6.8653e-01, -8.3516e-01, -2.0962e+00,  2.0530e-01,\n",
      "         -1.4382e+00, -1.6897e+00, -3.1810e-02, -1.0676e-01, -4.9733e-01,\n",
      "          1.1119e+00, -9.9187e-01,  5.7322e-01, -2.3786e-03, -1.4987e-01,\n",
      "          3.8554e-01,  1.0660e-02,  7.6363e-01,  1.2373e+00,  1.7435e+00,\n",
      "         -4.7892e-01,  6.2705e-01,  1.8338e+00, -1.1365e-02,  3.1523e-02,\n",
      "         -2.5914e+00, -3.6165e-01, -1.0001e+00,  3.2789e-01, -1.5257e-01,\n",
      "          1.6404e+00, -8.4129e-01,  6.0440e-01,  1.9957e+00,  7.7685e-01,\n",
      "         -3.2745e-01, -1.1139e+00, -3.9747e-01, -1.3177e-01, -9.2481e-01,\n",
      "          1.8444e+00, -8.0747e-01, -1.0523e-01, -1.9024e+00,  7.5735e-01,\n",
      "         -7.7882e-01, -6.2343e-01, -1.4039e-01, -1.3456e+00,  4.2345e-01,\n",
      "         -1.3838e+00,  1.2312e+00,  3.6419e-01, -1.0215e+00,  7.5634e-01,\n",
      "          1.6303e+00, -3.2246e-02,  1.4054e-01, -6.5935e-01, -9.5116e-01,\n",
      "          1.0225e+00, -1.5654e+00, -1.6367e+00, -2.8957e-01,  2.1347e+00,\n",
      "         -1.6032e+00,  2.4396e+00, -3.1046e-01,  6.6829e-01,  5.1598e-01,\n",
      "         -7.0692e-01,  3.1335e-01,  4.1809e-01, -4.3865e-01,  6.0893e-01,\n",
      "         -3.1151e-01, -1.4363e+00, -1.2840e-01, -7.2205e-01, -7.9477e-01,\n",
      "          8.5886e-03, -1.7824e+00, -2.8677e-01, -1.3990e-01,  1.4839e+00,\n",
      "          9.0978e-01, -1.9073e-01,  1.2335e-01,  1.6040e+00,  7.0855e-01,\n",
      "         -2.0262e+00, -9.0332e-01,  8.3221e-01,  7.6116e-01,  2.3929e-01,\n",
      "          5.1033e-01, -8.5608e-01,  2.1007e+00, -2.1326e-01,  1.6147e-01,\n",
      "         -1.3350e+00, -6.8657e-02, -9.6244e-01,  8.2211e-01, -8.8837e-01,\n",
      "         -8.5913e-01,  5.0783e-01, -2.7917e-01, -7.1900e-01,  4.3031e-02,\n",
      "         -7.2514e-01, -1.1421e-01,  1.0708e+00,  2.2793e-01, -7.1837e-01,\n",
      "          1.2261e+00,  8.1914e-01, -1.3826e+00, -1.5954e+00,  1.4758e+00,\n",
      "          1.1885e+00,  1.5404e-01,  2.0447e+00,  2.4149e-01, -6.6793e-02,\n",
      "         -7.7003e-01, -1.1934e+00,  1.1786e+00,  3.8416e-01,  1.0647e+00,\n",
      "          1.8076e-02, -1.6687e-01,  7.2730e-01, -9.0513e-01, -1.1892e+00,\n",
      "          3.6859e-01,  8.2099e-01,  3.6312e-01,  7.9191e-01, -3.1757e-01,\n",
      "          5.9174e-01, -1.5142e+00, -7.9660e-01,  7.0561e-01,  4.8373e-01,\n",
      "          1.4287e+00,  1.1716e+00,  7.0526e-01, -2.0027e-01, -2.5936e-01,\n",
      "          1.0779e-01,  5.6687e-01, -5.6763e-01,  1.6854e+00, -2.6340e-01,\n",
      "         -1.8455e+00,  8.7295e-01,  9.2108e-01, -5.0117e-01, -4.5044e-01,\n",
      "         -1.7609e-01,  1.0268e+00, -1.1858e+00, -5.6212e-01, -6.1610e-02,\n",
      "         -1.2079e-01,  1.3721e+00, -1.3533e+00, -1.1920e+00, -4.3741e-02,\n",
      "         -7.4662e-01,  1.7470e-02,  1.1362e-01,  9.5369e-01,  5.9157e-01,\n",
      "          7.7176e-01, -1.1229e+00,  9.8301e-01, -4.4631e-01,  4.8958e-01,\n",
      "         -3.5384e-01, -7.7042e-01, -4.6773e-01, -3.3258e-01,  6.0873e-01,\n",
      "         -8.6292e-01,  9.1091e-01,  3.9039e-01, -5.1529e-01, -2.2792e-01,\n",
      "         -1.0653e+00,  1.1000e+00, -1.3074e+00, -7.8430e-01,  2.8995e+00,\n",
      "          4.2250e-01, -4.9886e-01,  4.8737e-01, -6.5371e-01, -1.3167e+00,\n",
      "          8.2677e-01, -1.2442e+00, -2.9997e-01,  5.1534e-01,  3.6455e-01,\n",
      "         -1.2245e-01, -2.4272e+00, -6.3654e-01,  1.5694e-01,  1.0926e+00,\n",
      "          4.6141e-01,  1.9110e+00,  7.9715e-01,  1.0337e+00, -9.8307e-01,\n",
      "         -1.0773e-01, -7.6887e-02,  5.6184e-01,  7.0223e-01, -1.1125e+00,\n",
      "         -1.2446e+00,  1.8468e-01,  5.3985e-01, -1.8216e+00,  7.2135e-01,\n",
      "         -6.5140e-01, -4.4877e-01,  1.7764e+00, -9.3639e-01, -9.4257e-01,\n",
      "          5.7420e-01,  2.2936e-01,  4.2085e-01,  1.6287e-01,  2.5415e+00,\n",
      "         -2.3828e-01, -2.1421e+00,  3.7449e-01,  4.0032e-01,  6.1640e-01,\n",
      "          1.4947e-02,  4.4729e-01,  1.9281e+00,  4.5305e-01, -2.6587e-01,\n",
      "          1.5150e+00, -1.9386e+00, -1.4283e+00, -1.1091e+00,  2.7050e-02,\n",
      "         -3.4324e-02,  2.2195e+00, -5.8667e-01,  1.2079e+00, -1.2679e+00,\n",
      "          9.6949e-01,  4.6387e-01,  1.1236e+00, -1.3221e-01, -6.2334e-01,\n",
      "          1.8790e+00, -2.0825e+00, -1.3344e-01,  3.8070e-01, -6.2451e-01,\n",
      "         -2.8375e+00, -4.8133e-02,  1.2002e+00, -2.2127e+00, -3.4960e-01,\n",
      "          1.9585e+00, -1.8390e+00,  1.2136e+00, -1.7776e-01, -1.6641e-01,\n",
      "         -2.0040e-01,  1.3594e+00, -7.4765e-01, -9.4489e-01, -9.6888e-01,\n",
      "          2.4570e-01, -1.3902e+00,  4.9572e-02, -3.9652e-01, -4.1506e-01,\n",
      "         -1.3313e-01, -9.7846e-01, -7.2489e-01,  1.9162e+00,  2.2019e+00,\n",
      "          9.4345e-01, -3.3775e-01,  8.8613e-02, -1.4721e+00, -8.2714e-01,\n",
      "         -1.1530e+00, -3.0740e-01,  5.3462e-01,  1.2932e-01,  5.8842e-01,\n",
      "         -3.2231e-01, -2.5634e-01, -4.4738e-01,  2.6146e-02, -1.0132e+00,\n",
      "         -9.9340e-01, -8.1957e-01,  4.5842e-01, -1.4057e+00, -8.6660e-02,\n",
      "         -1.1784e+00,  7.1426e-01, -9.7228e-01,  2.3579e-01, -1.7291e-01,\n",
      "          5.3808e-01,  7.9677e-01,  1.1977e+00,  1.8856e+00, -2.0469e+00,\n",
      "         -6.5342e-01, -1.2137e-01,  5.1034e-01,  3.0308e-01, -1.2746e+00,\n",
      "          1.2739e+00, -1.7103e-01,  3.4132e-01, -6.7088e-01,  9.6265e-01,\n",
      "         -8.7549e-01, -1.1089e+00,  6.6124e-01, -7.6951e-01,  1.0052e+00,\n",
      "         -3.8967e-02,  9.8855e-01, -9.5359e-01,  5.9246e-01,  4.9129e-01,\n",
      "          1.4048e+00, -3.8367e-01,  7.8292e-01,  5.1511e-01, -1.3557e+00,\n",
      "          8.5667e-01,  1.3598e-01,  1.4654e+00,  4.7652e-01, -8.3917e-01,\n",
      "         -9.5178e-01,  5.6037e-01,  1.2146e+00, -9.3845e-01, -1.7722e-01,\n",
      "          8.0087e-01,  1.2776e+00, -3.2878e-01,  1.9455e+00, -7.0232e-01,\n",
      "         -1.9853e+00,  1.7715e-01, -4.4593e-01, -2.2257e-02,  6.7971e-01,\n",
      "         -1.7973e-01, -2.1502e-01,  7.7662e-01,  2.0473e+00,  9.1461e-01,\n",
      "          1.7247e+00, -1.0010e+00,  5.8196e-01,  7.3394e-01,  1.2278e-01,\n",
      "          1.2071e+00, -1.1898e+00,  8.6974e-01,  6.5933e-01,  3.4078e-01,\n",
      "         -8.1299e-01, -5.8490e-01,  1.1537e-01,  4.3417e-02,  1.1715e+00,\n",
      "         -6.7655e-01, -9.4847e-01, -1.4901e-01,  6.9806e-01, -1.2314e+00,\n",
      "         -4.9513e-01,  4.0121e-01, -2.0551e+00, -8.6134e-01,  6.5750e-01,\n",
      "         -6.6154e-01, -1.0785e-01, -6.6175e-01, -1.9334e+00,  5.3298e-01,\n",
      "          3.9807e-01, -4.1621e-01, -1.1466e+00,  1.3845e+00,  1.0344e+00,\n",
      "         -1.5721e+00,  6.9069e-01, -6.0060e-01, -1.0857e+00, -3.1412e-01,\n",
      "         -4.6996e-01, -6.0265e-01, -9.8728e-01, -1.9768e+00, -2.5200e-01,\n",
      "         -9.1993e-01,  6.5430e-01,  2.2611e+00,  7.7288e-01, -1.2779e+00,\n",
      "          4.9746e-01,  1.8963e-01,  1.0453e+00,  8.6980e-02,  4.3736e-01,\n",
      "          2.4634e+00,  7.4026e-01, -1.4644e-01,  9.7690e-02, -4.7630e-01,\n",
      "         -2.2930e-01,  3.4690e-01,  2.5451e-01, -2.2668e-01, -1.3467e-01,\n",
      "          1.0299e+00, -1.3873e-01, -2.2749e+00,  8.6482e-01,  1.7622e-01,\n",
      "          9.1537e-01, -3.2472e-01,  2.0626e+00,  5.5273e-01, -2.7561e-01,\n",
      "          9.7237e-01, -3.3007e-01, -2.9583e-01, -1.4825e-01, -1.1397e+00,\n",
      "          2.5921e-01, -1.0324e+00, -1.1056e+00,  5.9144e-01, -1.0865e+00,\n",
      "          4.3869e-01, -1.3644e+00,  1.8788e-01, -6.1451e-01,  1.9361e+00,\n",
      "          4.9027e-01,  4.7722e-01, -2.1295e+00,  6.0677e-02,  5.0468e-01,\n",
      "          2.4340e-01, -2.5481e-02,  1.1285e+00, -4.4793e-01,  1.4441e-01,\n",
      "         -7.0385e-01, -6.3206e-01, -2.3841e-01,  4.9562e-01,  1.3541e-01,\n",
      "          1.2765e+00,  5.4037e-01,  1.0722e+00,  1.3120e+00,  2.9452e-01,\n",
      "         -6.4651e-01, -4.9764e-01, -3.0029e+00, -4.5691e-01, -1.2787e-01,\n",
      "         -1.7322e+00,  1.2249e-01,  9.4422e-01, -1.3346e+00, -2.5892e-01,\n",
      "          9.9098e-01, -9.0473e-01,  9.6288e-01,  6.1426e-01, -1.3950e-01,\n",
      "          1.3578e+00, -6.2483e-01,  2.1501e-01, -1.8836e+00, -7.7758e-01,\n",
      "         -2.1275e-02,  1.7879e+00,  1.4077e+00,  1.3996e+00, -3.6971e-01,\n",
      "         -1.8057e+00, -9.5431e-01, -6.6692e-01, -2.2766e-01,  5.9614e-01,\n",
      "          1.6831e+00,  4.6789e-01,  5.2472e-01, -4.3476e-01,  7.4583e-01,\n",
      "          1.6262e+00,  1.3244e-01, -1.7868e+00, -4.9118e-02, -9.0637e-01,\n",
      "         -1.7060e-01, -9.4529e-02,  6.5029e-01,  1.4749e+00,  2.3661e-01,\n",
      "          6.1726e-02,  1.3255e+00, -1.2208e+00, -7.2667e-01, -1.7291e+00,\n",
      "         -9.6417e-01,  2.1357e+00, -1.9613e-01, -5.6211e-01,  4.4624e-01,\n",
      "         -7.7999e-01,  7.7627e-01, -9.5313e-01,  2.1577e+00, -1.3905e+00,\n",
      "         -3.4599e-01, -3.2332e-01, -4.3741e-01,  5.0582e-02,  2.5429e-01,\n",
      "         -5.4578e-01,  4.7791e-01,  1.4605e+00, -8.5120e-01, -4.9271e-01,\n",
      "         -4.9177e-01, -2.0986e-01, -5.1755e-01, -2.5498e-01,  5.3996e-01,\n",
      "         -2.4519e+00,  2.1500e+00,  1.4563e+00,  1.3656e-01, -1.5378e-02,\n",
      "         -1.1570e+00, -1.6735e-01,  2.2134e-01, -4.1691e-01,  1.4452e+00,\n",
      "         -1.2741e+00,  6.4298e-01,  7.2530e-01,  9.9878e-01, -7.2894e-01,\n",
      "          4.1246e-01,  4.3360e-01, -1.3753e+00,  1.1993e+00,  1.1674e-01,\n",
      "          5.2893e-03, -5.2284e-01, -9.9563e-01, -3.7136e-01,  1.7054e+00,\n",
      "          1.2069e+00,  1.3620e+00, -1.6627e+00,  4.5285e-01, -4.3917e-01,\n",
      "         -9.3592e-01,  2.9390e-02,  1.1244e+00,  3.6620e-02,  4.1027e-01,\n",
      "          2.4863e-01, -2.2270e+00, -6.3424e-01,  2.9001e+00, -1.5008e-02,\n",
      "         -1.9048e-02,  3.9642e-01,  1.0002e+00,  2.7432e-01, -4.9722e-01,\n",
      "          2.8268e-01, -4.6425e-01,  4.8644e-01, -8.2850e-01,  6.1051e-01,\n",
      "          2.2927e+00, -6.1948e-01, -6.8771e-01,  1.2341e+00, -2.5929e-01,\n",
      "          9.3645e-01, -1.4079e-01, -1.5741e+00,  8.1684e-01,  1.7557e-01,\n",
      "         -4.6767e-01, -4.7334e-01,  5.2849e-01,  1.0578e+00, -1.3510e+00,\n",
      "         -1.1168e+00,  1.3430e-01,  6.7370e-01, -6.5300e-01,  6.8509e-01,\n",
      "          1.9164e-01,  2.6084e-01, -4.1787e-01,  4.5928e-01,  1.0231e+00,\n",
      "         -3.4920e-01,  2.1749e+00, -1.0811e+00,  3.8998e-01, -1.1215e+00,\n",
      "          7.3878e-01,  8.8122e-03,  9.3716e-01, -4.9750e-01, -1.4923e+00,\n",
      "          8.9472e-01, -8.5031e-01,  7.5041e-01,  4.2708e-01, -1.5123e+00,\n",
      "         -8.5504e-01, -8.7310e-01,  6.7473e-01, -4.2881e-01, -3.8109e-01,\n",
      "         -1.0960e+00, -1.1541e+00, -2.0979e-02,  1.6753e+00,  5.6346e-01,\n",
      "         -9.8030e-01, -9.2689e-01, -1.1451e+00, -1.6258e+00, -1.3774e+00,\n",
      "         -3.7769e-01,  8.4796e-01, -1.2069e+00, -5.1059e-01, -1.1595e+00,\n",
      "          2.5700e+00, -7.2870e-02, -2.0824e+00,  1.5675e+00,  1.2096e+00,\n",
      "          2.1336e-01, -2.1319e-01,  1.8782e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 3\n",
      "tensor([[0.6534]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.4393])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.3415e+00, -3.2923e-01, -1.5106e+00, -2.0425e-01, -3.8889e-01,\n",
      "         -2.9646e-01, -1.9899e-01,  6.4129e-01,  1.8063e-01, -7.5875e-01,\n",
      "         -2.3196e-01, -1.3428e-01,  4.7494e-01, -1.0660e+00,  5.4626e-01,\n",
      "          2.8757e-01, -1.3989e+00,  1.3464e+00,  1.9736e-01, -7.5565e-01,\n",
      "          2.1439e+00, -3.9944e-01, -1.0760e+00,  3.1811e-01, -2.9056e-01,\n",
      "         -3.3765e-01,  7.3095e-01,  1.2523e-01, -3.8005e-01, -5.7274e-01,\n",
      "         -2.3366e+00,  2.5918e-01,  9.0635e-01,  1.0711e-01, -1.7971e-01,\n",
      "          8.5215e-01,  1.3470e+00, -1.3883e+00, -1.0469e+00, -1.2405e+00,\n",
      "          6.1358e-01, -9.4081e-01, -1.3686e-01, -3.6344e-01,  1.0319e+00,\n",
      "         -9.6772e-02, -1.4960e+00,  1.3259e+00,  8.0048e-01,  1.4772e+00,\n",
      "         -1.4006e+00, -1.5441e+00,  7.2988e-01,  1.7143e+00,  1.1871e+00,\n",
      "          3.5196e-01,  5.6884e-01, -1.1396e+00, -1.2869e+00, -9.1861e-01,\n",
      "         -7.2102e-01, -2.2357e-01, -3.0183e-01, -4.6784e-01, -1.6636e-02,\n",
      "         -2.3995e-01,  6.1441e-01,  4.7624e-01,  2.0859e+00, -6.3284e-02,\n",
      "         -1.5040e+00,  1.5332e+00,  5.6081e-01,  2.9754e-01,  1.8807e-01,\n",
      "         -8.5300e-01,  1.2858e-01,  1.9737e-01,  1.0251e+00,  4.4610e-01,\n",
      "         -1.1207e-01, -5.7209e-02,  1.4352e+00,  6.2416e-01, -4.9370e-01,\n",
      "          1.6881e+00, -6.5641e-01,  9.3377e-03,  7.6582e-01,  2.9402e-01,\n",
      "         -2.6149e-01,  4.3134e-01,  5.5775e-01,  5.4535e-01, -1.5367e+00,\n",
      "         -1.4995e+00, -7.4146e-02,  3.8822e-01, -1.5773e+00,  3.7162e-01,\n",
      "         -2.0707e+00, -1.9677e+00,  8.4166e-01,  1.1791e-01, -3.9687e-01,\n",
      "         -4.1335e-01, -1.0111e+00,  1.6425e+00,  1.4085e+00, -4.0220e-01,\n",
      "         -2.3446e-01, -1.0582e+00, -2.1871e-01,  4.5836e-01,  2.3751e+00,\n",
      "         -2.0098e+00,  4.1237e-02,  2.1666e+00, -4.2732e-01,  2.8059e-01,\n",
      "         -6.8048e-01,  1.6717e-01,  3.8768e-01, -2.5086e-01, -6.0890e-01,\n",
      "          2.0297e-01, -8.5481e-01, -7.9691e-03,  4.9862e-01, -1.2111e-01,\n",
      "          9.2816e-02, -6.3669e-01, -3.4503e-01,  3.2478e-01, -3.2144e-01,\n",
      "          1.1117e+00, -1.1520e+00, -5.1661e-01, -1.0251e+00,  8.8346e-02,\n",
      "         -5.1762e-01, -6.1170e-02, -5.5752e-02, -1.2677e+00,  6.2178e-01,\n",
      "         -9.6858e-01,  1.0006e+00,  1.3321e-03, -6.9136e-01,  1.8054e+00,\n",
      "          4.3372e-01,  1.3252e-02, -1.2819e+00,  3.4985e-01, -4.5889e-01,\n",
      "          2.2208e+00, -1.4768e+00, -7.4794e-01,  2.1859e-01,  2.7423e+00,\n",
      "         -5.6215e-01,  2.2072e+00, -3.9181e-02, -2.1686e-02,  7.8714e-01,\n",
      "         -1.9611e+00,  2.8908e-01,  8.5328e-02, -7.7051e-01, -1.1517e-02,\n",
      "         -6.2737e-01, -1.5563e+00,  1.3889e-01, -3.9030e-03, -5.5785e-01,\n",
      "          3.1171e-01, -5.8807e-01, -8.4738e-01,  1.4519e-01,  1.5041e+00,\n",
      "          9.1947e-02,  3.4604e-01,  3.7928e-01,  1.1213e+00,  6.5362e-02,\n",
      "         -2.2000e+00, -6.4688e-01,  1.0072e+00, -1.0536e+00, -3.1645e-01,\n",
      "          8.6818e-02, -6.4721e-01,  1.2902e+00,  1.7579e-01,  1.2661e+00,\n",
      "         -2.0314e+00,  1.3789e+00,  1.5781e-01,  1.2260e+00, -1.0364e+00,\n",
      "          2.1560e-02,  1.2727e+00, -4.4212e-01, -2.8544e-01, -7.1142e-01,\n",
      "         -1.7063e+00, -1.6131e+00, -5.2923e-01,  4.9248e-01, -4.0442e-01,\n",
      "          6.5259e-01,  1.1639e-01,  2.1399e-01, -2.4903e-01,  1.5893e+00,\n",
      "          1.4446e+00,  1.1803e-01,  9.9556e-01, -7.5530e-02,  3.9280e-01,\n",
      "         -3.7453e-01, -7.4251e-01, -1.5673e-02,  4.8780e-01,  1.0150e+00,\n",
      "          5.4164e-01, -6.3091e-01,  1.2535e+00, -4.8488e-01, -1.6028e+00,\n",
      "          1.8821e-01, -2.7401e-01, -3.2188e-01, -8.0650e-03, -2.3217e-01,\n",
      "         -2.2877e-01, -1.8114e+00, -4.8535e-01,  5.1024e-01,  1.0691e+00,\n",
      "          2.7034e+00, -1.2287e-01,  1.4896e-01, -1.2982e-01, -1.4324e+00,\n",
      "          1.1568e-01, -5.3604e-01, -5.5706e-01,  1.2260e+00, -7.7637e-01,\n",
      "         -1.5115e+00,  1.8838e+00, -1.5583e-01, -4.3193e-01,  2.4115e+00,\n",
      "          8.2160e-02, -7.0086e-01,  5.1982e-02, -8.7542e-01, -5.6883e-02,\n",
      "         -4.3362e-01,  1.4594e+00, -9.3938e-01, -2.1522e-01,  6.9108e-01,\n",
      "         -7.9194e-02,  3.5588e-01,  7.2689e-02,  7.6185e-01, -5.8109e-02,\n",
      "         -3.1438e-01, -2.3933e-01, -1.0337e+00,  4.6756e-01, -4.1260e-01,\n",
      "         -1.7757e+00, -1.7769e+00,  8.3789e-01,  2.0747e-01,  3.5872e-01,\n",
      "         -1.5273e+00,  1.7712e+00,  3.5174e-02,  6.1324e-01,  3.6544e-01,\n",
      "         -5.0184e-01, -1.5873e-01, -1.3905e+00, -1.7086e+00,  4.7333e-01,\n",
      "          2.8009e-01, -2.4386e-01,  9.7051e-01, -1.3984e-01, -6.8724e-02,\n",
      "          3.1667e-01, -1.3794e+00, -5.9100e-01,  8.7168e-01,  2.9207e-01,\n",
      "          2.3611e-01, -1.7975e+00, -1.2958e-01,  3.2502e-01,  1.4856e+00,\n",
      "          6.7162e-01,  8.0753e-01,  5.2119e-01,  1.5387e+00, -1.1824e+00,\n",
      "         -3.3872e-01,  4.3043e-01, -4.5989e-01,  2.6877e-01, -7.9142e-01,\n",
      "         -1.2612e+00,  7.9999e-01,  9.8047e-01, -2.6394e+00,  1.0696e+00,\n",
      "         -1.2944e+00,  9.2672e-01,  1.2967e+00, -8.8878e-01, -1.4625e+00,\n",
      "          2.1837e+00, -1.3548e+00,  1.6860e+00,  5.4180e-01,  2.1898e+00,\n",
      "          5.5558e-01, -1.5314e+00,  2.5668e-01,  1.1797e+00,  5.4167e-01,\n",
      "         -1.4781e-01,  3.2405e-01,  1.7607e+00,  5.5307e-01, -1.2439e+00,\n",
      "          1.1062e+00, -1.2737e+00, -1.3845e+00, -1.2361e+00,  8.1854e-02,\n",
      "          5.9851e-01,  1.2791e+00,  1.5676e-01, -1.5691e-01, -2.6971e+00,\n",
      "         -1.0017e+00, -1.5370e-01,  4.7728e-01, -1.4972e-01, -5.3116e-01,\n",
      "          1.8624e+00, -1.4997e+00, -1.1622e-01,  1.1799e+00,  1.3827e-01,\n",
      "         -1.7215e+00,  1.1841e+00,  1.7591e+00, -1.8096e+00,  9.6692e-01,\n",
      "          1.9619e+00, -1.0791e+00,  1.0374e+00, -8.9186e-01, -3.3770e-01,\n",
      "         -2.6738e-01,  1.8958e+00, -2.0108e+00,  1.9314e-01,  3.9014e-01,\n",
      "         -2.3123e-01,  1.5365e-01, -3.2923e-01, -8.7039e-01, -2.9806e-01,\n",
      "          1.0935e+00, -2.0941e+00, -6.1004e-01,  1.9994e+00, -3.7428e-01,\n",
      "         -4.0114e-01, -1.9781e+00,  6.8061e-01, -8.0078e-01, -1.4768e+00,\n",
      "          3.7594e-01, -1.9928e-01,  5.9893e-01,  1.5337e+00,  1.2319e+00,\n",
      "          4.5410e-01,  7.8194e-01, -4.0120e-01,  1.0943e+00, -2.5544e+00,\n",
      "         -8.0462e-02, -4.7144e-01,  9.0944e-02, -8.0174e-01,  4.1140e-01,\n",
      "         -3.5273e-01,  5.5983e-01, -5.2990e-01,  1.0479e+00, -3.4173e-01,\n",
      "          1.8092e+00, -4.8459e-01,  1.7211e+00,  3.2178e-01, -7.5737e-01,\n",
      "         -4.2590e-01, -1.4667e+00, -1.2349e-01,  4.0404e-01, -2.1056e-01,\n",
      "         -8.4115e-01, -4.9981e-01,  6.3235e-01, -2.1348e+00, -1.0600e-01,\n",
      "         -4.7387e-01, -1.0824e+00,  4.2881e-01, -1.2668e+00,  1.2993e+00,\n",
      "          5.8183e-01,  1.7821e+00,  1.0998e-02, -4.6138e-01,  6.7555e-01,\n",
      "          1.5322e+00,  1.6210e-01,  1.1448e-01,  3.8406e-01, -1.3221e+00,\n",
      "          1.3210e+00,  1.3282e-01,  1.1230e+00, -1.9121e-01, -1.0125e+00,\n",
      "          9.8482e-02,  8.0071e-01,  3.7458e-01, -1.1028e+00,  4.1569e-01,\n",
      "          1.0413e+00,  7.4106e-01, -1.0888e+00,  2.4788e+00, -8.3916e-01,\n",
      "         -1.3145e+00,  1.7736e+00, -3.9477e-01, -2.2276e-01,  7.4957e-01,\n",
      "         -7.3863e-01,  1.0520e+00,  1.3059e+00,  1.8890e+00, -3.1106e-02,\n",
      "          1.2076e+00, -7.7070e-01,  7.4021e-01,  6.4901e-01, -1.0738e+00,\n",
      "          1.8446e+00, -6.6198e-01, -3.0467e-01,  6.4382e-01,  9.4917e-01,\n",
      "         -1.4228e-01, -1.7787e+00,  7.1806e-02,  6.5590e-01, -8.1849e-01,\n",
      "         -3.3075e-01, -4.2661e-01, -4.2948e-01, -7.6094e-01, -1.9435e+00,\n",
      "         -9.0297e-01, -2.6399e-01, -3.0037e+00, -2.0672e-01,  5.6904e-01,\n",
      "         -6.1952e-01,  7.8149e-02, -4.7425e-01, -1.5868e+00, -4.2003e-01,\n",
      "         -2.3335e-01, -1.9497e+00, -1.2772e+00,  1.0128e+00,  9.3579e-01,\n",
      "         -6.8888e-01,  7.9959e-01,  9.8662e-01, -1.5204e+00, -8.1477e-02,\n",
      "         -1.7788e+00,  2.5516e-01, -1.8663e-01, -1.6764e+00, -4.8894e-01,\n",
      "          5.2182e-02, -3.9781e-02,  2.4144e+00,  1.5456e+00, -1.4548e+00,\n",
      "         -1.2591e-01, -6.3406e-01,  5.9524e-01, -7.8197e-01,  7.9425e-02,\n",
      "          9.0970e-01,  7.3103e-01,  6.0610e-01,  3.3062e-01,  5.7631e-01,\n",
      "         -1.0775e+00,  1.6182e+00,  8.7594e-01, -2.8240e-02,  2.1347e-01,\n",
      "          3.3797e-01,  1.1375e-01, -1.0363e+00,  1.0990e-02, -6.7851e-01,\n",
      "          1.3688e+00, -9.9029e-02,  1.5429e+00, -1.2013e-01,  3.2433e-01,\n",
      "          1.8850e+00, -1.7045e+00, -1.6463e+00, -2.3917e-01, -1.5420e+00,\n",
      "         -4.4247e-01,  2.3543e-01, -1.1244e+00,  5.1562e-01, -8.0009e-01,\n",
      "          2.1737e-01, -6.4326e-01,  6.1558e-01, -7.5520e-01,  7.5487e-01,\n",
      "         -2.4145e-01,  3.6689e-01, -9.3226e-01,  8.4636e-01,  6.4207e-01,\n",
      "          1.3300e+00,  2.3465e-01,  1.6774e+00, -7.2762e-01, -6.2567e-01,\n",
      "         -6.6822e-02, -9.4408e-01, -4.4188e-01,  2.7291e-01,  6.9994e-01,\n",
      "          1.7234e-01, -2.8205e-01,  1.8842e+00,  1.5964e+00,  1.5244e+00,\n",
      "         -1.1051e-01,  4.3762e-01, -2.7127e+00, -1.3464e+00, -8.2895e-01,\n",
      "         -1.5764e+00, -8.9582e-02,  6.9647e-01, -7.8630e-02, -4.3755e-01,\n",
      "          2.9375e+00,  1.8371e-01,  1.8175e+00,  5.5828e-01,  8.3646e-01,\n",
      "          2.1569e+00, -1.1139e+00,  4.2805e-01, -2.0728e+00, -1.1812e+00,\n",
      "         -1.3549e-01,  5.4568e-01,  1.2151e+00,  3.1709e+00, -2.2528e-02,\n",
      "         -1.3398e+00,  7.7328e-01, -5.4119e-01, -5.3004e-02,  1.3651e-01,\n",
      "          8.5387e-02, -5.7349e-01,  9.3204e-01,  1.0303e-01,  4.5305e-01,\n",
      "          1.5910e+00, -3.8804e-01, -1.6325e+00, -6.9838e-01, -2.7059e-01,\n",
      "         -3.3475e-01, -6.8574e-02,  9.0426e-01,  1.4582e+00,  2.6653e-01,\n",
      "         -2.9306e-01,  7.8290e-01,  1.8119e-01, -1.2382e-01, -3.3297e-01,\n",
      "         -5.0446e-01,  1.9294e+00, -1.1472e-01, -6.2473e-01,  1.1218e+00,\n",
      "          5.9442e-01,  2.5934e-01, -6.8251e-01,  2.0632e+00, -1.6282e+00,\n",
      "         -2.3074e-02,  6.2102e-02, -1.8060e-01, -8.0986e-02, -2.3369e-01,\n",
      "         -1.0908e+00,  8.7429e-01,  2.1401e+00, -1.1980e+00, -3.8061e-01,\n",
      "         -4.1752e-01, -1.3371e-03,  2.5108e-01,  8.8468e-01,  5.1318e-01,\n",
      "         -9.8841e-02,  1.3380e+00,  1.5790e+00,  9.1284e-01,  8.3279e-02,\n",
      "         -9.9824e-02,  7.2186e-01,  9.3579e-02, -1.1228e+00,  1.8286e-01,\n",
      "         -3.0059e-01,  4.0819e-01,  1.3148e+00,  1.8221e+00, -9.7347e-01,\n",
      "          8.3194e-01,  1.1221e+00, -1.3769e-01,  6.2402e-02, -2.3801e-01,\n",
      "         -1.2952e+00, -1.4991e+00,  5.8589e-01, -7.1679e-02,  1.6998e+00,\n",
      "          8.2274e-01,  1.1964e+00, -9.6560e-01, -6.7983e-01,  1.5391e-01,\n",
      "         -1.4657e+00, -4.7404e-01,  9.0124e-02, -2.2509e-03,  3.2706e-01,\n",
      "         -1.6044e+00, -1.3840e+00, -2.0840e-01,  1.6465e+00,  1.9021e+00,\n",
      "         -5.4480e-01,  1.2404e+00,  7.3536e-01,  1.2639e+00, -2.4162e-01,\n",
      "          2.9933e-01,  3.2644e-01, -2.3478e-01, -9.2899e-01,  9.5868e-01,\n",
      "          8.9958e-01, -9.7409e-01, -2.8565e+00,  5.4792e-01, -6.6390e-01,\n",
      "          3.2940e-02, -1.1844e+00, -2.3290e+00,  1.2335e+00, -3.8134e-01,\n",
      "          1.4527e-01, -5.6204e-02,  1.2609e+00,  5.3013e-01,  9.5701e-02,\n",
      "         -1.2984e+00, -5.8016e-01,  1.8007e+00, -1.3114e+00,  2.5149e-01,\n",
      "         -4.1403e-01,  7.0020e-01, -4.6447e-01, -6.3677e-01,  5.4003e-01,\n",
      "         -6.8363e-01,  8.3893e-01, -1.6621e+00, -4.0262e-01, -1.4784e+00,\n",
      "         -5.1744e-03,  1.8845e-01,  8.8296e-01, -7.5211e-01, -1.0227e+00,\n",
      "          1.2856e+00,  8.1931e-02,  2.0519e-01,  9.4647e-01, -7.5081e-01,\n",
      "         -7.7651e-01, -2.3243e-01,  8.9523e-02,  7.7827e-01, -3.7242e-02,\n",
      "         -1.5804e+00, -5.7614e-01,  2.4413e-01,  1.7258e+00,  1.3545e-01,\n",
      "         -1.4369e+00, -1.3515e+00, -2.0352e+00, -2.3836e-01, -2.0364e+00,\n",
      "          6.2571e-01,  1.5572e-01,  4.2638e-02, -4.6982e-01, -6.3793e-01,\n",
      "          1.9655e+00, -4.8764e-01, -1.7162e+00,  2.2380e+00,  2.4980e-01,\n",
      "          5.6813e-01, -5.3952e-02,  7.5958e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 4\n",
      "tensor([[0.4928]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,  347,  134,\n",
      "          347,  347,  347,  347,  347,  134,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.3496])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347,  347,  347,  134,\n",
      "          347,  347,  347,  347,  347,  134,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-6.6889e-01, -1.4149e+00, -5.1914e-01, -2.3080e-01,  4.5452e-01,\n",
      "         -4.6344e-01,  6.4076e-01,  1.5925e+00, -2.2979e-01,  4.0345e-01,\n",
      "         -9.2619e-01, -7.8161e-01,  2.3558e+00, -9.0484e-01, -6.0352e-01,\n",
      "          6.4889e-01,  7.4784e-01,  4.1854e-01, -3.8708e-01, -7.7380e-01,\n",
      "          1.1113e+00,  1.5606e-01, -1.4283e+00, -2.7119e-01,  8.2148e-02,\n",
      "          6.0771e-02, -5.2645e-01,  7.8046e-01,  6.0656e-01,  8.0986e-01,\n",
      "         -3.8436e-01, -4.6763e-01,  5.7484e-01,  9.2591e-01,  9.9559e-01,\n",
      "          7.5509e-01,  1.0116e+00, -1.2789e+00, -3.3399e-01,  3.7483e-02,\n",
      "          1.2781e+00, -1.2562e-01, -1.1259e+00,  4.9488e-02,  2.5058e+00,\n",
      "          2.1685e+00, -8.2004e-01,  1.6810e-01,  4.1217e-01,  1.6605e+00,\n",
      "         -9.7960e-01, -1.4957e-01, -1.1565e+00,  5.2399e-01, -1.3446e+00,\n",
      "         -1.6837e-02,  6.1119e-01, -1.0002e+00, -7.4402e-01, -2.2713e-01,\n",
      "         -6.3079e-02,  4.5697e-02, -8.6938e-01, -3.5591e-01, -2.1569e-01,\n",
      "         -1.6939e-01,  1.6012e+00,  1.6510e+00,  7.5863e-01,  1.7073e-01,\n",
      "         -9.9600e-01, -1.8424e+00,  2.4571e-01,  3.6276e-01, -3.5131e-01,\n",
      "         -7.2314e-01,  8.2775e-01,  1.7044e+00,  8.3282e-01,  2.1819e+00,\n",
      "         -1.9383e+00,  1.2013e+00,  3.2496e-01,  9.3822e-01, -6.7956e-01,\n",
      "          6.6179e-01, -5.2588e-01, -6.7189e-01, -3.5729e-01, -1.6148e+00,\n",
      "         -8.6736e-01,  1.7518e+00, -4.3197e-01, -2.6915e-01, -7.7397e-01,\n",
      "         -2.0968e+00, -1.2064e+00, -1.8001e-01, -2.1214e+00, -5.2112e-01,\n",
      "         -1.2353e+00, -1.1964e+00,  1.6677e+00, -3.1770e-01, -1.1344e+00,\n",
      "          1.3186e+00, -2.2830e-01, -5.4436e-01, -1.1430e+00, -1.5036e-01,\n",
      "          1.6933e-02,  3.7831e-01,  1.3388e+00,  1.8579e+00,  6.9829e-01,\n",
      "          1.1792e+00,  8.0768e-01,  1.5561e+00, -3.2559e-01, -4.1790e-01,\n",
      "         -1.4785e+00, -4.6243e-01, -1.5790e+00,  8.8392e-01,  8.1100e-02,\n",
      "          1.7617e+00, -6.0057e-01,  3.6646e-01,  1.9485e+00,  1.0772e+00,\n",
      "          1.6309e-02, -9.5023e-01, -4.6655e-01, -7.9003e-01, -1.1582e+00,\n",
      "          1.8080e+00, -1.2400e+00,  2.2889e-01, -9.6544e-01,  1.8320e-01,\n",
      "          4.1740e-01, -2.8466e-01,  3.4460e-01,  5.8579e-01,  5.0559e-01,\n",
      "         -7.5394e-01,  1.3814e+00,  4.0003e-01, -5.8382e-01,  7.4450e-01,\n",
      "          2.3835e+00,  1.5874e-01,  9.0840e-01, -1.5553e+00, -1.2756e+00,\n",
      "          7.0480e-02,  4.4311e-01, -2.3242e+00,  1.7324e-01,  7.5602e-01,\n",
      "         -1.3374e+00,  1.8785e+00,  2.0669e-01,  8.4534e-02, -1.4637e+00,\n",
      "          3.4405e-01,  4.3115e-01, -2.2900e-01, -2.8964e-01,  1.0424e+00,\n",
      "          9.2780e-02, -1.0416e+00, -5.3813e-01, -6.3007e-01, -1.3055e+00,\n",
      "         -3.9649e-01, -6.2947e-01,  1.1587e+00,  1.4021e-01,  2.9359e-01,\n",
      "          9.5509e-01, -1.1276e+00,  6.2358e-01,  1.9845e+00,  1.3780e+00,\n",
      "         -1.8128e+00, -6.5401e-01,  3.5722e-01,  9.5131e-01,  9.0925e-01,\n",
      "          8.8183e-01, -5.4224e-01,  1.2388e+00,  2.2434e-01, -3.6039e-01,\n",
      "         -2.5005e-01, -8.3747e-01, -1.0444e-01,  1.3883e+00, -9.4840e-01,\n",
      "         -4.3657e-01, -2.1301e-01,  3.7195e-01, -6.7910e-01, -2.2487e-01,\n",
      "          6.9751e-01,  6.0183e-01,  2.1355e+00, -4.1714e-01, -5.4840e-01,\n",
      "          1.3478e+00,  7.3228e-02, -1.1028e+00, -1.6397e+00,  1.5638e+00,\n",
      "          1.6013e+00, -5.9157e-01,  1.3029e+00,  7.1781e-01,  5.1779e-02,\n",
      "         -1.4275e+00, -1.5595e+00,  2.5319e+00, -2.7276e-01,  8.2380e-01,\n",
      "         -4.5208e-03, -6.3139e-01, -1.4560e-01, -5.5190e-01,  1.7079e-01,\n",
      "          1.4544e+00,  1.2403e+00, -2.8550e-02,  9.6605e-01, -7.4738e-02,\n",
      "          6.4632e-01, -1.0005e+00,  6.2707e-03,  7.5622e-01,  4.8850e-01,\n",
      "          1.1252e+00,  1.3484e+00,  9.0346e-01, -4.3092e-01, -1.5881e+00,\n",
      "         -2.4383e-01,  1.0751e+00, -3.8054e-01,  8.7851e-01,  6.7163e-01,\n",
      "         -1.5922e+00, -5.0720e-01,  1.0669e+00,  1.2504e-01, -7.7117e-01,\n",
      "         -5.2713e-01,  4.2597e-01, -1.6106e+00, -4.0103e-01,  1.5701e-01,\n",
      "          4.5360e-01,  1.2954e+00, -1.1563e+00, -1.4965e+00, -5.9480e-01,\n",
      "         -9.8845e-01,  2.1740e-01,  1.2446e+00,  9.6358e-01,  1.7374e+00,\n",
      "          7.5947e-01, -1.8475e+00,  3.9579e-01, -6.6331e-01, -8.5925e-01,\n",
      "         -1.9418e-01,  1.0373e-01,  2.8165e-01, -3.1400e-01, -3.9586e-01,\n",
      "         -1.0912e+00,  7.9104e-01,  1.1351e+00, -1.0995e+00, -6.4645e-01,\n",
      "         -3.4727e-01,  1.8285e-01, -8.5248e-01,  2.8858e-01,  3.7776e+00,\n",
      "          2.7261e-01, -8.9526e-01, -5.6006e-02, -1.4847e+00, -9.1729e-01,\n",
      "          5.7859e-01, -6.0945e-01,  5.0155e-01,  9.9994e-01, -5.4392e-01,\n",
      "          3.0073e-01, -2.0645e+00, -1.4110e+00,  4.7903e-01,  4.2676e-01,\n",
      "         -4.4436e-01,  1.5879e+00,  6.5569e-02, -3.0145e-01, -7.8079e-01,\n",
      "          1.7406e-01,  3.2815e-01,  1.2323e+00,  3.0410e-01, -2.0047e+00,\n",
      "         -9.1517e-01,  3.9950e-01,  9.0772e-01, -1.3702e+00,  2.9404e-01,\n",
      "          9.7525e-01, -9.3201e-01,  1.4963e+00, -1.1079e+00, -1.6417e-01,\n",
      "          2.4523e-01,  1.4052e+00, -4.8686e-01, -5.7004e-01,  1.4366e+00,\n",
      "         -4.2872e-01, -1.4402e+00,  1.6753e-01,  1.4916e+00, -6.1995e-01,\n",
      "         -4.4557e-01,  5.1098e-01,  1.6702e+00,  2.6824e-01,  7.3462e-02,\n",
      "          1.7370e+00, -7.8212e-01, -1.2152e+00, -9.7945e-01, -9.8879e-02,\n",
      "         -4.0854e-01,  5.7940e-01, -8.1291e-01,  1.1250e+00, -7.3961e-01,\n",
      "          2.3121e+00,  1.9158e-01,  9.1554e-01, -5.2368e-01,  8.9773e-02,\n",
      "          4.2113e-01, -1.8724e+00, -5.2891e-01, -5.8646e-01,  6.0730e-01,\n",
      "         -1.5739e+00, -6.2828e-01,  1.2088e+00, -1.4791e+00,  8.8519e-01,\n",
      "          2.3656e+00, -4.1085e-01,  8.5912e-01, -7.0201e-02,  6.6805e-01,\n",
      "         -1.4397e+00,  2.2901e-01,  1.7712e-02, -2.1861e+00, -1.6911e+00,\n",
      "          2.4301e-02, -1.6951e+00, -1.1343e-01, -3.0744e-01, -1.2442e+00,\n",
      "         -1.8090e-01, -2.5518e-01, -7.0859e-01,  1.9933e+00,  1.9599e+00,\n",
      "          1.2684e+00,  5.8213e-01, -1.7307e-01, -1.9262e+00, -2.7444e-01,\n",
      "         -7.7135e-01,  3.1622e-01,  6.3427e-01,  4.2875e-02,  4.9050e-01,\n",
      "         -3.9773e-01, -1.1752e+00, -1.4878e+00, -1.4442e+00,  1.1414e-02,\n",
      "         -1.3996e+00, -5.1153e-01, -6.0119e-01, -1.8144e+00, -1.0581e-01,\n",
      "         -1.2776e-02,  1.1402e+00, -2.6898e+00, -2.3114e-01, -7.1362e-01,\n",
      "          1.0158e+00,  1.1369e+00,  1.5711e-03,  9.6737e-01, -1.0043e+00,\n",
      "         -9.6181e-01, -1.8510e+00,  1.3750e+00, -2.3098e-01, -1.1161e+00,\n",
      "          1.5021e+00,  5.0670e-01,  5.2805e-01, -2.8566e-01,  5.4427e-01,\n",
      "         -1.1049e+00, -6.2181e-01,  1.2099e+00, -5.2221e-01,  6.9562e-01,\n",
      "          7.5935e-02,  2.7524e-01, -4.3207e-01,  6.9566e-01, -2.0196e-01,\n",
      "          6.7965e-01, -5.6879e-01,  5.3674e-01,  1.3055e+00,  3.4813e-01,\n",
      "         -2.9721e-01, -3.8314e-01,  1.6010e+00,  9.4671e-01, -1.0025e+00,\n",
      "         -8.3717e-01, -3.2627e-01,  1.4115e+00, -2.5755e-01, -3.4313e-01,\n",
      "         -5.7250e-01,  1.4695e+00, -2.9125e-01,  1.1648e+00,  2.2960e-01,\n",
      "         -2.5188e+00,  5.9868e-02,  7.5318e-01, -4.8884e-01, -2.0087e-02,\n",
      "          1.7650e-01, -2.7009e-01,  4.3145e-01,  1.5861e+00,  5.6498e-01,\n",
      "          2.1893e+00, -8.3981e-01,  3.7973e-01,  8.0115e-01,  9.2095e-01,\n",
      "          1.7435e-01, -1.4486e+00,  2.1397e+00,  5.7570e-01, -5.9343e-01,\n",
      "         -1.0447e+00,  7.7556e-01,  4.3446e-02, -4.3177e-01,  1.5520e+00,\n",
      "         -4.3863e-01, -1.2413e+00, -2.7139e-01,  8.5311e-01, -4.4898e-01,\n",
      "          1.8926e-01, -5.2784e-01, -1.0395e+00, -2.6990e-01,  1.1453e+00,\n",
      "         -7.6783e-01, -1.7277e+00, -3.9317e-01, -1.2193e+00,  1.7604e+00,\n",
      "          3.2002e-01,  2.4909e-01, -4.3822e-01,  1.4830e+00,  4.1846e-01,\n",
      "         -1.5723e+00,  4.9463e-01, -8.0233e-01,  6.4690e-02, -3.2825e-01,\n",
      "          2.5193e-02, -7.5939e-01, -2.7579e-02, -8.3834e-01, -6.2396e-01,\n",
      "         -2.3153e+00,  5.8035e-01,  1.8588e+00,  1.0380e+00, -8.0121e-01,\n",
      "         -7.7927e-02,  1.1092e-01,  1.0058e+00,  8.6987e-01,  1.8707e-01,\n",
      "          1.2163e+00, -3.8179e-02, -5.0595e-01,  9.5516e-02, -9.3180e-01,\n",
      "         -5.0753e-01, -4.0553e-01,  5.8644e-01,  2.5793e-01, -1.3894e-01,\n",
      "          8.4259e-01, -4.7147e-01, -2.0897e+00,  1.6695e-01,  1.1902e-01,\n",
      "         -2.6269e-01,  9.7432e-01,  1.4884e+00,  5.6191e-01, -6.1954e-01,\n",
      "          1.4512e+00,  4.7270e-01, -1.4879e+00, -5.3466e-01, -6.0145e-01,\n",
      "          4.5241e-01, -7.1606e-01, -8.4726e-01,  4.1509e-01, -1.1427e+00,\n",
      "          1.3791e+00, -9.7866e-01, -1.8652e-01, -9.7267e-01,  2.1252e+00,\n",
      "          1.4084e+00,  9.5992e-01, -2.1865e+00, -4.9064e-01,  1.7218e-01,\n",
      "         -9.6834e-01, -1.6444e-01,  1.2311e-01, -1.3834e-01,  4.8179e-01,\n",
      "         -4.5352e-01, -2.2936e-03,  5.3118e-02, -2.6613e-01, -1.5202e+00,\n",
      "          1.2260e+00,  4.0173e-01,  4.3766e-01,  6.8539e-01,  1.1754e-01,\n",
      "         -8.3997e-01, -1.2144e-01, -2.1185e+00, -5.8587e-01, -2.3487e-01,\n",
      "         -2.6811e+00,  3.2581e-02,  7.5397e-01, -1.7107e-01, -9.4370e-01,\n",
      "         -4.5210e-01, -1.4887e+00, -2.4377e-01, -2.4537e-01, -6.4433e-01,\n",
      "         -2.3959e-01,  1.3768e-02,  9.6833e-02, -9.8048e-01, -3.1278e-01,\n",
      "         -5.9021e-01,  2.1391e+00,  1.0324e+00,  1.1559e+00, -2.4194e-01,\n",
      "         -1.0928e+00, -1.6116e+00, -1.1079e+00, -5.7292e-02,  7.0548e-01,\n",
      "          1.7630e+00,  8.6779e-01,  5.2105e-01, -1.1235e+00,  7.3838e-01,\n",
      "          8.6076e-01,  1.6203e+00, -1.3379e+00,  1.4499e-01, -6.7948e-01,\n",
      "          4.3198e-01,  6.6059e-01, -2.5921e-01,  3.6452e-01,  1.1504e+00,\n",
      "         -1.9757e-01,  2.1984e+00, -1.5637e+00, -8.7775e-01, -1.6534e+00,\n",
      "          5.8683e-01,  1.6250e+00, -1.7836e+00, -6.1398e-01,  7.3006e-01,\n",
      "          3.9613e-01,  9.3427e-01, -5.2736e-01,  2.0913e+00, -8.1086e-01,\n",
      "          1.9188e-02, -3.8013e-01,  1.9241e-01,  1.8948e-01,  8.3509e-01,\n",
      "          8.8793e-02,  2.6976e-01,  1.5316e-01, -1.1334e-01, -1.0114e+00,\n",
      "         -9.1777e-01, -1.5491e-01, -6.2212e-01, -4.4888e-01,  2.0456e-03,\n",
      "         -3.2743e+00,  2.1185e+00,  1.0812e+00, -3.1382e-02, -2.0105e-01,\n",
      "         -7.6376e-01, -1.2754e+00,  9.0031e-01, -1.6991e-01,  1.2515e+00,\n",
      "         -1.6978e+00,  2.1391e-01,  1.3227e+00, -2.6523e-01,  3.6079e-01,\n",
      "         -1.0594e-01,  1.8255e-01, -1.5598e+00,  2.2885e+00,  5.2593e-01,\n",
      "          3.9640e-01, -8.7833e-01, -9.0378e-01, -2.7934e-01,  8.6551e-01,\n",
      "          3.6203e-01,  2.1687e+00, -1.3908e+00, -9.9721e-01, -1.0668e+00,\n",
      "         -3.4005e-01,  5.9963e-02,  2.0558e+00,  7.3627e-02,  4.2883e-01,\n",
      "          1.0532e+00, -2.7568e+00, -8.7629e-01,  2.4573e+00,  8.2994e-01,\n",
      "         -2.9395e-01,  5.8234e-01,  6.8357e-01,  2.1776e-01,  1.9649e-01,\n",
      "          1.1893e-01, -8.5893e-01,  3.7496e-01, -4.0609e-01,  7.8615e-01,\n",
      "          1.5554e+00,  2.7008e-01,  4.1116e-01,  6.3113e-01,  1.2089e-01,\n",
      "          1.2144e+00, -2.2170e-01, -6.0488e-01,  1.7570e-01,  6.2758e-01,\n",
      "         -5.7764e-01, -6.2157e-01, -1.1337e-01,  4.0207e-01, -2.8092e+00,\n",
      "         -6.8450e-01,  1.7843e-01,  8.0479e-01, -7.0804e-02,  5.6629e-01,\n",
      "         -4.6437e-01, -8.5512e-02, -1.1036e+00,  9.7375e-01,  1.0092e+00,\n",
      "         -4.8578e-01,  2.0583e+00, -6.5727e-01, -5.1821e-01, -6.6703e-01,\n",
      "          1.9436e+00, -5.2776e-01, -4.5837e-02, -3.9521e-03, -1.1607e+00,\n",
      "          5.8290e-01,  6.6145e-01,  9.0868e-01,  6.3772e-01, -1.5165e+00,\n",
      "          2.7448e-02, -8.5435e-01,  6.2050e-01, -5.4146e-01, -1.5887e+00,\n",
      "         -1.6501e+00, -1.2422e+00,  2.1697e-05,  6.1605e-03,  2.0676e-01,\n",
      "          1.8554e-01, -8.0417e-01,  9.2192e-02, -2.1301e+00, -6.2455e-01,\n",
      "          3.2004e-02,  9.4438e-01, -2.1617e+00, -6.7220e-01,  1.0784e-01,\n",
      "          2.3042e+00,  4.2840e-01, -1.2349e+00,  8.8699e-01,  1.2875e+00,\n",
      "          1.7881e-01,  4.2318e-02,  1.6232e+00]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 5\n",
      "tensor([[0.3973]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347, 1640,  347,   43,\n",
      "          347,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.5753])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347,  347, 1640, 3226,   43,  347,  347, 1640,  347,   43,\n",
      "          347,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.6846e+00, -5.9831e-01, -1.6058e+00,  9.4880e-02, -2.5433e-01,\n",
      "         -1.8356e-01, -3.8028e-01,  7.9822e-01, -6.0157e-02, -8.6755e-01,\n",
      "         -6.2073e-01, -4.7286e-01,  7.2472e-01, -9.1055e-01,  9.8553e-01,\n",
      "         -1.8505e-02, -1.7234e+00,  1.3885e+00,  7.8982e-01, -1.3336e+00,\n",
      "          1.9199e+00, -4.4792e-01, -7.9115e-01,  3.1838e-01, -3.8261e-01,\n",
      "          5.4047e-02,  1.4125e+00, -6.8740e-02,  3.4093e-01, -7.1890e-01,\n",
      "         -2.0094e-02,  6.6196e-02,  4.7745e-01,  3.7391e-01, -6.1726e-01,\n",
      "          6.9472e-01,  1.6661e+00, -1.7982e+00, -4.5226e-01, -9.7816e-01,\n",
      "          7.8520e-01, -1.1635e+00, -4.1850e-01, -6.2972e-01,  6.3728e-01,\n",
      "          1.6966e-01, -1.6060e+00,  8.1839e-01,  8.9358e-01,  1.7027e+00,\n",
      "         -1.3726e+00, -1.7601e+00,  8.2374e-01,  2.2032e+00,  7.8894e-01,\n",
      "          3.2281e-01,  8.7150e-01, -1.2487e+00, -1.2701e+00, -1.2137e+00,\n",
      "         -4.5898e-01,  9.1534e-02, -9.6160e-01, -1.0048e+00, -2.0623e-01,\n",
      "         -3.4962e-01,  3.8220e-01,  8.0766e-01,  2.0845e+00, -1.4125e+00,\n",
      "         -1.1770e+00,  1.4924e+00,  5.9550e-01, -9.6590e-02,  1.6537e-02,\n",
      "         -4.7057e-01, -1.5613e-02,  1.8992e-01,  1.2112e+00,  6.5706e-01,\n",
      "         -4.7101e-01,  2.5722e-01,  1.4588e+00,  1.9978e-01,  4.2648e-02,\n",
      "          1.9094e+00, -7.2418e-01,  1.8281e-01,  9.4556e-01,  1.7105e-02,\n",
      "          3.0608e-02,  1.4238e-01,  4.0210e-01,  5.8291e-01, -1.6102e+00,\n",
      "         -9.6600e-01, -5.5464e-01, -1.4183e-02, -3.5697e-01,  3.1226e-01,\n",
      "         -2.2866e+00, -1.4963e+00,  1.1213e+00,  2.1229e-01, -5.9836e-01,\n",
      "          3.7050e-01, -5.9598e-01,  1.5675e+00,  1.2643e+00, -8.1706e-01,\n",
      "         -2.6840e-01, -1.4345e+00, -1.1384e-01,  5.6470e-01,  2.2712e+00,\n",
      "         -1.4436e+00,  3.8780e-01,  4.7801e-01, -4.9998e-01,  2.9355e-01,\n",
      "         -9.4814e-01,  1.3236e-02,  4.7727e-02,  2.8731e-01, -2.8513e-01,\n",
      "         -7.6591e-02, -7.1037e-01, -3.0810e-01,  3.4362e-01, -6.6069e-01,\n",
      "          5.1768e-02, -2.7404e-01, -4.9088e-01,  5.8597e-01, -4.4087e-01,\n",
      "          1.4121e+00, -8.3897e-01, -3.3016e-01, -1.3382e+00,  7.6359e-02,\n",
      "         -1.6958e-01,  1.4539e-01,  9.5721e-02,  3.9253e-02,  5.1680e-01,\n",
      "         -7.6959e-01,  1.1789e+00, -1.3610e+00, -9.1150e-01,  3.1885e-01,\n",
      "          4.9839e-01,  1.6169e-01, -1.2609e+00,  4.9103e-01, -4.9738e-01,\n",
      "          2.0475e+00, -1.6208e+00, -1.2741e+00,  7.3722e-01,  2.8420e+00,\n",
      "         -8.6544e-01,  1.7717e+00, -1.8944e-01,  5.0892e-02,  6.2131e-01,\n",
      "         -2.1454e+00,  2.6007e-01, -2.4905e-01, -2.8734e-01,  9.4611e-02,\n",
      "         -6.4607e-01, -1.4904e+00,  1.4266e-01,  2.7368e-01, -7.8414e-01,\n",
      "          9.6975e-02, -2.7860e+00, -4.7281e-01,  2.4920e-01,  1.7787e+00,\n",
      "          3.0958e-01,  1.6138e-01,  3.5818e-01,  1.2057e+00,  9.7165e-02,\n",
      "         -1.7867e+00, -2.8521e-01,  1.0909e+00, -5.4065e-01, -3.2794e-01,\n",
      "         -2.4228e-01, -1.2143e-01,  1.6680e+00,  4.0235e-01,  1.5473e+00,\n",
      "         -2.0213e+00,  1.7371e+00, -1.0151e+00,  9.2541e-01, -7.3330e-01,\n",
      "          4.8584e-02,  2.0515e-01, -3.6399e-01,  2.1890e-01, -4.0045e-01,\n",
      "         -1.9555e+00, -1.7076e+00, -2.5733e-01,  1.2346e+00, -6.3002e-01,\n",
      "          7.9578e-01,  6.6513e-01, -1.3170e-01, -6.6444e-01,  2.1737e+00,\n",
      "          1.8041e+00, -8.2293e-02,  1.4335e+00, -9.4761e-04,  6.0271e-01,\n",
      "          2.0973e-01, -7.7204e-01,  5.5470e-01,  1.4217e-01,  9.0306e-01,\n",
      "          2.1196e-01, -5.9493e-01,  1.0414e+00, -4.8625e-01, -1.9236e+00,\n",
      "          3.6392e-01,  8.4870e-01, -9.7666e-01,  5.4760e-01, -3.2949e-01,\n",
      "          7.7613e-02, -1.6240e+00,  1.6763e-01,  8.9509e-01,  7.6108e-01,\n",
      "          2.7370e+00,  5.1682e-01,  4.7537e-01,  1.8404e-01, -1.7021e+00,\n",
      "         -1.6080e-01, -2.9025e-01, -5.9157e-01,  1.3500e+00, -7.5935e-01,\n",
      "         -1.2901e+00,  1.8361e+00,  4.7840e-01, -1.8310e-01,  2.2137e+00,\n",
      "          1.7213e-02, -8.9359e-01, -4.1813e-02, -8.0281e-01,  2.3106e-02,\n",
      "         -1.9236e-01,  1.6011e+00, -1.0414e+00, -6.3231e-01,  2.4152e-01,\n",
      "         -2.6560e-01, -2.9286e-01,  6.8080e-03,  4.9978e-01, -1.6491e-01,\n",
      "         -3.4532e-01, -6.0165e-01, -6.6310e-01,  1.9665e-01,  4.5345e-01,\n",
      "         -1.4972e+00, -1.6224e+00,  9.7518e-01, -3.2698e-01,  5.4667e-01,\n",
      "         -1.2685e+00,  1.4648e+00,  5.1156e-02,  8.0074e-01,  3.7768e-01,\n",
      "         -2.0895e+00, -7.4891e-02, -1.2395e+00, -1.2787e+00,  7.9776e-01,\n",
      "         -1.2396e-01, -1.7998e-01,  9.9115e-01, -1.6978e-01, -1.2286e-01,\n",
      "          7.0635e-01, -1.1285e+00, -1.0915e+00,  1.1227e+00, -3.8630e-01,\n",
      "          3.7458e-01, -1.8008e+00, -1.8794e-01,  5.4251e-01,  1.2635e+00,\n",
      "          7.6962e-01,  7.7244e-01,  3.8994e-01,  9.2843e-02, -1.1016e+00,\n",
      "         -7.6517e-01,  1.7813e-03, -1.2883e-01,  3.4604e-01, -1.1069e+00,\n",
      "         -1.4673e+00,  6.9822e-01,  1.0289e+00, -2.8988e+00,  1.0879e+00,\n",
      "         -1.3611e+00,  7.9013e-01,  1.3809e+00, -7.8962e-01, -1.1328e+00,\n",
      "          2.2752e+00, -8.7810e-01,  1.5702e+00,  8.8791e-01,  2.4538e+00,\n",
      "          3.0816e-01, -1.5733e+00,  2.6934e-01,  1.2039e+00, -3.4956e-01,\n",
      "          1.5535e-01,  6.8462e-01,  1.5106e+00,  5.4783e-01, -8.1306e-01,\n",
      "          1.0401e+00, -3.3867e-01, -1.5244e+00, -1.5639e+00,  5.2742e-01,\n",
      "          2.5557e-01,  1.4783e+00, -6.9457e-02, -3.4438e-01, -2.2846e+00,\n",
      "         -7.7314e-01, -4.5309e-01,  7.3344e-01,  9.7709e-02, -2.9969e-01,\n",
      "          1.3500e+00, -1.7640e+00,  1.1154e-01,  9.8796e-01,  2.4987e-01,\n",
      "         -1.5265e+00,  1.1823e+00,  1.6225e+00, -2.0541e+00,  1.1418e+00,\n",
      "          1.8000e+00, -1.1011e+00,  6.8767e-01, -7.9525e-01, -5.2338e-01,\n",
      "         -4.4664e-01,  1.6416e+00, -1.9598e+00, -8.3389e-02,  1.6289e-01,\n",
      "         -2.8577e-01,  1.4042e-01, -2.2855e-01, -5.9742e-01, -3.2921e-01,\n",
      "          6.7860e-01, -1.9570e+00, -1.0099e+00,  2.2287e+00,  5.6845e-01,\n",
      "         -1.7278e-01, -1.8555e+00,  1.0339e+00, -6.9182e-01, -2.0788e-01,\n",
      "          2.9224e-01, -4.4583e-04,  1.1868e+00,  1.4785e+00,  1.2140e+00,\n",
      "          5.8580e-01,  1.1003e+00, -3.5176e-01,  9.7032e-01, -2.4792e+00,\n",
      "          1.9184e-01, -4.0115e-01,  2.6968e-01, -8.3157e-01, -8.3533e-02,\n",
      "         -1.0671e+00,  9.3056e-01, -4.9618e-01,  1.2285e+00, -1.2612e-01,\n",
      "          1.9016e+00,  4.9937e-02,  1.1331e+00,  1.2156e+00, -3.1642e+00,\n",
      "         -3.9667e-01, -1.5731e+00,  2.8870e-01,  1.4131e-01, -5.3729e-02,\n",
      "         -7.1245e-01, -1.7288e-01, -3.2832e-01, -9.3679e-01,  1.6667e+00,\n",
      "         -9.9345e-01, -1.1709e+00, -2.6574e-02, -9.9185e-01,  1.1316e+00,\n",
      "          3.8627e-01,  1.7123e+00, -4.6593e-01, -2.8788e-01,  5.5034e-01,\n",
      "          4.7536e-01, -1.1230e-01, -3.1067e-02,  5.6127e-01, -1.2759e+00,\n",
      "          1.1906e+00, -6.7553e-02,  6.9834e-02,  2.6734e-01, -8.6069e-01,\n",
      "          1.6247e-01,  9.1455e-01,  2.1782e-01, -1.2074e+00,  2.3622e-01,\n",
      "          1.4002e+00,  8.9207e-01, -1.1224e+00,  2.4527e+00, -6.9893e-01,\n",
      "         -1.2352e+00,  1.3659e+00, -4.7601e-01, -4.8426e-01, -3.0549e-02,\n",
      "         -4.4164e-01,  6.9153e-01,  1.4132e+00,  2.1530e+00, -3.5293e-01,\n",
      "          1.4117e+00, -1.4492e+00,  7.6761e-01,  7.4358e-01,  4.2417e-02,\n",
      "          1.7358e+00, -1.1145e+00,  6.2253e-01,  5.5194e-01,  7.2678e-01,\n",
      "          3.2971e-01, -1.2762e+00,  4.6387e-01, -1.0272e-01, -5.2160e-01,\n",
      "         -3.4900e-01, -8.9705e-01, -4.2179e-01, -1.8671e-01, -2.1948e+00,\n",
      "          2.5768e-01,  1.9948e-01, -2.8228e+00, -2.4518e-01,  7.2480e-01,\n",
      "         -5.3304e-01, -1.2956e-02, -3.7113e-01, -1.7421e+00, -3.9963e-01,\n",
      "         -2.8044e-02, -1.8466e+00, -1.7477e+00,  7.9872e-01,  6.3251e-01,\n",
      "         -8.9075e-01,  1.2289e+00,  6.0590e-01, -2.8003e-01, -1.5219e-01,\n",
      "         -1.8014e+00,  6.7937e-02, -4.4668e-01, -2.1847e+00, -9.4734e-02,\n",
      "         -8.6590e-02,  1.1014e-01,  2.5555e+00,  1.0710e+00, -1.4848e+00,\n",
      "          3.9501e-02, -3.2141e-01,  5.2270e-01, -1.1280e-01,  1.9615e-01,\n",
      "          1.1775e+00,  6.4873e-01,  6.5372e-01,  5.5238e-01,  3.4449e-01,\n",
      "         -1.1473e+00,  1.1508e+00,  9.5686e-01, -9.2397e-01, -3.3422e-01,\n",
      "          1.0618e+00,  3.9898e-01, -1.5732e+00,  1.0973e+00, -5.4688e-01,\n",
      "          1.1791e+00,  1.4838e-01,  1.7910e+00,  4.5199e-01,  6.8763e-01,\n",
      "          1.9484e+00, -1.2913e+00,  2.1381e-02, -7.3327e-01, -2.0632e+00,\n",
      "         -5.1458e-01,  9.7969e-02, -1.1131e+00,  6.4027e-01, -4.0722e-02,\n",
      "          2.5377e-01, -7.0714e-01,  5.5711e-01, -1.6610e-01,  7.6295e-01,\n",
      "          1.0858e-02,  1.2561e+00, -9.0698e-01,  6.4082e-01,  5.9609e-01,\n",
      "          1.2840e+00,  2.3297e-01,  1.9373e+00, -6.1423e-01, -8.1183e-01,\n",
      "         -9.2151e-01, -6.1424e-01, -4.0018e-01,  3.7627e-01,  2.0461e-01,\n",
      "          7.1301e-01,  3.0440e-01,  1.6514e+00,  7.5100e-01,  1.6318e+00,\n",
      "         -2.4951e-01,  5.5622e-01, -2.6783e+00, -8.3463e-01, -6.8375e-01,\n",
      "         -1.4480e+00, -3.9412e-01,  9.4527e-01, -1.7597e+00, -3.8563e-01,\n",
      "          2.8230e+00,  1.6444e-01,  7.1928e-01,  8.2484e-01,  5.7898e-01,\n",
      "          1.6030e+00, -8.5827e-01,  3.1828e-01, -2.1045e+00, -1.3496e+00,\n",
      "          3.3378e-01,  7.1019e-01,  7.7563e-01,  3.0167e+00,  1.8769e-01,\n",
      "         -1.5078e+00,  5.4700e-01, -7.7311e-01, -6.7873e-02, -1.4897e-01,\n",
      "          1.4422e-02, -4.7702e-01,  1.1407e+00,  2.3491e-01,  5.7740e-01,\n",
      "          1.2935e+00, -2.2326e-01, -1.5453e+00, -5.8458e-01, -4.6332e-01,\n",
      "         -7.0726e-02, -1.1873e+00,  1.1583e+00,  1.5726e+00, -1.2499e-01,\n",
      "         -7.4210e-02,  9.4920e-01, -6.0752e-01,  1.0231e-01, -1.7364e+00,\n",
      "         -7.3674e-01,  2.4067e+00, -5.3076e-01, -8.1039e-01,  4.4504e-01,\n",
      "          3.8759e-01,  4.1379e-01, -7.2321e-01,  2.0087e+00, -1.7238e+00,\n",
      "         -1.8125e-02,  3.3734e-01, -9.2468e-01,  2.5178e-01, -7.9532e-01,\n",
      "         -8.6469e-01,  1.0144e+00,  1.9157e+00, -1.3879e+00, -6.4784e-01,\n",
      "         -7.9101e-01,  6.4458e-02,  2.8680e-01,  8.6060e-01,  5.4460e-01,\n",
      "         -3.0192e-03,  4.6386e-01,  1.2251e+00,  9.7477e-01, -1.8656e-01,\n",
      "         -5.6046e-02,  5.5399e-01,  4.0272e-01, -1.4368e+00,  7.0450e-02,\n",
      "         -6.4028e-01,  2.5681e-01,  1.6296e+00,  1.6802e+00, -3.5355e-01,\n",
      "          6.4335e-01,  9.0338e-01,  1.4022e-01,  4.7279e-01,  9.3528e-02,\n",
      "         -1.4732e+00, -2.0355e+00,  3.8534e-02,  1.5753e-01,  1.5423e+00,\n",
      "          9.7875e-01,  1.5750e-01, -6.1658e-01, -6.1335e-01,  5.2667e-01,\n",
      "         -1.0337e+00, -6.0887e-01,  2.0212e-01,  4.3258e-01,  8.0504e-01,\n",
      "         -1.4355e+00, -1.8924e+00, -1.9591e-01,  1.6511e+00,  1.4925e+00,\n",
      "         -3.7622e-01, -1.0429e-01,  6.9078e-01,  7.9407e-01, -4.3616e-01,\n",
      "          3.9555e-01,  4.5015e-01, -1.3138e-01, -8.1367e-01,  1.0015e+00,\n",
      "          1.1621e+00, -6.7628e-01, -2.6286e+00,  5.0362e-01, -2.9728e-01,\n",
      "          7.8430e-01, -8.9192e-01, -1.9281e+00,  1.4309e-02, -6.5517e-02,\n",
      "         -5.3553e-01, -6.6541e-02,  1.1433e+00,  6.6549e-01, -5.6380e-01,\n",
      "         -1.0737e+00, -8.3278e-01,  1.7408e+00, -8.1912e-02,  2.9478e-02,\n",
      "          6.1401e-01,  6.4699e-01, -4.9296e-01, -5.3472e-01,  4.4852e-01,\n",
      "         -7.2075e-01,  6.8168e-01, -1.5592e+00, -7.6214e-01, -1.6167e+00,\n",
      "          3.0796e-01, -7.9763e-02,  8.3051e-01, -1.1508e+00, -6.3406e-01,\n",
      "          9.3843e-01,  6.8406e-02,  5.4943e-01,  5.8871e-01, -9.0419e-01,\n",
      "         -9.5431e-01, -5.5832e-01,  3.5235e-01, -6.0121e-02,  1.4613e+00,\n",
      "         -1.7022e+00,  2.1121e-01, -1.0085e-01,  1.7779e+00, -1.7349e-02,\n",
      "         -1.7235e+00, -1.1339e+00, -2.1336e-01, -7.7415e-01, -2.0604e+00,\n",
      "          4.6072e-01,  6.4944e-01,  9.6466e-02, -7.3652e-02, -8.1719e-01,\n",
      "          2.3673e+00, -5.4211e-01, -1.1642e+00,  1.7825e+00, -3.3777e-01,\n",
      "          1.7206e-01, -6.4171e-01,  6.8390e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 6\n",
      "tensor([[0.2622]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347, 5214,  347,  347,  347, 3226,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([-0.3582])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347, 5214,  347,  347,  347, 3226,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.5083e+00, -1.3734e+00,  1.2905e-01, -2.4127e-01, -3.4187e-01,\n",
      "          1.3516e+00,  1.0552e-01,  1.3359e+00, -9.6773e-02, -9.2903e-01,\n",
      "         -2.2199e-01, -1.1147e-01,  1.5123e+00, -3.5771e-02, -1.0576e+00,\n",
      "          4.5016e-01,  8.4618e-01,  1.6395e+00, -2.0159e-01, -9.9066e-01,\n",
      "          2.1484e-01, -6.2471e-01, -4.6986e-01,  4.8883e-01, -4.2995e-01,\n",
      "         -5.3502e-01,  9.1802e-02,  9.3431e-01,  8.4643e-01, -3.3932e-02,\n",
      "         -2.4041e+00, -2.2326e-01,  8.0597e-01,  5.3071e-01,  1.4691e+00,\n",
      "          4.7794e-01,  1.0788e+00, -1.3196e+00, -5.3255e-01,  8.5248e-01,\n",
      "          6.3994e-02, -6.2745e-01, -2.1200e-02,  1.3103e-01,  1.8793e-01,\n",
      "          1.8576e+00, -1.0758e+00,  1.1700e+00,  2.6290e-01,  1.6231e+00,\n",
      "         -1.0373e+00, -7.4769e-01, -1.4598e+00, -4.5234e-01,  3.3892e-01,\n",
      "         -2.7027e-01,  5.3780e-01, -1.8260e+00,  5.2487e-01, -5.5377e-01,\n",
      "         -9.6691e-01,  3.8797e-01,  3.4537e-01, -1.3366e+00,  3.9013e-01,\n",
      "          1.4839e-01,  9.4212e-01,  9.2932e-02, -1.4879e-01,  2.1276e-01,\n",
      "         -7.7393e-01, -8.6517e-01,  4.5197e-01,  1.0771e-01, -6.0246e-01,\n",
      "         -1.0341e+00, -4.7887e-01,  1.4457e-01,  4.6981e-01,  1.7473e+00,\n",
      "         -9.2046e-01,  5.2408e-01, -1.5206e-01,  1.5388e+00, -1.0443e-01,\n",
      "          1.7830e-01, -4.0312e-01, -8.7848e-01,  4.2321e-01, -5.5466e-01,\n",
      "         -7.5941e-01,  1.2437e+00,  3.7300e-01, -2.5002e-01, -1.5864e+00,\n",
      "         -1.8744e+00, -1.9144e+00, -6.2203e-01, -2.1300e+00, -9.8912e-01,\n",
      "         -7.7523e-01, -1.4576e+00,  1.3876e+00, -5.9151e-01, -6.4455e-01,\n",
      "          6.6657e-01, -9.8592e-01, -3.2741e-01,  2.1816e-01, -1.0539e+00,\n",
      "          6.3824e-01, -2.1624e-01,  8.5007e-01,  1.3805e+00, -9.6062e-03,\n",
      "         -1.2618e+00, -5.2098e-01,  1.0896e+00, -4.0673e-01, -4.1710e-01,\n",
      "         -1.5565e+00, -2.8190e-01, -1.6196e-01,  1.2862e+00,  5.0893e-02,\n",
      "          2.0022e+00, -1.0203e+00,  1.1323e+00,  2.2812e+00,  7.4286e-01,\n",
      "         -5.8926e-01, -4.5347e-01, -9.4629e-01, -7.7152e-01, -2.1627e-01,\n",
      "          1.3257e+00, -1.6656e+00, -5.5982e-01, -1.8448e+00,  3.9672e-02,\n",
      "         -6.8328e-02,  2.0905e-01, -3.3045e-01, -3.5321e-01,  1.0113e+00,\n",
      "         -1.0578e+00,  2.1157e+00,  8.8971e-01, -8.5609e-01,  9.1807e-01,\n",
      "          1.6137e+00,  5.3919e-02, -2.2223e+00, -9.3732e-01, -8.7167e-01,\n",
      "          1.1912e+00, -7.0715e-01, -8.9354e-01,  3.3136e-01,  7.0016e-01,\n",
      "         -2.9269e-01,  3.2209e+00,  2.0835e-01,  8.8982e-01,  8.3784e-01,\n",
      "         -5.9265e-01, -8.0604e-01, -2.1234e+00, -7.3893e-01,  1.6928e+00,\n",
      "         -4.5338e-01, -6.9965e-01, -6.8342e-01, -4.9996e-01, -5.3382e-01,\n",
      "         -1.5421e-01, -1.7569e+00, -6.7445e-01,  5.3821e-01,  3.7642e-01,\n",
      "          6.3810e-01, -2.0890e-01,  6.5136e-01,  1.8264e+00, -1.2520e-01,\n",
      "         -6.7176e-01, -4.9594e-01,  4.2418e-01,  6.1796e-02,  1.2155e+00,\n",
      "          1.8192e+00, -1.2562e+00,  1.5349e+00,  7.8690e-02,  3.9218e-01,\n",
      "          2.2888e-01, -5.4932e-01, -3.5617e-01,  1.7392e+00, -4.2079e-01,\n",
      "         -2.8802e-01,  4.9162e-01,  7.9268e-01,  5.6499e-01,  5.4654e-01,\n",
      "          2.7636e-01,  3.6328e-01, -3.2792e-01,  5.9913e-03, -4.5052e-01,\n",
      "          9.8443e-01,  1.0748e-02, -1.3010e+00, -1.4491e+00,  6.9445e-01,\n",
      "          1.4201e+00, -9.3996e-01,  1.3715e+00, -1.0459e-01,  3.9180e-01,\n",
      "          3.7349e-01, -1.2588e+00,  1.2997e+00,  9.4380e-03,  1.5656e+00,\n",
      "         -1.0184e+00, -3.1940e-01,  7.2121e-02,  1.8481e-02, -3.7645e-02,\n",
      "          1.6552e-01,  7.8212e-01, -3.4729e-01,  6.3207e-01,  2.0518e-01,\n",
      "          1.6235e+00, -1.1368e+00,  5.5480e-01,  6.9298e-01, -1.8855e-01,\n",
      "          1.1405e+00,  1.4135e+00,  1.3105e+00, -1.6913e-01,  2.5643e-01,\n",
      "         -1.5385e-01,  8.8501e-01, -4.1881e-01,  1.8297e+00, -1.0500e-01,\n",
      "         -2.0045e+00, -3.1829e-01, -3.9909e-01, -4.1046e-01, -4.1078e-01,\n",
      "         -7.9933e-01,  8.9619e-01, -7.2665e-01, -2.9820e-01, -8.5659e-01,\n",
      "          5.3487e-01,  1.4242e+00, -3.4003e-01, -1.1763e+00, -1.7470e-01,\n",
      "         -1.3210e+00,  2.6764e-01,  7.3724e-01,  1.1256e+00,  9.0468e-01,\n",
      "          7.7805e-01, -1.4135e+00,  9.4479e-01, -5.5643e-01, -3.0475e-01,\n",
      "         -5.5835e-01,  1.6968e-02, -3.6523e-01, -2.1117e-01,  5.4136e-01,\n",
      "         -1.0789e-01,  8.2919e-01,  5.1563e-01, -5.7307e-01,  1.0587e+00,\n",
      "         -5.5143e-02, -4.4660e-01, -2.9541e-01,  4.3860e-02,  2.7892e+00,\n",
      "         -7.9216e-01, -6.3702e-01, -3.6848e-01, -1.4437e+00, -9.4324e-01,\n",
      "          9.7422e-01, -4.7510e-01, -9.7296e-02,  1.2191e+00,  2.3965e-01,\n",
      "          7.2030e-01, -1.0385e+00, -2.1556e-01, -5.2791e-01,  3.4846e-01,\n",
      "         -3.3334e-01,  7.5474e-01,  5.1464e-01, -9.3802e-01, -8.2173e-01,\n",
      "          9.5732e-01,  8.9386e-01, -1.1502e+00,  6.1770e-01, -1.7207e+00,\n",
      "         -2.0287e+00,  8.7329e-01,  1.4812e+00, -1.7960e+00, -5.0964e-01,\n",
      "         -7.4051e-01, -2.0079e-01,  1.3147e+00, -4.8685e-01, -6.3233e-01,\n",
      "          1.8235e+00,  2.8629e-01,  2.0872e-01, -5.1854e-02,  2.4956e+00,\n",
      "         -1.8624e-01, -1.2327e+00, -5.3608e-01, -1.8859e-01,  7.5827e-01,\n",
      "         -5.6525e-01,  4.4100e-01,  1.5345e+00,  1.6781e+00, -3.6687e-01,\n",
      "          9.8486e-01, -7.4362e-01, -1.2842e+00, -1.5763e+00, -1.4880e-01,\n",
      "         -8.8217e-01,  1.7154e+00, -7.1518e-01,  6.6027e-02,  4.3212e-01,\n",
      "          3.8283e-01, -1.2588e+00,  6.6748e-01,  4.6012e-01, -9.2674e-01,\n",
      "          9.9939e-01,  1.7659e-01,  6.3149e-01,  1.3936e-01,  7.0579e-02,\n",
      "         -2.4486e+00,  7.9987e-02,  4.2750e-01, -2.3562e+00,  1.4118e+00,\n",
      "          9.3761e-01, -2.2288e+00,  1.5432e+00, -8.4822e-01,  5.6681e-01,\n",
      "         -4.3113e-01,  1.2003e+00, -4.4429e-01, -1.5803e+00, -2.4962e-01,\n",
      "          2.9893e-01,  8.5100e-01, -9.0828e-01, -4.5256e-01, -1.5843e+00,\n",
      "         -8.7247e-01, -8.7921e-01, -1.9054e+00,  1.2516e+00,  1.7526e+00,\n",
      "          1.4788e-02, -2.1493e-01,  6.8147e-01, -2.4981e+00, -3.1157e-01,\n",
      "          3.1638e-01,  1.5182e+00,  2.5342e-04,  3.6316e-01, -1.6187e-01,\n",
      "         -7.1018e-02, -4.9550e-01, -1.7706e+00, -2.3723e-01,  8.4290e-01,\n",
      "          2.6869e-01, -5.2906e-01,  1.9445e+00, -1.2437e+00,  6.4057e-01,\n",
      "          3.4598e-01,  8.5367e-01, -2.6937e+00,  1.0310e-01, -4.8833e-01,\n",
      "          1.0416e+00, -4.9261e-03,  5.4131e-01,  1.5808e+00, -2.4230e+00,\n",
      "         -4.8544e-01, -7.6204e-01,  1.3754e+00,  4.6475e-01, -2.8436e-01,\n",
      "         -4.0802e-01, -6.6184e-02, -3.4101e-01, -6.3866e-01,  1.4657e+00,\n",
      "         -9.1267e-01, -1.0506e+00,  8.6712e-01,  3.9673e-01,  5.7557e-01,\n",
      "          1.2828e+00, -1.2255e-01,  9.4293e-02, -1.8851e-01,  9.7273e-01,\n",
      "          1.1140e+00, -4.7857e-01,  2.6486e-01,  2.6394e-01, -9.1340e-01,\n",
      "          4.2751e-01, -5.9595e-01,  2.0419e-01, -1.1417e-01,  2.7639e-01,\n",
      "         -6.3933e-01,  1.1390e+00,  1.5446e+00, -1.1559e+00,  6.5027e-01,\n",
      "          1.0789e+00,  1.0858e+00, -1.6097e-01,  7.0598e-01,  1.6036e-01,\n",
      "         -2.7799e+00,  6.2422e-01,  9.1541e-01,  6.7592e-01, -2.2893e-01,\n",
      "          2.0233e-01, -3.5075e-01, -4.0441e-01,  1.0822e+00,  2.7641e-01,\n",
      "          1.3710e+00, -5.5745e-01, -4.4200e-01,  4.8569e-01,  5.2797e-01,\n",
      "          1.1766e+00, -4.2671e-01,  1.2746e+00, -3.7446e-01, -4.9457e-01,\n",
      "         -3.4733e-01,  7.8842e-01,  1.7874e-01,  9.9257e-01, -2.3662e-01,\n",
      "         -3.0841e-01, -1.1116e+00, -5.2742e-01,  9.5556e-01, -2.4235e-01,\n",
      "          1.3406e-01, -1.0538e-01, -1.4822e+00,  4.4912e-01,  7.7155e-01,\n",
      "         -1.1415e+00, -4.6421e-01,  2.0226e-01, -1.0401e+00,  1.0859e+00,\n",
      "          7.3610e-01,  1.0976e+00, -9.3241e-01,  1.3088e+00,  1.7382e+00,\n",
      "         -6.8460e-01,  5.9515e-01, -4.0611e-01,  4.9807e-01, -6.7924e-01,\n",
      "         -6.4597e-01, -3.1829e-01,  6.5675e-02, -1.0469e+00, -1.9137e-01,\n",
      "         -3.8672e-01, -2.2335e-01,  2.3382e+00,  1.1834e+00, -1.4483e+00,\n",
      "          3.8050e-01, -9.5795e-01,  1.5824e+00,  5.4760e-01,  1.4529e-01,\n",
      "          2.0281e+00, -2.2602e-01, -1.4915e-01,  4.4899e-01, -7.9213e-01,\n",
      "         -1.5769e-01,  3.0944e-01,  1.1852e+00,  2.4147e-01, -5.3860e-02,\n",
      "          8.1010e-01, -2.0034e-01, -2.4091e+00,  1.0318e+00, -8.8872e-01,\n",
      "          1.1119e+00,  6.6156e-01,  1.5281e+00,  5.0539e-01,  4.5327e-02,\n",
      "          2.0550e+00,  1.0811e+00, -2.0553e+00, -9.4741e-01, -4.6218e-01,\n",
      "          7.8440e-01, -3.4803e-01, -1.1525e+00,  7.0877e-01, -9.3734e-01,\n",
      "          1.0329e+00, -1.1268e+00,  7.8192e-01, -1.8285e+00,  1.3679e+00,\n",
      "          1.4958e+00,  1.2971e+00, -2.6657e+00, -1.3765e-01,  2.3272e-01,\n",
      "         -2.4346e-01,  6.4429e-02,  1.1504e-01, -2.1029e-01, -2.8797e-01,\n",
      "          1.1883e+00, -1.0244e+00,  8.6982e-01,  2.1097e-01, -7.9056e-01,\n",
      "          9.7550e-01,  1.6332e+00, -5.1443e-02, -1.8462e-01,  6.5520e-01,\n",
      "         -1.2963e+00,  9.4187e-01, -2.3622e+00, -1.6011e+00, -1.1647e+00,\n",
      "         -1.2032e+00, -1.4266e+00,  7.4377e-01, -2.2058e+00, -8.4490e-01,\n",
      "         -3.6489e-01, -2.9592e-01,  5.4288e-01, -3.7689e-01,  5.7836e-03,\n",
      "          4.7062e-01, -7.4464e-01,  1.0466e+00, -1.0661e+00, -7.7276e-01,\n",
      "         -3.4551e-01,  2.8547e+00,  5.3607e-01,  1.0820e+00,  4.9883e-01,\n",
      "         -1.7704e+00, -2.2461e-01, -1.4783e+00,  2.6821e-02,  3.9960e-01,\n",
      "          9.4489e-01,  1.5054e+00,  1.1098e+00, -9.9766e-01, -5.5345e-02,\n",
      "          2.3255e+00,  2.2032e-01, -1.3759e+00, -5.8985e-01, -2.4105e-01,\n",
      "          8.1588e-01,  5.7519e-01,  8.8218e-01,  1.9697e+00,  7.3055e-03,\n",
      "         -7.7371e-02,  1.9212e+00, -7.1077e-01,  4.2488e-02, -1.8047e+00,\n",
      "         -6.0631e-02,  1.6877e+00, -1.9101e+00, -1.2062e+00,  1.0164e+00,\n",
      "         -1.1167e+00,  5.2472e-01,  3.2837e-01,  6.7496e-01, -1.9612e+00,\n",
      "         -4.2521e-02,  8.6719e-01, -8.4238e-01,  7.1084e-01, -7.2290e-01,\n",
      "         -6.1094e-01,  1.1711e+00,  4.3995e-01, -7.4630e-01, -1.5638e+00,\n",
      "         -1.5124e+00,  2.6371e-01,  7.7979e-01,  1.2470e+00,  3.9133e-01,\n",
      "         -2.1686e+00,  1.4558e+00,  9.5134e-01, -5.4841e-01, -1.4237e+00,\n",
      "          8.6486e-01,  4.7790e-01,  1.3803e+00, -1.0125e+00,  3.6116e-01,\n",
      "         -1.6540e+00,  5.6490e-01,  1.1073e+00, -4.2113e-01, -1.5561e+00,\n",
      "         -4.6779e-01, -1.0116e-01, -2.2245e+00,  1.3561e+00, -6.9028e-02,\n",
      "         -5.5443e-02, -7.7738e-01, -8.4532e-01, -3.4249e-01,  1.4623e+00,\n",
      "          2.6232e-01,  1.5377e+00, -2.4693e-01,  3.9363e-01, -6.7877e-01,\n",
      "         -1.7474e+00,  4.8577e-01,  6.1932e-03,  6.9410e-01,  6.2555e-01,\n",
      "         -2.3662e-01, -2.2454e+00, -3.0418e-01,  1.8380e+00,  2.0998e+00,\n",
      "         -5.8816e-01,  1.5246e+00,  4.5746e-01, -2.2759e-01, -1.3492e-01,\n",
      "          5.0086e-01, -1.4791e-01, -4.1454e-01, -6.1899e-01,  1.3210e+00,\n",
      "          1.4360e+00, -5.2475e-02,  7.0572e-01,  2.9702e-01,  3.1598e-01,\n",
      "         -1.0071e-01,  1.0161e+00, -8.6836e-01, -7.3471e-01, -1.5589e-01,\n",
      "         -7.7505e-01, -1.1782e-01, -7.4190e-01,  5.4776e-01, -2.4229e+00,\n",
      "         -4.4205e-01, -1.6606e-01,  5.0026e-01, -4.9510e-01, -3.3518e-01,\n",
      "          3.1165e-01,  9.1698e-01, -1.4910e+00,  1.4424e+00,  1.9255e+00,\n",
      "         -1.4573e+00,  2.2440e+00, -9.9954e-01,  1.2302e+00, -8.1895e-01,\n",
      "          1.7923e+00, -1.3701e+00,  9.2871e-01, -6.3896e-01, -1.0855e+00,\n",
      "          1.7036e+00, -1.7989e-01,  1.5793e+00, -1.5118e-01, -1.8260e+00,\n",
      "          4.2201e-01, -1.2617e+00,  1.9967e+00, -7.8947e-01,  3.1479e-02,\n",
      "         -8.4338e-01, -1.1841e+00,  1.6719e-02,  3.0626e-02, -2.1947e-01,\n",
      "         -1.3497e+00, -1.8972e+00, -1.0432e+00, -4.2677e-01, -2.0635e+00,\n",
      "          1.1845e+00, -1.0502e+00, -5.4147e-01,  2.5232e-01, -6.0597e-01,\n",
      "          2.4475e+00,  8.0030e-01, -1.7518e+00,  9.8906e-01,  2.1564e-01,\n",
      "         -1.2634e+00, -7.1661e-02,  1.8008e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 7\n",
      "tensor([[-0.0212]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347, 5214,  347, 3226,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([-2.6912])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347, 5214,  347, 3226,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.1563e+00, -6.6796e-01, -5.7121e-01, -2.7897e-01, -2.5868e-01,\n",
      "          1.1487e+00,  4.1601e-01,  1.0793e+00, -3.3822e-01, -8.3648e-01,\n",
      "          2.1648e-01,  1.2436e-01,  6.1604e-01, -4.4588e-01,  1.1699e-01,\n",
      "         -2.1745e-02,  1.7288e-01,  1.8644e+00,  7.3975e-01, -7.8331e-01,\n",
      "          7.5807e-01, -8.4152e-01, -9.8011e-02,  3.9349e-01,  3.4007e-01,\n",
      "         -2.5495e-01,  1.0643e+00,  5.5120e-01,  5.5584e-01, -1.0192e+00,\n",
      "         -2.1765e+00, -6.6810e-01, -8.5116e-02, -6.3131e-02,  8.8841e-01,\n",
      "          9.8888e-01,  1.3905e+00, -1.6926e+00, -7.6073e-01,  3.5446e-01,\n",
      "          3.2802e-01, -5.2846e-01, -6.5616e-01, -3.9859e-01,  2.2792e+00,\n",
      "          1.2792e+00, -1.0081e+00,  2.5052e-01, -4.8195e-02,  2.4351e+00,\n",
      "         -8.2690e-01, -1.0628e+00, -1.5037e+00,  6.6172e-02,  9.0733e-01,\n",
      "         -6.4818e-02,  8.4181e-01, -1.8300e+00, -1.6503e-01, -7.4605e-01,\n",
      "         -1.1552e+00,  4.2668e-01, -3.5332e-01, -1.2401e+00,  9.7996e-02,\n",
      "          2.1459e-01,  1.0318e+00,  3.7283e-01,  8.1210e-01,  1.1866e-01,\n",
      "         -8.6971e-01,  8.6918e-02,  1.8589e-01, -1.3320e-02, -5.6220e-01,\n",
      "         -1.6674e+00,  2.1377e-01,  4.7017e-04,  8.5309e-01,  1.9733e+00,\n",
      "         -8.1718e-01,  8.6946e-01,  2.2785e-01,  1.0317e+00, -2.5253e-01,\n",
      "          1.5939e+00, -2.3219e-01, -7.5012e-01,  1.0178e+00,  4.3809e-01,\n",
      "         -6.2430e-01,  1.2483e+00,  9.7289e-01, -5.3372e-01, -1.8186e+00,\n",
      "         -2.4696e-01, -1.6878e+00, -1.0001e+00, -2.4505e+00, -1.4663e-01,\n",
      "         -1.5576e+00, -1.8730e+00,  1.6039e+00,  3.0570e-01, -6.0606e-01,\n",
      "         -2.6648e-01, -8.2508e-01,  2.4454e-01,  1.0303e+00, -1.2787e+00,\n",
      "         -5.2037e-01, -6.7551e-01,  7.1557e-01,  4.7196e-01,  9.4620e-01,\n",
      "         -2.1540e+00, -2.2068e-01,  1.3880e+00, -2.2734e-01,  1.1034e-01,\n",
      "         -5.3541e-01, -8.1189e-01, -2.5756e-01,  4.6167e-01, -3.5093e-01,\n",
      "          1.4480e+00, -1.2798e+00,  8.9840e-02,  1.7104e+00,  6.8332e-01,\n",
      "         -5.6251e-01, -6.8823e-01, -1.1093e+00, -8.6536e-01,  1.5750e-01,\n",
      "          1.8307e+00, -1.7199e+00, -3.9801e-01, -1.4162e+00,  2.6349e-01,\n",
      "         -2.7171e-01, -6.3870e-01, -5.4587e-01, -1.1200e+00,  8.0616e-01,\n",
      "         -5.7423e-01,  1.9398e+00,  2.4637e-01,  3.5108e-01,  1.2334e+00,\n",
      "          1.0418e+00, -5.5341e-01, -2.4444e+00, -4.7396e-01, -7.5786e-01,\n",
      "          1.3686e+00, -9.9970e-01, -3.5547e-01,  3.4826e-01,  2.3283e+00,\n",
      "          3.5840e-02,  3.5503e+00,  4.6820e-01,  5.8486e-01,  1.0748e+00,\n",
      "         -1.2912e+00, -5.1535e-02, -1.5209e+00, -8.2259e-01,  9.8007e-01,\n",
      "         -3.5753e-01, -3.0347e+00,  3.0495e-01, -4.8874e-01, -3.9617e-01,\n",
      "          1.8661e-01, -2.3237e+00, -3.7347e-01,  8.3775e-01,  1.2525e+00,\n",
      "          8.1793e-01,  5.5563e-01,  4.7029e-01,  1.4259e+00,  2.4703e-01,\n",
      "         -5.0101e-01,  7.7740e-01,  5.2500e-01, -6.1745e-01,  5.5002e-01,\n",
      "          5.3833e-01, -8.2258e-01,  1.7652e+00, -2.9724e-02,  6.2385e-01,\n",
      "         -7.9841e-01,  5.5763e-01, -7.4571e-01,  2.5080e+00, -6.4166e-01,\n",
      "          1.2566e-01,  5.6604e-01, -3.3488e-01, -2.4060e-01,  2.9094e-02,\n",
      "         -5.9040e-01, -8.9804e-02, -8.4395e-01,  6.8740e-01, -4.9336e-01,\n",
      "          1.3041e+00,  5.1773e-01, -7.9658e-01, -1.3741e+00,  1.3928e+00,\n",
      "          9.2902e-01, -8.9325e-01,  1.2258e+00,  9.6269e-01,  3.1088e-01,\n",
      "          2.2814e-01, -1.0139e+00,  1.2025e+00,  9.4361e-01,  9.1669e-01,\n",
      "         -4.9525e-01, -5.5629e-01,  1.4891e-01, -9.0581e-02, -1.0920e+00,\n",
      "         -9.2715e-02, -6.7649e-02,  5.3175e-01,  1.2746e-01, -3.2028e-01,\n",
      "          1.4630e+00, -1.7502e+00,  5.0247e-02,  3.9321e-01,  4.2629e-02,\n",
      "          1.6515e+00,  6.6932e-01,  1.0021e+00, -5.4169e-01, -4.3174e-01,\n",
      "          2.1459e-01,  3.7802e-01, -1.2024e+00,  9.9969e-01, -6.0240e-01,\n",
      "         -2.2146e+00, -4.6472e-02, -2.3139e-02, -6.9922e-01,  5.3012e-01,\n",
      "         -3.9894e-01,  5.1031e-01, -5.6319e-01, -7.9784e-01, -6.9659e-01,\n",
      "          5.7584e-01,  2.0513e-01, -1.6759e+00, -1.0368e+00, -1.5509e-01,\n",
      "         -1.0376e+00,  2.3134e-01,  9.9634e-01,  7.9807e-01, -3.9001e-02,\n",
      "          1.3849e-01, -1.5397e+00, -2.4580e-01,  1.5000e-01,  8.0519e-02,\n",
      "         -6.1148e-01, -4.4549e-01,  1.6426e-02,  1.0303e-01,  3.3216e-01,\n",
      "         -3.2793e-01,  2.9104e-01,  7.5041e-01, -1.5450e-01,  1.1155e+00,\n",
      "         -2.7294e-01, -4.5081e-01, -9.9953e-01, -9.0602e-01,  1.8692e+00,\n",
      "         -1.0784e+00, -3.6614e-01, -3.1060e-01, -7.7374e-01, -2.1294e-01,\n",
      "          1.1750e+00,  5.2634e-02, -3.7877e-01,  1.0414e+00, -2.8649e-01,\n",
      "          7.3436e-01, -7.3473e-01, -1.0161e+00, -3.5703e-01,  1.0249e+00,\n",
      "         -2.2538e-01,  1.0094e+00,  2.8868e-01, -7.7420e-02, -1.1248e+00,\n",
      "          1.3229e-01,  6.7616e-01, -2.2428e-01,  2.8986e-01, -9.1273e-01,\n",
      "         -2.7045e+00,  1.0335e+00,  3.8847e-01, -1.1242e+00,  1.6590e+00,\n",
      "          2.0348e-01,  5.8488e-01,  3.5023e-01, -1.1558e+00, -7.1290e-02,\n",
      "          2.5637e+00, -5.7445e-01,  7.8319e-01,  5.3512e-01,  2.6053e+00,\n",
      "          5.0044e-01, -1.0992e+00, -5.1952e-01, -2.4635e-01,  8.1905e-01,\n",
      "          1.5807e-01,  3.7409e-01,  2.3685e+00,  1.6023e+00, -6.1501e-01,\n",
      "          8.3061e-01, -1.3644e+00, -1.9150e+00, -1.9051e+00,  4.0143e-01,\n",
      "         -2.0296e-02,  1.3279e+00, -7.2258e-01, -2.2771e-01, -9.1014e-01,\n",
      "          3.5638e-01, -1.0283e+00,  6.6509e-01,  2.4778e-01, -4.7525e-01,\n",
      "          1.0291e+00, -5.8840e-01,  9.6325e-01, -7.3494e-02,  1.8183e-01,\n",
      "         -1.6337e+00,  8.2564e-01,  7.1397e-01, -2.8870e+00,  1.2026e+00,\n",
      "          1.5892e+00, -1.1392e+00,  1.8973e+00, -1.3602e+00,  3.2290e-01,\n",
      "         -3.4914e-01,  1.5169e+00, -6.8031e-01, -9.0590e-01, -3.2589e-01,\n",
      "          6.8125e-02,  1.1868e-01, -6.9596e-01, -2.7330e-01, -1.2685e+00,\n",
      "          7.0261e-01, -1.4064e+00, -1.1325e+00,  1.3135e+00,  8.2940e-01,\n",
      "         -3.1351e-01, -1.3384e+00,  1.2102e+00, -2.2404e+00, -3.2258e-01,\n",
      "          8.2669e-01,  9.7750e-01,  2.0333e-01,  1.0762e+00,  5.6388e-01,\n",
      "          1.2611e-01, -1.5689e-01, -1.1396e+00,  2.6232e-01, -9.1360e-02,\n",
      "          2.5807e-01, -2.5741e-01,  1.4558e+00, -8.0933e-01,  1.0608e+00,\n",
      "          4.4673e-01,  2.8641e-01, -1.6821e+00,  5.7501e-01, -6.1479e-01,\n",
      "          1.2198e+00, -6.1805e-01,  1.5916e+00,  1.9821e+00, -2.4982e+00,\n",
      "          2.3767e-01, -1.2620e+00,  3.9605e-01,  5.8688e-01, -6.8692e-01,\n",
      "         -1.0341e+00, -1.9373e-01,  6.0608e-01, -1.3713e+00,  1.1227e+00,\n",
      "         -1.0097e+00, -1.1056e+00,  1.1145e+00, -4.7475e-01,  5.3548e-01,\n",
      "          1.9182e+00,  2.6252e-01,  3.9252e-01, -5.8727e-01,  1.2624e+00,\n",
      "          8.0739e-01, -1.8383e-01,  1.3373e-01,  8.5762e-01, -8.3347e-01,\n",
      "          1.0823e+00, -1.7281e-01,  8.4234e-01, -1.8090e-01,  2.3657e-01,\n",
      "         -2.3954e-01, -6.2272e-02,  6.9169e-01, -1.4994e+00,  2.3773e-02,\n",
      "          2.0687e-01,  1.0223e+00, -3.7530e-01,  1.2430e+00, -5.0208e-01,\n",
      "         -2.2525e+00, -5.2017e-01, -3.1854e-02,  3.1982e-01, -2.7075e-01,\n",
      "         -4.1539e-03,  1.1120e-03,  3.1810e-01,  1.2079e+00,  4.7358e-01,\n",
      "          2.1739e+00, -4.9725e-01, -4.0537e-01,  9.7496e-01,  5.6052e-01,\n",
      "          1.3901e+00, -1.2614e+00,  9.2871e-01,  3.6115e-01, -1.4239e-01,\n",
      "         -7.8760e-01, -2.8334e-01,  1.3057e-01,  6.3726e-01, -5.1877e-01,\n",
      "         -4.3164e-01, -1.0574e+00, -4.5201e-02,  4.6044e-01, -5.9189e-01,\n",
      "         -6.2557e-01, -4.3766e-02, -1.9808e+00,  3.8235e-02,  1.0661e+00,\n",
      "         -1.7417e+00, -2.6900e-01, -3.9254e-01, -1.6202e+00,  2.3886e-02,\n",
      "          5.8350e-01, -7.2633e-02, -1.1279e+00,  1.2618e+00,  1.8579e+00,\n",
      "          7.4439e-02,  4.0271e-01,  1.7658e-01, -1.7760e-01, -2.9687e-01,\n",
      "         -1.1569e+00, -2.3338e-01, -1.4656e-01, -1.3102e+00, -1.3329e-01,\n",
      "         -2.5305e-01, -2.1725e-01,  2.7097e+00,  9.8084e-01, -1.9030e+00,\n",
      "          2.3621e-01, -3.9484e-01,  1.3341e+00,  7.3602e-03, -2.6128e-01,\n",
      "          1.5484e+00, -6.6861e-01,  7.6262e-03,  1.2012e+00,  3.2641e-01,\n",
      "         -4.5309e-01,  1.0975e+00,  1.2385e+00, -6.0065e-01, -7.2684e-01,\n",
      "          1.5204e+00, -4.3512e-01, -2.1461e+00,  1.4181e-01, -3.8960e-01,\n",
      "          1.1511e+00,  1.0181e+00,  1.8169e+00, -1.8774e-01, -1.1206e-01,\n",
      "          2.7091e+00,  5.6623e-01, -8.5087e-01, -9.0346e-01, -1.0188e+00,\n",
      "          9.2151e-01, -5.9666e-01, -7.1364e-01,  1.3239e+00, -5.9725e-01,\n",
      "          1.1758e-01,  3.6846e-01,  6.4196e-01, -1.3209e+00,  1.2723e+00,\n",
      "          6.0647e-01,  3.7625e-01, -1.9331e+00,  3.4360e-02, -5.2286e-02,\n",
      "          5.1043e-01,  1.2878e-01,  1.1889e+00, -3.9985e-01, -9.5230e-01,\n",
      "          9.1908e-02, -8.0695e-01, -3.0760e-01,  6.0619e-01, -3.6764e-01,\n",
      "          6.4558e-01,  9.1715e-01, -9.2517e-02,  4.9815e-01,  8.6099e-01,\n",
      "         -6.6436e-01,  7.1845e-01, -2.5880e+00,  1.3512e-01, -1.2262e+00,\n",
      "         -1.3555e+00, -1.0890e+00, -1.3838e-01, -2.0886e+00, -2.7600e-01,\n",
      "          9.2947e-02, -1.1289e+00,  6.8868e-01,  8.1360e-01,  3.8236e-01,\n",
      "          1.6902e+00, -1.3734e+00,  3.4858e-01, -1.1807e+00, -3.5643e-01,\n",
      "         -2.3890e-01,  2.1781e+00,  4.0813e-01,  2.2244e+00, -6.4486e-02,\n",
      "         -1.3160e+00,  2.3782e-01, -5.7326e-01, -3.7666e-01,  4.7459e-01,\n",
      "          9.8173e-01,  1.3100e+00,  5.7181e-01, -9.0402e-01,  1.0944e+00,\n",
      "          2.2702e+00, -5.0016e-01, -9.2214e-01, -6.5687e-01, -9.2903e-01,\n",
      "          6.4720e-01,  6.0111e-01,  8.9725e-01,  1.5436e+00,  1.6562e-02,\n",
      "         -5.8478e-01,  1.2204e+00, -9.2550e-01, -2.4320e-01, -2.8313e+00,\n",
      "          5.6944e-01,  1.9340e+00, -2.0447e+00, -7.9960e-01,  5.0248e-01,\n",
      "         -6.2060e-01,  6.4926e-01,  6.0070e-01,  2.0306e+00, -2.1564e+00,\n",
      "         -1.9249e-01, -2.6888e-01, -9.4408e-01,  9.4988e-02, -7.3904e-01,\n",
      "         -1.2270e+00,  8.8685e-01,  8.5465e-01, -8.4797e-01, -1.0860e+00,\n",
      "         -1.9831e+00, -7.0860e-01,  8.0841e-02,  1.3172e+00,  9.2673e-01,\n",
      "         -1.8066e+00,  1.5090e+00,  7.9948e-01, -2.0211e-01, -1.1804e+00,\n",
      "          1.0285e+00,  4.0362e-01,  5.5097e-01, -1.0510e+00,  6.4066e-01,\n",
      "         -1.0764e+00,  3.7331e-01,  9.6158e-01,  5.0361e-01, -1.9889e+00,\n",
      "          1.5280e-01,  1.0205e+00, -1.6220e+00,  8.0364e-01, -1.2649e+00,\n",
      "         -4.9810e-01, -6.7639e-01,  2.7228e-01, -7.6450e-01,  1.6661e+00,\n",
      "          6.5934e-02,  1.5645e+00, -4.4247e-01,  3.0214e-01, -2.6377e-01,\n",
      "         -1.7816e+00, -4.3136e-01,  2.6272e-01,  1.0393e+00,  8.9990e-01,\n",
      "         -1.4942e+00, -1.6245e+00,  5.5906e-01,  1.6503e+00,  2.1183e+00,\n",
      "         -1.2116e+00,  1.8972e+00,  1.1150e+00,  2.6637e-02, -1.1476e-01,\n",
      "          8.1187e-01, -4.5389e-02, -1.0250e+00, -2.1890e+00,  9.6106e-01,\n",
      "          1.1473e+00, -2.8440e-01,  2.8155e-01,  4.9298e-01,  2.8761e-01,\n",
      "          9.6795e-02, -2.5796e-01, -1.2011e+00, -2.2417e-01,  9.9167e-01,\n",
      "         -3.3033e-01, -3.9268e-01,  3.7343e-01,  1.0049e+00, -1.7327e+00,\n",
      "         -7.2340e-01, -1.9154e-01,  6.6273e-01, -9.1316e-01, -1.9644e-01,\n",
      "          1.1417e+00,  3.3954e-01, -1.2901e+00,  1.4492e+00,  1.6101e+00,\n",
      "         -1.8657e-01,  1.4669e+00, -9.6834e-01,  6.2218e-01, -1.6388e+00,\n",
      "          1.2997e+00, -1.2333e+00,  3.6833e-01, -8.5371e-01,  2.2509e-01,\n",
      "          1.1541e+00, -3.2886e-01,  1.5604e+00,  4.2593e-01, -2.0359e+00,\n",
      "          2.8633e-01, -9.7218e-01,  2.1405e+00, -9.5101e-01,  4.6079e-02,\n",
      "         -6.7365e-01, -6.8317e-01,  1.0326e-01,  3.2826e-01, -1.6267e-01,\n",
      "         -1.2862e+00, -1.9263e+00, -1.6049e+00, -7.5522e-01, -2.3248e+00,\n",
      "          1.4960e+00, -7.6406e-01, -4.3713e-01,  2.5492e-01, -6.5571e-01,\n",
      "          2.5445e+00,  2.1661e-01, -1.2304e+00,  1.8690e+00,  2.1728e-02,\n",
      "         -6.3396e-01,  1.1724e-01,  6.5935e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 8\n",
      "tensor([[-0.0765]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347, 3226,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([0.6719])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347, 3226,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.3282e+00, -2.4673e-01, -1.2351e+00, -6.3076e-01, -8.5155e-02,\n",
      "          2.4000e-01,  3.3212e-01,  4.9469e-01, -7.6653e-01, -7.0489e-01,\n",
      "         -3.2501e-01, -2.4727e-02,  7.9282e-01, -4.6476e-01,  4.9716e-01,\n",
      "         -3.1673e-01, -1.1064e+00,  5.8964e-01,  6.9000e-01,  1.5950e-01,\n",
      "          1.8203e+00, -7.1460e-01, -1.0758e+00,  2.1403e-01, -3.8980e-01,\n",
      "         -1.0983e-01,  1.0426e+00,  1.6569e-01,  1.1573e-01, -3.4041e-01,\n",
      "         -5.5015e-01, -6.2153e-01,  2.8855e-01,  6.1042e-01, -6.3570e-02,\n",
      "          1.3562e+00,  1.5689e+00, -3.7892e-01, -8.8076e-01, -5.9534e-01,\n",
      "          5.0159e-01, -9.1076e-01, -4.4025e-01, -4.1757e-01,  1.8216e+00,\n",
      "          6.9266e-01, -1.2997e+00,  4.8975e-01,  1.0650e+00,  2.7399e-01,\n",
      "         -7.2484e-01, -1.9758e+00, -1.0195e+00,  1.7700e-01,  1.3711e+00,\n",
      "          2.5074e-01,  9.1548e-01, -1.1954e+00, -1.0358e+00, -3.1012e-01,\n",
      "         -1.5526e+00, -5.4576e-01, -4.0378e-01, -3.3816e-01, -1.0356e-01,\n",
      "         -6.0541e-01,  5.9551e-01,  4.2903e-01,  2.3975e+00, -1.9193e-01,\n",
      "         -1.5001e+00,  1.4560e-01,  4.3791e-01,  3.1396e-02,  5.4513e-01,\n",
      "         -1.9609e+00,  1.8333e-01,  1.8107e-01,  1.1579e+00,  1.3549e+00,\n",
      "         -5.0354e-01,  5.4651e-01,  1.0821e+00, -2.1504e-01, -4.1433e-01,\n",
      "          1.6181e+00, -7.1703e-01, -5.2975e-01,  8.1568e-01, -1.2898e-01,\n",
      "         -6.4519e-01,  1.1177e+00,  1.0886e+00,  6.3051e-01, -1.6389e+00,\n",
      "         -3.8383e-02, -1.0155e+00,  1.7706e-01, -1.8871e+00,  5.6575e-01,\n",
      "         -2.0907e+00, -1.4760e+00,  1.6079e+00, -9.3702e-02, -6.6501e-01,\n",
      "         -1.1811e-01, -1.0787e+00,  9.2236e-01,  1.2190e+00, -6.9970e-01,\n",
      "         -2.2781e-01, -4.4025e-01, -4.4845e-01,  2.8708e-01,  2.1189e+00,\n",
      "         -1.1309e+00, -8.1502e-01,  1.6250e+00, -5.7326e-01,  2.2962e-01,\n",
      "         -1.3332e+00,  1.8362e-02, -1.0403e-01, -4.7175e-02, -3.6664e-01,\n",
      "          7.8355e-01, -1.7436e+00,  4.0221e-01,  1.5358e+00,  6.8112e-01,\n",
      "         -2.1092e-01, -1.0400e+00, -5.3796e-01, -6.6434e-01,  6.6623e-02,\n",
      "          1.5166e+00, -1.6847e+00, -4.5899e-01, -1.4078e+00,  1.1683e-01,\n",
      "         -6.1942e-01, -3.8623e-01,  2.0786e-01, -8.3955e-01,  7.2468e-01,\n",
      "         -7.6824e-01,  1.7173e+00, -1.8678e+00, -1.6105e+00,  2.1653e+00,\n",
      "          1.0641e+00, -7.0653e-02, -9.8345e-01, -2.7968e-01, -5.6979e-01,\n",
      "          1.8176e+00, -1.2990e+00, -8.8769e-01,  3.3313e-02,  2.5879e+00,\n",
      "         -5.9275e-02,  3.2435e+00,  7.3467e-01, -3.5287e-02,  8.9110e-01,\n",
      "         -1.4723e+00,  5.6831e-01, -3.3758e-01, -6.6582e-01,  9.2483e-01,\n",
      "         -6.0077e-01, -2.5214e+00,  1.0373e+00, -1.3380e-01, -3.2263e-01,\n",
      "          1.3738e-01, -2.5170e+00,  3.8156e-01,  4.6046e-01,  6.9290e-01,\n",
      "          7.2261e-01, -1.0305e-01,  1.7064e-03,  1.0090e+00,  1.9764e-01,\n",
      "         -2.5798e+00,  1.8695e-01,  6.3275e-01, -7.0009e-01, -5.8265e-01,\n",
      "          4.5088e-01, -5.4977e-01,  1.4007e+00, -1.0027e-01,  4.4731e-01,\n",
      "         -2.2888e+00,  1.9568e+00, -8.0044e-01,  8.5714e-02, -1.2373e+00,\n",
      "          3.1862e-01,  1.1807e+00, -1.6640e-01,  5.8463e-01, -4.0016e-01,\n",
      "         -1.6167e+00,  4.2946e-01, -4.6692e-01,  3.0971e-01, -2.3611e-01,\n",
      "          8.9799e-01,  1.2594e-01, -6.4178e-01, -4.9919e-01,  1.3659e+00,\n",
      "          1.0267e+00,  4.1490e-01,  1.1684e+00, -7.6492e-03,  6.5611e-01,\n",
      "          1.5807e-01, -2.3754e-01,  4.3528e-01,  8.6712e-01,  1.3912e+00,\n",
      "          3.4788e-01, -1.8859e-01,  6.2721e-01, -4.6225e-01, -1.5528e+00,\n",
      "          6.5847e-01, -6.9972e-01, -4.6417e-01,  3.5581e-01, -6.6467e-01,\n",
      "          4.8762e-01, -1.9145e+00, -1.9135e-01,  7.1396e-01,  8.0618e-01,\n",
      "          1.5602e+00,  5.9955e-01,  8.5665e-01, -7.7207e-02, -8.2718e-01,\n",
      "         -4.7773e-03, -4.6924e-01, -5.4597e-01,  1.4073e+00, -7.6522e-01,\n",
      "         -1.7151e+00,  9.4532e-01, -1.5266e-01, -7.4953e-01,  1.7905e+00,\n",
      "         -1.4441e-01,  9.0468e-02, -8.4374e-01, -1.1252e+00, -3.9243e-01,\n",
      "          1.9610e-01,  1.5299e+00, -1.1757e+00, -9.5503e-01,  2.7633e-02,\n",
      "         -4.9175e-01,  4.1650e-01,  4.1180e-01,  7.8510e-01,  1.8805e-01,\n",
      "         -7.8753e-01, -1.4172e+00, -5.5913e-01,  2.0082e-01,  1.0775e-01,\n",
      "         -9.8612e-01, -1.1369e+00,  7.3189e-01, -7.3394e-02,  4.0317e-01,\n",
      "         -1.5978e+00,  1.4674e+00,  6.3244e-01, -8.8408e-02,  5.2419e-01,\n",
      "         -2.6748e-01, -1.7864e-01, -9.0197e-01, -5.2264e-01,  9.2465e-01,\n",
      "         -7.5700e-01, -4.8516e-02,  7.8956e-01, -4.4201e-01,  2.3362e-01,\n",
      "          4.7888e-01, -7.7940e-01, -7.7339e-02,  5.0405e-03, -8.8846e-01,\n",
      "          1.5063e-01, -9.7487e-02, -4.2294e-01, -3.6763e-02,  1.8194e+00,\n",
      "          5.9888e-01,  8.6338e-01,  2.5262e-01,  4.0721e-01, -1.7073e+00,\n",
      "         -2.1796e-01,  8.3340e-01, -1.1912e-01,  6.7392e-01, -8.9271e-01,\n",
      "         -1.8474e+00,  1.0308e+00,  1.4723e+00, -2.5851e+00,  1.4538e+00,\n",
      "         -2.4613e-01,  1.2788e+00,  3.5002e-01, -9.1239e-01, -7.2499e-01,\n",
      "          4.8437e-01, -5.7115e-01,  1.1454e+00, -8.8600e-02,  2.4164e+00,\n",
      "          3.7833e-01, -1.2689e+00,  9.5199e-02,  1.8345e+00,  9.2164e-01,\n",
      "         -8.0196e-01,  6.8888e-01,  7.4491e-01,  9.0083e-01,  6.0290e-02,\n",
      "          1.4509e+00, -1.0604e+00, -2.0582e+00, -2.9218e-01,  1.7077e-01,\n",
      "          2.9812e-01,  2.0178e+00, -6.0873e-01, -2.6819e-03, -2.1911e+00,\n",
      "         -5.9520e-01, -2.7306e-01,  6.8804e-01,  3.6273e-01, -5.0089e-01,\n",
      "          1.4919e+00, -1.1198e+00,  1.4782e-01,  6.5117e-01,  6.9447e-02,\n",
      "         -2.6860e+00,  1.0612e+00,  1.2812e+00, -2.9796e+00, -8.9929e-02,\n",
      "          1.9457e+00, -1.9431e+00,  1.2212e+00, -1.0035e+00,  7.3353e-02,\n",
      "          8.6412e-02,  1.4172e+00, -1.7793e+00, -4.3535e-01, -1.8033e-01,\n",
      "         -6.9605e-01, -4.2016e-01, -3.5460e-01, -5.6700e-01, -1.1320e+00,\n",
      "          6.8309e-02, -5.9158e-01, -1.1021e+00,  2.1667e+00,  9.3237e-01,\n",
      "         -1.0862e-01, -1.0715e+00,  6.5362e-01, -1.6693e+00, -9.5450e-01,\n",
      "         -1.1421e-02,  2.2578e-01,  3.3408e-01,  1.2432e+00,  1.1623e+00,\n",
      "         -4.9883e-01,  5.6723e-01, -7.0617e-01,  4.8870e-01, -7.6621e-01,\n",
      "         -2.8745e-01, -5.1129e-01,  2.8670e-01, -1.0511e+00,  8.6387e-01,\n",
      "         -2.9640e-01,  8.1088e-01, -1.0575e+00,  6.6323e-01, -3.1010e-02,\n",
      "          1.5202e+00, -7.0952e-01,  5.5311e-01,  1.9034e+00, -2.9579e+00,\n",
      "         -2.0897e-02, -1.2057e+00,  2.8695e-01,  5.4276e-01, -1.1454e+00,\n",
      "         -9.1701e-01, -7.0470e-01,  6.8756e-01, -1.8411e+00,  1.3921e+00,\n",
      "         -5.2240e-01, -9.9048e-01,  9.4653e-01, -7.2135e-01,  8.2872e-01,\n",
      "          1.1756e+00,  1.2642e+00, -3.5253e-01, -3.0582e-01,  3.6254e-03,\n",
      "          1.5319e+00,  2.2126e-01,  5.0251e-01,  1.2246e-01, -1.2238e+00,\n",
      "          1.4657e+00,  1.3307e-01,  1.2036e+00, -1.6859e-01, -8.2658e-02,\n",
      "         -8.0587e-01,  1.0456e+00,  8.1495e-01, -1.6694e+00,  2.4847e-01,\n",
      "          1.1030e+00,  1.5390e+00, -7.7853e-01,  8.4470e-01, -4.1263e-01,\n",
      "         -8.8978e-01,  9.7322e-01,  6.3021e-02,  2.3055e-01,  5.6930e-01,\n",
      "         -2.3320e-01,  3.4543e-01,  1.0521e+00,  1.8026e+00, -1.3742e-01,\n",
      "          1.4803e+00, -2.1228e-01,  2.5081e-01,  5.8323e-01, -1.1471e-01,\n",
      "          1.4105e+00, -6.2954e-01,  9.1750e-02,  9.2003e-01,  7.9703e-02,\n",
      "         -4.0251e-01, -1.5499e+00,  4.9075e-01,  3.9419e-01, -1.4593e-01,\n",
      "         -5.0155e-01, -6.0126e-01, -1.8633e-01,  4.2588e-01, -8.8927e-01,\n",
      "         -7.6818e-01,  1.0209e-01, -9.5737e-01,  5.5670e-01,  1.0693e+00,\n",
      "         -1.1843e+00, -6.3911e-02, -4.3465e-01, -5.9700e-01,  9.2784e-01,\n",
      "          2.8308e-01, -4.6101e-01, -1.7952e+00,  1.5777e+00,  8.1643e-01,\n",
      "         -3.4109e-01,  2.1120e-01,  8.4778e-01, -7.1299e-01, -5.8227e-01,\n",
      "         -1.0549e+00,  5.4222e-01, -4.7204e-02, -1.6420e+00,  3.3874e-02,\n",
      "         -7.0423e-01, -3.4713e-02,  2.6685e+00,  6.0704e-01, -1.2350e+00,\n",
      "         -3.7904e-02,  1.1779e-01,  6.2917e-01, -3.0032e-01, -6.0925e-02,\n",
      "          1.2418e+00,  3.9780e-01, -4.2263e-01,  6.4438e-01,  2.3767e-01,\n",
      "         -8.6419e-01,  1.1594e+00,  1.0994e+00, -7.5188e-01, -6.8870e-01,\n",
      "          1.2970e+00, -6.1455e-02, -2.1215e+00,  6.1138e-02, -1.3371e+00,\n",
      "          9.9026e-01,  5.3588e-01,  2.4754e+00,  2.3486e-01, -2.5087e-02,\n",
      "          2.2071e+00, -4.4757e-01, -2.3180e+00, -2.9060e-02, -5.8976e-01,\n",
      "          5.6940e-01, -7.4939e-02, -9.0023e-01,  4.6696e-01, -4.2075e-01,\n",
      "          9.7546e-04, -1.3088e+00,  4.9785e-01, -1.3409e+00,  9.9391e-01,\n",
      "          2.8449e-01,  9.6994e-01, -1.6761e+00,  8.9447e-01,  2.3157e-01,\n",
      "          5.8638e-01, -7.0340e-02,  1.4260e+00, -2.6218e-01, -7.4098e-01,\n",
      "          2.5743e-01, -3.3234e-01,  2.6623e-01,  6.1911e-01,  2.5845e-01,\n",
      "          1.0323e+00,  4.4843e-01,  1.0253e+00,  1.2594e+00,  1.9666e+00,\n",
      "         -4.1493e-01,  8.9923e-01, -2.7585e+00, -1.1475e+00, -3.5099e-01,\n",
      "         -1.8130e+00, -2.7400e-01,  4.4603e-01, -2.6836e+00, -2.3950e-01,\n",
      "          1.6067e+00, -6.9988e-01,  1.3886e+00, -1.4077e-02,  5.8142e-01,\n",
      "          1.3750e+00, -9.9063e-01,  3.8223e-01, -1.5143e+00, -1.3686e+00,\n",
      "         -1.0292e+00,  1.6208e+00,  1.3393e+00,  5.1475e-01, -4.7984e-02,\n",
      "         -1.1669e+00,  4.5097e-01, -1.3387e+00, -5.4159e-01, -3.2889e-01,\n",
      "          4.1767e-01,  7.5952e-01,  5.4647e-01, -5.5249e-01,  6.1511e-01,\n",
      "          2.3659e+00, -3.8274e-01, -2.0325e+00, -9.7852e-01, -4.7570e-01,\n",
      "          2.3410e-01, -8.0494e-01,  7.9809e-01, -5.9001e-03,  3.6685e-01,\n",
      "          2.6982e-03,  4.9568e-01, -1.1898e+00, -6.9195e-01, -2.8062e+00,\n",
      "         -2.4148e-01,  2.5623e+00, -1.6685e+00, -2.2613e-01,  1.1589e+00,\n",
      "          1.2842e-01, -4.1765e-02, -2.3483e-01,  2.5114e+00, -8.4300e-01,\n",
      "         -5.6607e-01,  3.3435e-01, -1.0568e+00,  3.1716e-01, -6.3392e-01,\n",
      "         -1.0901e+00,  1.0106e+00,  2.1938e+00, -6.1017e-01, -6.6512e-01,\n",
      "         -1.3696e+00,  1.6679e-01,  5.2495e-01,  9.5358e-01,  4.2184e-01,\n",
      "         -1.3421e+00,  1.1138e+00,  7.0059e-01, -2.8479e-01, -8.1102e-01,\n",
      "          8.1381e-01,  2.5555e-01,  6.6087e-01, -1.2683e+00,  8.1338e-01,\n",
      "         -1.1977e+00, -4.4084e-01,  1.6531e+00,  8.8372e-01, -1.8025e+00,\n",
      "          8.1036e-01,  1.4132e+00, -3.9925e-01,  7.9412e-01, -4.0351e-01,\n",
      "         -1.2936e+00, -1.3385e+00,  5.5520e-01, -4.5203e-01,  1.8882e+00,\n",
      "          4.6455e-01,  2.3957e+00, -1.2687e+00, -1.1609e-01, -3.7070e-01,\n",
      "         -6.6547e-01, -3.4111e-01,  4.4035e-01,  6.2088e-01,  5.5241e-01,\n",
      "         -1.4101e+00, -1.6919e+00, -8.7302e-02,  2.2000e+00,  2.3784e+00,\n",
      "         -1.7347e+00,  1.8484e+00,  8.0306e-01,  3.5880e-01, -1.6365e-01,\n",
      "          1.0399e+00,  3.9664e-01, -6.7132e-01, -5.7549e-01,  1.5998e+00,\n",
      "          2.3053e+00, -9.5913e-01, -7.5178e-02,  8.4040e-01, -1.5217e-01,\n",
      "          1.1052e-01, -3.5830e-01, -2.0029e+00,  6.1486e-01,  1.2476e+00,\n",
      "         -4.6093e-01, -5.6256e-01,  5.9444e-01,  8.1861e-01, -6.2736e-01,\n",
      "         -6.5432e-01, -4.3278e-01,  7.1284e-01, -1.1814e+00, -1.3540e-01,\n",
      "          9.1027e-01,  5.0584e-01, -1.0669e+00,  1.1276e-01,  3.4032e-01,\n",
      "         -1.6889e-01,  1.6789e+00, -6.5420e-01, -1.0195e-01, -2.1694e+00,\n",
      "          9.4149e-01, -8.1096e-01,  2.4734e-01, -7.3074e-01, -9.3826e-01,\n",
      "          5.1713e-01,  7.7952e-01,  1.2811e+00,  2.5725e-01, -2.0100e+00,\n",
      "          8.6920e-02, -3.9334e-01,  1.3229e+00,  9.5983e-02,  1.0185e+00,\n",
      "         -2.1843e+00, -6.1917e-01,  7.7898e-01,  1.0962e+00, -3.6899e-01,\n",
      "         -1.1375e+00, -5.7520e-01, -1.6154e+00, -2.9973e-01, -1.5538e+00,\n",
      "          1.2801e+00, -7.2048e-01,  2.0996e-01, -6.5003e-01, -1.1920e+00,\n",
      "          2.6395e+00, -4.5267e-01, -1.7309e+00,  5.9458e-01,  8.6741e-02,\n",
      "          3.9915e-01,  7.7015e-04,  9.3773e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n",
      "Output for step 9\n",
      "tensor([[0.0239]], grad_fn=<ToCopyBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 2/1\n",
      "Train func is called\n",
      "Step: 0\n",
      "Batch\n",
      "{'input_ids': tensor([[   0, 3226,  347, 5214,  347,  347,  347,  347, 3226,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'prop': tensor([-0.7105])}\n",
      "Input ids of batch\n",
      "tensor([[   0, 3226,  347, 5214,  347,  347,  347,  347, 3226,    2,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1]])\n",
      "Finger print is:\n",
      "tensor([[-1.3427e+00, -1.1090e+00,  2.8052e-01, -6.1448e-01, -4.7658e-01,\n",
      "          1.1459e+00,  6.3138e-01,  1.0870e+00, -1.3770e+00,  5.3410e-02,\n",
      "         -3.4300e-01, -6.8813e-02,  1.9650e+00,  4.7122e-01, -9.6099e-01,\n",
      "          3.0505e-01,  1.4493e+00,  7.1342e-01, -4.0075e-01, -4.6544e-01,\n",
      "          4.8123e-01, -1.3162e-01,  5.4756e-02,  3.7056e-03,  4.6317e-02,\n",
      "          1.9161e-01, -1.3654e-01,  3.3418e-01,  4.2076e-01,  2.9591e-01,\n",
      "         -1.6213e+00, -1.5673e-01, -3.8840e-01,  5.9581e-01,  1.7737e+00,\n",
      "          1.2322e+00,  7.1621e-01, -1.2765e+00, -8.4758e-01,  5.8891e-01,\n",
      "          2.0394e-01, -1.4970e-01, -1.0114e+00,  5.1648e-02,  1.6117e+00,\n",
      "          2.1198e+00, -4.1896e-01,  9.1356e-02,  4.2835e-01,  2.1526e+00,\n",
      "         -8.7879e-01, -5.1849e-01, -1.5730e+00, -5.4911e-01, -3.4812e-01,\n",
      "          1.7047e-01,  6.6748e-01, -1.3096e+00,  1.6272e-01, -6.2937e-01,\n",
      "         -1.1156e+00,  9.2778e-01, -2.7154e-01, -1.8205e+00, -4.4965e-01,\n",
      "          5.2966e-02,  4.4468e-01,  1.2569e-01,  4.1574e-01,  7.7123e-01,\n",
      "         -9.1287e-01, -9.4474e-01, -3.0170e-01,  2.5361e-01, -5.4249e-01,\n",
      "         -1.4208e+00, -7.4148e-01,  5.0414e-02,  5.9408e-01,  2.8769e+00,\n",
      "         -8.4714e-01,  8.8780e-01,  5.5558e-01,  1.2704e+00, -4.4259e-01,\n",
      "          6.7135e-01, -5.4035e-02, -9.7336e-01, -5.0441e-02, -6.6980e-01,\n",
      "         -2.8678e-01,  1.0002e+00,  3.2263e-01,  1.4468e-02, -1.4489e+00,\n",
      "          1.1804e+00, -2.0734e+00, -1.6406e+00, -1.5052e+00, -3.0748e-01,\n",
      "         -1.0253e+00, -1.0939e+00,  6.4980e-01, -4.9900e-01, -9.6124e-01,\n",
      "          2.5445e-02, -3.0094e-01, -2.7679e-01,  1.0219e-01, -8.6705e-01,\n",
      "          7.0443e-01, -8.7190e-01,  9.0887e-01,  5.0642e-01, -3.5070e-02,\n",
      "          2.9366e-02, -1.4906e-01,  5.7040e-01, -5.4828e-02, -7.4760e-01,\n",
      "         -1.9047e+00, -5.7496e-01, -1.5293e+00,  1.4935e+00,  1.7257e-01,\n",
      "          5.0879e-01, -5.7038e-01,  1.0696e+00,  2.5907e+00,  1.2139e+00,\n",
      "         -1.5026e-01, -1.3488e+00, -1.5785e+00, -1.1402e+00,  6.8592e-02,\n",
      "          1.7731e+00, -1.8966e+00,  2.9477e-01, -2.0384e+00,  1.1472e-01,\n",
      "          1.5654e-02, -4.9546e-01, -1.6932e-01,  1.5684e-01,  3.6252e-03,\n",
      "         -6.9502e-01,  2.3258e+00, -2.6108e-02, -1.2244e+00,  2.3334e-01,\n",
      "          1.6560e+00,  6.6982e-02, -1.5485e+00, -4.3989e-01, -9.7394e-01,\n",
      "          3.0998e-01,  4.3518e-01, -3.6502e-01,  2.6104e-01,  1.1610e+00,\n",
      "          1.0218e-01,  1.6968e+00,  1.6220e-01,  6.9620e-01,  5.4225e-03,\n",
      "          1.4411e-01, -8.6582e-01, -1.6917e+00, -5.4324e-01,  1.8048e+00,\n",
      "          4.5610e-01, -1.4206e+00, -5.1780e-01, -5.8416e-01, -3.8309e-01,\n",
      "         -4.3859e-01, -4.1868e-02,  9.5056e-01,  7.0702e-01,  8.6906e-01,\n",
      "          3.7236e-01,  1.6475e-01,  4.8114e-01,  1.9407e+00,  6.0347e-01,\n",
      "         -1.1056e+00,  7.0054e-01,  8.5826e-02,  1.1647e+00,  1.8649e+00,\n",
      "          1.4520e+00, -6.2300e-01,  1.1989e+00,  1.8637e-01, -4.9802e-01,\n",
      "          1.1029e+00, -1.0756e+00,  8.3625e-02,  2.6648e+00, -6.3301e-01,\n",
      "         -6.7639e-01,  3.0387e-01,  6.3235e-01,  5.6452e-01,  2.0649e-01,\n",
      "         -4.2852e-02,  1.5396e+00, -4.5069e-02,  3.8765e-02, -6.5331e-01,\n",
      "          1.7269e+00, -3.9434e-01,  7.5686e-01, -1.5056e+00,  4.6694e-01,\n",
      "          3.4874e-01, -1.4777e+00,  1.5135e+00, -1.8564e-01,  1.1204e-01,\n",
      "          1.6549e-01, -1.1216e+00,  1.3306e+00,  5.3826e-01,  1.3790e+00,\n",
      "         -8.6163e-01,  1.1824e-01, -3.6857e-01, -4.7594e-02,  6.4379e-01,\n",
      "          1.1961e-01,  1.1530e+00,  1.6266e+00,  8.3181e-01,  7.8422e-01,\n",
      "          5.9094e-01, -1.3646e+00,  1.2476e-01,  1.6317e+00, -1.9885e-01,\n",
      "          3.0262e-01,  7.6964e-01,  1.4875e+00, -7.5182e-02, -4.2922e-01,\n",
      "         -1.6036e-01,  9.0323e-01, -4.3389e-01,  1.5946e+00,  6.4110e-01,\n",
      "         -1.9866e-01, -1.3273e+00,  2.4861e-01, -9.1170e-01, -6.1087e-01,\n",
      "         -9.2976e-02,  1.7792e+00, -9.0557e-01,  2.1151e-01, -7.9476e-01,\n",
      "          3.3800e-01,  1.0327e+00, -6.6554e-01, -9.6812e-01, -4.5175e-01,\n",
      "         -1.5642e+00, -2.7758e-01,  7.7111e-01,  1.5615e+00,  3.4436e-01,\n",
      "          9.9698e-01, -1.1813e+00,  7.6886e-01, -4.0024e-01, -1.7266e+00,\n",
      "          2.1836e-01,  7.8755e-02, -9.2418e-01, -4.1525e-01,  8.7872e-01,\n",
      "         -7.7239e-01,  5.4820e-01,  1.2165e+00, -1.1655e+00,  1.2222e+00,\n",
      "          1.0019e+00, -2.0021e-01,  4.0920e-01,  2.8816e-01,  1.8528e+00,\n",
      "         -1.1534e+00, -6.2250e-01, -1.4290e+00, -2.4545e-01, -8.6949e-01,\n",
      "          1.0078e+00,  5.6625e-01,  1.8647e-01,  3.1312e-01,  4.7417e-01,\n",
      "          1.0837e+00, -1.1738e-01, -1.7624e+00, -8.3448e-01,  1.4108e-01,\n",
      "         -5.9974e-01,  8.4591e-01,  5.8743e-01, -1.8628e+00, -5.9739e-01,\n",
      "         -1.6936e-01,  7.9699e-01, -6.7549e-01,  7.4467e-01, -1.2393e+00,\n",
      "         -1.6703e+00,  4.9950e-01,  7.1312e-01, -2.3515e-01, -4.9084e-01,\n",
      "          3.2347e-01, -7.5447e-02,  1.0984e+00, -1.2007e+00,  1.8005e-01,\n",
      "          7.0350e-01,  1.7324e-01, -6.8943e-01, -1.9513e-01,  1.9205e+00,\n",
      "         -4.2484e-01, -6.1101e-01, -1.5156e-01, -4.1732e-01,  1.1711e+00,\n",
      "         -1.2337e+00,  9.2943e-01,  2.4007e+00,  2.1793e+00, -1.1244e-01,\n",
      "          8.8335e-01, -4.4714e-01, -1.4242e+00, -1.0009e+00,  8.5346e-01,\n",
      "         -1.5396e+00,  4.4491e-01, -1.2745e+00,  8.1074e-02,  6.9134e-01,\n",
      "          1.0234e+00, -1.5167e+00, -5.7320e-01,  3.2008e-01, -1.0716e+00,\n",
      "          1.1814e-01, -1.7257e-01,  4.8074e-01, -8.7974e-01,  1.1275e+00,\n",
      "         -1.5222e+00, -4.7233e-01, -3.8922e-02, -2.2861e+00,  8.5163e-01,\n",
      "          1.3847e+00, -1.8234e+00,  1.3085e+00, -1.3295e+00,  1.0267e-01,\n",
      "         -1.5481e-02,  6.8749e-01, -6.7266e-02, -7.9456e-01, -5.2616e-01,\n",
      "          2.9813e-01, -8.8896e-01, -6.4487e-01,  3.9312e-03, -1.9923e+00,\n",
      "         -4.1955e-01, -2.0681e-01, -1.7182e+00,  4.2112e-01,  1.3675e+00,\n",
      "          3.9708e-01, -1.4400e+00,  8.5381e-01, -1.7707e+00,  3.5711e-01,\n",
      "          4.7886e-01,  1.3238e+00, -1.3690e-01, -2.7188e-02,  8.0891e-01,\n",
      "         -5.4563e-01, -1.7601e+00, -1.0396e+00, -5.5088e-01,  1.4251e+00,\n",
      "         -1.2355e-01, -4.6320e-01,  1.3103e+00, -1.2957e+00,  3.6675e-01,\n",
      "          1.0495e+00,  5.5030e-01, -2.4020e+00, -5.7941e-01, -4.5483e-01,\n",
      "          1.3753e+00,  4.4177e-01,  6.1869e-01,  1.7541e+00, -1.4169e+00,\n",
      "         -8.9870e-01, -1.3572e+00,  1.0887e+00, -2.2144e-02, -1.1114e+00,\n",
      "         -3.1414e-01,  3.9868e-01,  5.5811e-01,  4.6599e-02,  6.1250e-01,\n",
      "         -6.3592e-01, -6.9549e-01,  1.3866e+00, -4.7255e-01,  1.7485e-01,\n",
      "          7.6025e-01, -7.0579e-01, -1.0695e-02, -2.3346e-01,  1.1025e+00,\n",
      "          5.5321e-01, -9.2525e-02,  1.9813e-01,  1.3475e-01, -3.3380e-01,\n",
      "          3.1473e-01, -1.0966e+00,  1.1519e-01,  4.4288e-01,  9.3204e-01,\n",
      "         -9.6275e-01,  6.7725e-01,  7.7681e-01, -1.0874e+00,  3.8393e-01,\n",
      "         -7.5085e-01,  5.4760e-03, -2.6290e-03, -2.7226e-01,  5.8193e-01,\n",
      "         -2.9268e+00, -3.7603e-01, -1.5827e-01,  5.3105e-01, -6.6263e-01,\n",
      "          2.7153e-02, -6.6437e-01, -1.8360e-01,  1.0070e+00,  5.8424e-01,\n",
      "          1.8824e+00, -4.2591e-01, -7.4434e-01, -6.8433e-02,  1.1838e+00,\n",
      "          1.4360e+00, -2.7014e-01,  1.9740e+00, -5.2912e-01,  7.3729e-02,\n",
      "         -9.9158e-01,  1.2933e+00, -3.4927e-01,  9.7159e-05,  1.0540e-02,\n",
      "         -5.9975e-01, -8.8628e-01,  1.1033e-01,  1.0497e+00,  1.7930e-01,\n",
      "          1.4519e-01, -1.9148e-02, -1.1155e-01,  2.1909e-01,  1.2853e+00,\n",
      "         -7.9324e-01, -7.0038e-01, -3.2456e-01, -1.3595e+00,  1.5497e+00,\n",
      "          9.6481e-01,  1.0420e+00, -8.0133e-01,  1.6663e+00,  1.9428e+00,\n",
      "         -4.2087e-01,  6.4273e-02, -7.4653e-01,  7.2442e-01, -6.9265e-01,\n",
      "          6.7374e-01, -4.5407e-01, -4.5469e-01, -4.7471e-01, -4.2374e-01,\n",
      "         -2.9773e+00, -5.5806e-01,  1.4346e+00,  2.3972e-01, -1.5593e+00,\n",
      "          7.0525e-01,  3.8772e-01,  1.4975e+00,  5.6831e-01, -6.4100e-01,\n",
      "          2.4117e+00,  1.9297e-01, -2.9794e-01,  1.0727e+00, -6.4386e-01,\n",
      "          1.1769e-02, -1.3529e-01,  4.9014e-01,  1.5914e+00, -7.9203e-01,\n",
      "          7.9772e-01,  7.8225e-02, -2.3081e+00,  1.0948e-01, -4.2409e-01,\n",
      "          5.0673e-01,  7.1861e-01,  9.2636e-01,  3.1377e-01, -1.7849e-01,\n",
      "          2.0282e+00,  1.0001e+00, -2.1810e+00, -1.3084e+00, -7.6850e-01,\n",
      "          1.5763e+00, -1.0971e+00, -3.0230e-02,  5.4380e-01, -1.9021e-01,\n",
      "          1.6190e+00, -1.2688e+00,  6.7569e-01, -1.2918e+00,  1.4226e-01,\n",
      "          1.7258e+00,  1.0673e+00, -2.8164e+00, -5.7343e-01,  2.2863e-01,\n",
      "         -1.0004e+00,  1.2964e-01,  4.7856e-01,  6.0243e-02, -2.4793e-01,\n",
      "          1.1243e+00, -6.3171e-01,  8.1284e-01,  2.4649e-03, -1.1387e+00,\n",
      "          1.2133e+00,  1.5091e+00, -2.9331e-02,  9.3146e-02,  6.6582e-01,\n",
      "         -1.2408e+00,  7.8200e-01, -1.8568e+00, -1.1186e+00, -9.6869e-01,\n",
      "         -1.4857e+00, -1.2796e+00,  4.0686e-01, -1.5401e+00,  8.8470e-02,\n",
      "         -1.1364e+00, -1.1401e+00,  1.3182e-01, -2.0593e-01, -3.8212e-01,\n",
      "         -9.5278e-02, -3.4836e-01,  1.1272e+00, -8.0279e-01, -5.6155e-01,\n",
      "         -5.1069e-01,  3.1821e+00,  4.8946e-01,  3.2563e-01, -4.4355e-01,\n",
      "         -1.6306e+00, -6.1661e-01, -1.6898e+00,  9.7650e-02,  5.5353e-01,\n",
      "          1.0128e+00,  5.3124e-01,  1.0757e+00, -1.3917e+00, -6.7220e-02,\n",
      "          1.0874e+00,  2.0668e-01, -1.1415e+00, -1.1911e-01,  2.9029e-01,\n",
      "          9.3422e-01,  1.2553e+00,  8.9173e-01,  1.5410e+00,  5.8247e-01,\n",
      "         -4.3204e-01,  1.9716e+00, -9.5999e-01, -1.1390e+00, -1.1543e+00,\n",
      "          2.9129e-01,  1.0949e+00, -2.0925e+00, -8.6931e-01,  1.7832e+00,\n",
      "         -7.6425e-01,  3.9344e-01,  2.8066e-01,  2.3922e+00, -2.3207e+00,\n",
      "          6.8880e-02, -2.3420e-01, -6.8014e-01,  5.1962e-01, -5.2510e-01,\n",
      "         -4.1985e-01,  1.0512e+00, -6.7010e-01, -3.3286e-01, -7.1033e-01,\n",
      "         -1.5783e+00,  4.3466e-02, -9.0722e-01,  1.2300e+00, -2.1011e-01,\n",
      "         -3.6074e+00,  2.0187e+00,  1.0602e+00, -6.6565e-01, -6.1506e-01,\n",
      "          5.0651e-01, -3.8420e-01,  1.6637e+00, -5.9007e-01,  1.1149e+00,\n",
      "         -1.8370e+00, -4.2127e-02,  7.5379e-01, -9.9862e-01, -8.8639e-01,\n",
      "         -1.3959e-01,  1.6350e-01, -2.2415e+00,  9.8753e-01, -3.9703e-01,\n",
      "         -3.0059e-01, -1.5308e-01, -8.7820e-01, -6.3318e-01,  8.9331e-01,\n",
      "          4.1743e-01,  2.3389e+00, -8.0381e-01,  2.2150e-01, -7.3691e-01,\n",
      "         -1.3693e+00,  6.8688e-01,  1.4428e+00,  1.3516e+00,  8.6421e-03,\n",
      "         -1.6150e-01, -2.2732e+00,  7.7907e-01,  2.0402e+00,  1.1438e+00,\n",
      "         -5.4832e-02,  8.6721e-01,  5.4864e-01,  3.5225e-02,  3.4663e-01,\n",
      "          3.8169e-01,  2.1742e-01, -3.8542e-01, -1.7340e+00,  1.3385e+00,\n",
      "          1.6409e+00,  4.2925e-01,  1.1830e+00,  6.6375e-02, -8.0377e-02,\n",
      "          3.1549e-01,  1.1433e+00, -6.2833e-01, -3.0650e-01,  8.8004e-01,\n",
      "         -3.9610e-01, -3.5429e-01, -8.5447e-01, -2.8945e-01, -2.7699e+00,\n",
      "          2.8079e-02, -3.6953e-01, -3.3694e-04, -2.6279e-01, -4.1341e-01,\n",
      "          4.9725e-01,  1.0584e+00, -6.8916e-01,  1.5868e+00,  1.8619e+00,\n",
      "         -1.0951e+00,  1.1071e+00, -4.3141e-01,  1.4508e+00, -7.9114e-01,\n",
      "          1.9086e+00, -1.7601e+00,  2.2385e-01, -6.5465e-01, -1.0015e+00,\n",
      "          1.4657e+00,  2.1153e-01,  1.4954e+00, -6.7627e-01, -2.0065e+00,\n",
      "          1.1157e+00, -8.6280e-01,  2.1160e+00, -8.4203e-01, -1.8013e+00,\n",
      "         -5.5259e-01, -1.3539e+00, -9.9821e-02,  9.8369e-02,  2.1343e-01,\n",
      "         -8.6770e-01, -9.4300e-01,  2.5803e-02, -1.6301e+00, -2.0653e+00,\n",
      "          7.3961e-01, -1.5441e+00, -1.3681e+00,  3.6462e-01, -1.8204e-01,\n",
      "          2.2976e+00,  1.0098e+00, -1.1571e+00,  8.1568e-01,  4.4545e-01,\n",
      "         -1.0218e+00, -6.1318e-02,  5.7623e-01]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for step 0\n",
      "tensor([[-0.3086]], grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\tprint(\"Training epoch: %s/%s\" % (epoch+1, 1))\n",
    "\ttrain(model, optimizer, scheduler, loss_fn, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
